{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster-RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/DeepLearning/Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MF2Suorb2s7",
        "colab_type": "text"
      },
      "source": [
        "# <font face=STCAIYUN size=10 color=purple>构建Faster RCNN</font>\n",
        "\n",
        "\n",
        "**<font face=楷体 color=skyblue size=5>训练Faster RCNN大致流程</font>**\n",
        "\n",
        "<font face=楷体 color=skyblue>1、从图像中提取特征  \n",
        "2、生成anchor，筛选、转换得到RPN网络的训练标签  \n",
        "3、RPN网络中得到预测位置和正负样本的预测得分(Anchors$\\Longrightarrow ROIs$)  \n",
        "4、取前N个ROIs作为建议框（大约2000个proposals）  \n",
        "5、从proposals中挑选出n个样本作为建议目标喂给Fast R-CNN网络  \n",
        "6、通过Fast RCNN的分类和位置回归层得到预测    \n",
        "7、采用2,3计算rpn_cls_loss和rpn_reg_loss  \n",
        "8、采用5,6计算roi_cls_loss和roi_reg_loss  \n",
        "</font> \n",
        "\n",
        "\n",
        "<img src=\"https://img-blog.csdnimg.cn/20200217201316137.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcxMTU1NA==,size_16,color_FFFFFF,t_70\" width=\"80%\" height=\"80%\">\n",
        "\n",
        "<font face=楷体 size=5 color=green>绿色链接：</font>  \n",
        "【1】[Guide to build Faster RCNN in PyTorch](https://medium.com/@fractaldle/guide-to-build-faster-rcnn-in-pytorch-95b10c273439)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhVGR8LPdE3R",
        "colab_type": "text"
      },
      "source": [
        "## 提取特征\n",
        "<font face=楷体 color=skyblue>示例如何定义一张图像、bbox（两个）及其标签</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N1cMxogn1ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "image = torch.zeros((1, 3, 800, 800)).float()\n",
        "\n",
        "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]]) # [y1, x1, y2, x2] format\n",
        "labels = torch.LongTensor([6, 8]) # 0 represents background\n",
        "sub_sample = 16"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWIHh_Y73n6G",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>生成一张图片（dummy image）</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk7AeHlHS_vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46e933e8-9e60-4560-dc94-5e8bd1cc39f0"
      },
      "source": [
        "import torchvision\n",
        "dummy_img = torch.zeros((1, 3, 800, 800)).float()\n",
        "print(dummy_img.shape)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 800, 800])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pApvQWCh4oJc",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>列出VGG16的所有层</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCcqJz0lTCjt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "f6021b26-67fd-4be5-ff83-f6d1204aae58"
      },
      "source": [
        "# model = torchvision.models.vgg16(pretrained=True)\n",
        "model = torchvision.models.vgg16(pretrained=False)\n",
        "fe = list(model.features)\n",
        "for layer in fe:\n",
        "    print (layer)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lFie3NZ4zP2",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将图像喂给网络，确定得到相应的输出尺寸</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVXE5KCITE8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "25f60c1b-5268-4c43-93e1-b0ea4f8f1673"
      },
      "source": [
        "req_features = []\n",
        "k = dummy_img.clone()\n",
        "for i in fe:\n",
        "    k = i(k)\n",
        "    if k.size()[2] < 800//16:\n",
        "        break\n",
        "    req_features.append(i)\n",
        "    out_channels = k.size()[1]\n",
        "print(len(req_features)) #30\n",
        "print(out_channels) # 512"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frk664ZF5kG5",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将list转换为Sequential module</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CHH7IXETLZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "faster_rcnn_fe_extractor = torch.nn.Sequential(*req_features)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "betsGKcr5z1x",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>用构建好的VGG16网络提取特征图</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lo6CllBTa7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e782f476-befb-4bc1-91c5-e9910d347c00"
      },
      "source": [
        "out_map = faster_rcnn_fe_extractor(image)\n",
        "print(out_map.size())"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 50, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g78lFac06K-3",
        "colab_type": "text"
      },
      "source": [
        "## Anchor boxes\n",
        "<font face=楷体>\n",
        "\n",
        "- 将feature map的每个像素位置映射回输入图，作为锚点位置\n",
        "- 在feature map对应的所有位置上生成Anchor\n",
        "- 将标签和目标与Anchor相对位置分配给每个Anchor\n",
        "\n",
        "采用参数：anchor_scales=[8，16，32] ratio=[0.5，1，2] subsampling=16\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5wVFjHR78ax",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>feature map的一个像素位置生成9个anchor boxes，每个像素对应输入图像中的16*16像素</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYCgkuxDKVjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "643e5086-02dc-41bb-c1f5-f14b7f088c28"
      },
      "source": [
        "import numpy as np\n",
        "ratios = [0.5, 1, 2]\n",
        "anchor_scales = [8, 16, 32]\n",
        "\n",
        "anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4), dtype=np.float32)\n",
        "\n",
        "print(anchor_base)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EajsCQw_1xsZ",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>一个位置要生成9个Anchors</font>\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/971/1*cPidpSRVUVgv3YeY9Fc11Q.png\" width=\"25%\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsQyUHHMVw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "74f0d48f-7885-444f-e541-76134f546b9b"
      },
      "source": [
        "ctr_y = sub_sample / 2.\n",
        "ctr_x = sub_sample / 2.\n",
        "print(ctr_y, ctr_x)\n",
        "\n",
        "for i in range(len(ratios)):\n",
        " for j in range(len(anchor_scales)):\n",
        "   h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])    # 输出的feature map的每个像素对应图像中的16*16像素\n",
        "   w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratios[i])  # ration决定了anchor的长宽比例(相同面积)\n",
        "\n",
        "   index = i * len(anchor_scales) + j\n",
        "\n",
        "   anchor_base[index, 0] = ctr_y - h / 2.\n",
        "   anchor_base[index, 1] = ctr_x - w / 2.\n",
        "   anchor_base[index, 2] = ctr_y + h / 2.\n",
        "   anchor_base[index, 3] = ctr_x + w / 2.\n",
        "print(anchor_base)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.0 8.0\n",
            "[[ -37.254833  -82.50967    53.254833   98.50967 ]\n",
            " [ -82.50967  -173.01933    98.50967   189.01933 ]\n",
            " [-173.01933  -354.03867   189.01933   370.03867 ]\n",
            " [ -56.        -56.         72.         72.      ]\n",
            " [-120.       -120.        136.        136.      ]\n",
            " [-248.       -248.        264.        264.      ]\n",
            " [ -82.50967   -37.254833   98.50967    53.254833]\n",
            " [-173.01933   -82.50967   189.01933    98.50967 ]\n",
            " [-354.03867  -173.01933   370.03867   189.01933 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9WZhhRTbGSA",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>feature map的每一个像素位置都要生成9个anchor boxes，将每个像素位置映射回输入图中，作为Anchor的中心，每个像素对应输入图像中的16*16像素</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTw56ZpwNCJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "68948394-f904-4263-d87d-12e4b970fa66"
      },
      "source": [
        "fe_size = (800//16)\n",
        "ctr_x = np.arange(16, (fe_size+1) * 16, 16)\n",
        "ctr_y = np.arange(16, (fe_size+1) * 16, 16)\n",
        "print (ctr_x)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272 288\n",
            " 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560 576\n",
            " 592 608 624 640 656 672 688 704 720 736 752 768 784 800]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlkvqR4Adi57",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>在原图上生成Anchor中心位置</font>  \n",
        "\n",
        "<img src=\"https://miro.medium.com/max/969/1*f-AxsYA9ys5wtiY9NDZh9Q.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI3PdJs5OaaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 0\n",
        "ctr  = np.zeros(shape=(len(ctr_x)*len(ctr_y),2))\n",
        "for x in range(len(ctr_x)):\n",
        "   for y in range(len(ctr_y)):\n",
        "       ctr[index, 1] = ctr_x[x] - 8  # 前面生成中心点位置偏移了8个像素点\n",
        "       ctr[index, 0] = ctr_y[y] - 8\n",
        "       index +=1"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z02c3OUeXhC4",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>每个位置生成9个Anchors</font>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRMZoB4yWfGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bed4fecd-c2d2-4459-8cc0-7fc6bf6fb2f1"
      },
      "source": [
        "anchors = np.zeros(shape=(fe_size * fe_size * 9, 4))  # 共有2500个锚点，每个锚点9个框，每个框4个参数\n",
        "index = 0\n",
        "for c in ctr:\n",
        " ctr_y, ctr_x = c\n",
        " for i in range(len(ratios)):\n",
        "   for j in range(len(anchor_scales)):\n",
        "     h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])\n",
        "     w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratios[i])\n",
        "     anchors[index, 0] = ctr_y - h / 2.\n",
        "     anchors[index, 1] = ctr_x - w / 2.\n",
        "     anchors[index, 2] = ctr_y + h / 2.\n",
        "     anchors[index, 3] = ctr_x + w / 2.\n",
        "     index += 1\n",
        "print(anchors.shape)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22500, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1bWvWvxdJLY",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=5>给anchor分配标签和位置</font>  \n",
        "<font face=楷体>\n",
        "a)与ground-truth-box IoU最大的anchor标记为正标签1  \n",
        "b)与ground-truth-box IoU大于0.7的anchor标记为正标签1  \n",
        "c)与ground-truth-box IoU小于0.3的anchor标记为负标签0  \n",
        "d)其余anchor既不是正样本的也不是负样本，对训练没有帮助-1  \n",
        "<font color=red>注意：</font>单个ground-truth对象可以为多个anchor分配正标签  \n",
        "</font>\n",
        "<font face=楷体 color=skyblue>通过如下方式对anchor boxes分配标签和位置：</font>   \n",
        "<font face=楷体>\n",
        "1、找到有效的anchor boxes的索引，并且生成索引数组，生成标签数组其形状索引数组填充-1  \n",
        "2、检查是否满足以上a、b、c条件中的一条，并相应填写标签。如果是正anchor box(标签为1)，注意哪个ground-truth目标可以得到这个结果。  \n",
        "3、计算与anchor box相关的ground-truth的位置(loc)。  \n",
        "4、通过为所有无效的anchor box填充-1和为所有有效Anchor计算具体值，重新组织所有anchor box。  \n",
        "5、输出应该是(N, 1)数组的标签和带有(N, 4)数组的locs。  \n",
        "6、找到所有有效anchor boxes的索引\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmkwu2Dmxs8-",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>定义两个目标框及其标签</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yzP6Xs2OAQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox = np.asarray([[20, 30, 400, 500], [300, 400, 500, 600]], dtype=np.float32) # [y1, x1, y2, x2] format\n",
        "labels = np.asarray([6, 8], dtype=np.int8) # 0 represents background "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_VLt6dD6R31",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>挑选出未超出图片坐标边界的框</font>\n",
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/968/1*6E4EXMoTvSLZTlHLWpS3uA.png\" width=\"25%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjpMFy5qOE2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "020c748f-2d34-455a-a4cc-822e9614b69f"
      },
      "source": [
        "inside_index = np.where(\n",
        "       (anchors[:, 0] >= 0) &\n",
        "       (anchors[:, 1] >= 0) &\n",
        "       (anchors[:, 2] <= 800) &\n",
        "       (anchors[:, 3] <= 800)\n",
        "   )[0]\n",
        "print(inside_index.shape)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0nv-ugX6eV0",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>初始化标签为-1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPuDM6_RSzdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f1e8276-79e7-43c5-f68a-6483b9eedc6d"
      },
      "source": [
        "label = np.empty((len(inside_index), ), dtype=np.int32)\n",
        "label.fill(-1)\n",
        "print(label.shape)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqCIyc3k62cL",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>获取有效anchor（图片内anchor）坐标</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfBg94s0TJ4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4aff8c91-466e-47e2-a604-c6f01f866558"
      },
      "source": [
        "valid_anchor_boxes = anchors[inside_index]\n",
        "print(valid_anchor_boxes.shape)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Urojwf77xLA",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>计算每个anchor框与所有目标框的IOU，这里目标框共2个</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZSL1KcFTVUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "2a2526d3-fbda-4488-e4ae-9b20b09bdd32"
      },
      "source": [
        "ious = np.empty((len(valid_anchor_boxes), 2), dtype=np.float32)\n",
        "ious.fill(0)\n",
        "print(\"两个目标框为：\\n{}\".format(bbox))\n",
        "for num1, i in enumerate(valid_anchor_boxes):\n",
        "   ya1, xa1, ya2, xa2 = i \n",
        "   anchor_area = (ya2 - ya1) * (xa2 - xa1)  # 有效框面积\n",
        "   for num2, j in enumerate(bbox):\n",
        "       yb1, xb1, yb2, xb2 = j\n",
        "       box_area = (yb2- yb1) * (xb2 - xb1)  # 目标框面积\n",
        "\n",
        "       inter_x1 = max([xb1, xa1])\n",
        "       inter_y1 = max([yb1, ya1])\n",
        "       inter_x2 = min([xb2, xa2])\n",
        "       inter_y2 = min([yb2, ya2])\n",
        "       if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
        "           iter_area = (inter_y2 - inter_y1) * \\\n",
        "(inter_x2 - inter_x1)\n",
        "           iou = iter_area / \\\n",
        "(anchor_area + box_area - iter_area) \n",
        "       else:\n",
        "           iou = 0.\n",
        "\n",
        "       ious[num1, num2] = iou\n",
        "print(ious.shape)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "两个目标框为：\n",
            "[[ 20.  30. 400. 500.]\n",
            " [300. 400. 500. 600.]]\n",
            "(8940, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvcJ9zabkmkP",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>分别找到与每个gt_box iou最高的 anchor box(两个)</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWg8E-xHThar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f2a95c1d-d95e-4111-ee2c-3d6f700d798a"
      },
      "source": [
        "gt_argmax_ious = ious.argmax(axis=0)\n",
        "print(gt_argmax_ious)\n",
        "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n",
        "print(gt_max_ious)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2262 5620]\n",
            "[0.68130493 0.61035156]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBvOPwkclPKv",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>得到每个anchor box与所有ground-truth box中 的最高iou</font> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQrIneFgUN6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "76e3673b-834f-4e38-b984-d181c3fab63f"
      },
      "source": [
        "argmax_ious = ious.argmax(axis=1)\n",
        "print(argmax_ious.shape)\n",
        "print(argmax_ious)\n",
        "max_ious = ious[np.arange(len(inside_index)), argmax_ious]\n",
        "print(max_ious.shape)\n",
        "print(max_ious)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940,)\n",
            "[0 0 0 ... 0 0 0]\n",
            "(8940,)\n",
            "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI7btHDJDqT-",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>根据上面目标与Anchors的最大IOU值，获取等于该值的index（对应的Anchor索引，一般不存在与两个目标框的IoU都最大的情况），便于对Anchors进行正负样本设定</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwp3Yz2qRty7",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=green size=5>绿色链接</font>  \n",
        "<font face=楷体>\n",
        "【1】[numpy.where() 用法详解](https://www.cnblogs.com/massquantity/p/8908859.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IFkuG7IURfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "35b9eb30-553e-43c4-c5f5-52214a13f1cd"
      },
      "source": [
        "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
        "print(ious[np.where(ious == gt_max_ious)])\n",
        "print(gt_argmax_ious)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.68130493 0.68130493 0.61035156 0.61035156 0.61035156 0.61035156\n",
            " 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156\n",
            " 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156]\n",
            "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
            " 6358 6366 6374 6382]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdsU7-w-Ej_M",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>设置正负样本阈值</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmlR9UOrUfM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_iou_threshold  = 0.7\n",
        "neg_iou_threshold = 0.3\n",
        "\n",
        "label[max_ious < neg_iou_threshold] = 0  # 小于0.3为负样本\n",
        "label[gt_argmax_ious] = 1  # 最大IOU对应anchor为正样本\n",
        "label[max_ious >= pos_iou_threshold] = 1  # 大于0.7为正"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Mbi1UuGZjk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<font face=楷体 color=skyblue size=4>设置正负样本比例及总量 <font>\n",
        "\n",
        "<font face=楷体> \n",
        "每张图片都可以产生大量的样本，但多数情况下负样本占优，需要从样本中随机抽取一定数量的样本作为一个mini-batch，并且要保持一定正负样本比例维持均衡<font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwju5732UtZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_ratio = 0.5  # 正样本比例\n",
        "n_sample = 256  # 样本总量\n",
        "\n",
        "n_pos = pos_ratio * n_sample  # 正样本数量"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOhtVN-mO086",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>如果正样本数量大于n_pos，则随机抽取n_pos个正样本</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVP0qf5XUwm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "84096484-cbc2-4bdf-cdfb-b3edf72318c4"
      },
      "source": [
        "pos_index = np.where(label == 1)[0]\n",
        "print(np.where(label == 1))\n",
        "print(pos_index)\n",
        "if len(pos_index) > n_pos:\n",
        "   disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace=False)\n",
        "   label[disable_index] = -1"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
            "       6120, 6128, 6136, 6358, 6366, 6374, 6382]),)\n",
            "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
            " 6358 6366 6374 6382]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE8B6EWIUzc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "80b3fc44-a5c6-4437-a6e8-eb0d369fe03d"
      },
      "source": [
        "n_neg = n_sample - np.sum(label == 1)\n",
        "print(n_neg)\n",
        "neg_index = np.where(label == 0)[0]\n",
        "if len(neg_index) > n_neg:\n",
        "   disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
        "   label[disable_index] = -1"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80E5VzZuU1E9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "1a28918b-3ba1-4843-ccee-3aaf2bc3c079"
      },
      "source": [
        "print(bbox)  \n",
        "print(argmax_ious)  # 各个Anchor与目标框最大IoU对应的的列索引 0：[ 20.  30. 400. 500.] ， 1：[300. 400. 500. 600.]\n",
        "max_iou_bbox = bbox[argmax_ious]\n",
        "print(max_iou_bbox)\n",
        "print(max_iou_bbox.shape)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 20.  30. 400. 500.]\n",
            " [300. 400. 500. 600.]]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[[ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]\n",
            " ...\n",
            " [ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]]\n",
            "(8940, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6qOl85AQ-Z-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<font face=楷体 color=skyblue>有效anchor的中心点和宽高：ctr_x, ctr_y, width, height  \n",
        "有效anchor对应目标框的中心点和宽高: base_ctr_x, base_ctr_y, base_width, base_height</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV2fy7qeU9Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:, 0]\n",
        "width = valid_anchor_boxes[:, 3] - valid_anchor_boxes[:, 1]\n",
        "ctr_y = valid_anchor_boxes[:, 0] + 0.5 * height\n",
        "ctr_x = valid_anchor_boxes[:, 1] + 0.5 * width\n",
        "\n",
        "base_height = max_iou_bbox[:, 2] - max_iou_bbox[:, 0]\n",
        "base_width = max_iou_bbox[:, 3] - max_iou_bbox[:, 1]\n",
        "base_ctr_y = max_iou_bbox[:, 0] + 0.5 * base_height\n",
        "base_ctr_x = max_iou_bbox[:, 1] + 0.5 * base_width"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqXDjvN_RxYC",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=yellow size=5>疑问：</font>  \n",
        "\n",
        "<font face=楷体 color=yellow>有效anchor转为目标框的系数（dy，dx是平移系数；dh，dw是缩放系数）  \n",
        "为什么不用绝对值呢？</font>   \n",
        "<font face=楷体>\n",
        "- 1）$\\log/\\exp$变换防止出现负数，网络学习的是<font color=skyblue>proposal box$\\to$gt box</font>的变换系数\n",
        "- 2）直接学习真实坐标，loss并不能很好地反映预测准确性，因为大目标即使预测得很准也可能比预测较差的小目标loss大得多，因此直接预测真实坐标所产生的loss并不能很好地反映预测框的好坏(yolo v1对w, h取了平方根，可以有效缓解这个问题，但是并不能解决这个问题)\n",
        "</font> \n",
        "\n",
        "$$\\begin{matrix}\n",
        "&t_{x} = (x - x_{a})/w_{a} \n",
        "&t_{y} = (y - y_{a})/h_{a}\\\\\n",
        "&t_{w} = \\log(w/ w_a)\n",
        "&t_{h} = \\log(h/ h_a)\n",
        "\\end{matrix}$$\n",
        "\n",
        "<font face=楷体 color=green size=5>绿色链接：</font>  \n",
        "<font face=楷体>\n",
        "【1】[python numpy np.finfo()函数 eps](https://blog.csdn.net/Dontla/article/details/103062246)\n",
        "</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDNkIdsVCU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "6705233e-c2ba-4fa4-a8aa-25e132526944"
      },
      "source": [
        "eps = np.finfo(height.dtype).eps  # 代表非负的最小值\n",
        "height = np.maximum(height, eps)\n",
        "width = np.maximum(width, eps)\n",
        "dy = (base_ctr_y - ctr_y) / height\n",
        "dx = (base_ctr_x - ctr_x) / width\n",
        "dh = np.log(base_height / height)\n",
        "dw = np.log(base_width / width)\n",
        "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
        "print(anchor_locs)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.5855728   2.30914558  0.7415674   1.64727602]\n",
            " [ 0.49718446  2.30914558  0.7415674   1.64727602]\n",
            " [ 0.40879611  2.30914558  0.7415674   1.64727602]\n",
            " ...\n",
            " [-2.50801936 -5.29225232  0.7415674   1.64727602]\n",
            " [-2.59640771 -5.29225232  0.7415674   1.64727602]\n",
            " [-2.68479606 -5.29225232  0.7415674   1.64727602]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnsFQev4RaaO",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>每个anchor框对应的label\n",
        "- -1：无效anchor，\n",
        "- 0：负有效anchor，\n",
        "- 1：正有效anchor\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qHwQzPUVcr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "050c10fc-8f50-4278-cccc-a3498b45cc72"
      },
      "source": [
        "anchor_labels = np.empty((len(anchors),), dtype=label.dtype)\n",
        "print(anchor_labels)\n",
        "anchor_labels.fill(-1)\n",
        "print(anchor_labels)\n",
        "print(anchor_labels.shape)\n",
        "print(label)\n",
        "print(label.shape)\n",
        "anchor_labels[inside_index] = label\n",
        "print(anchor_labels.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1768030208           0  -859807206 ...  1081065155  1717580045\n",
            "  1082267608]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n",
            "(22500,)\n",
            "[-1 -1 -1 ... -1 -1 -1]\n",
            "(8940,)\n",
            "(22500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6BJnCZ2Xu2w",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>每个anchor框对应的目标框的系数</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SkyOD_hVgMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d54c748c-642d-4a0e-a620-5059b0bc5065"
      },
      "source": [
        "anchor_locations = np.empty((len(anchors),) + anchors.shape[1:], dtype=anchor_locs.dtype)  # (22500,)+(4,)=(22500,4),anchors.shape[1]=4,anchors.shape[1:]=(4,)\n",
        "anchor_locations.fill(0)\n",
        "anchor_locations[inside_index, :] = anchor_locs\n",
        "print(anchor_locs.shape)\n",
        "print(anchor_locations.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940, 4)\n",
            "(22500, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqOMACoC365U",
        "colab_type": "text"
      },
      "source": [
        "<font face =楷体 color=yellow>用IOU过滤的方式给选定的Anchor分配正负样本标签+真实目标框和选定的Anchor的位置系数为位置标签$\\color{red}\\Longrightarrow$RPN的训练标签</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slEgWwib5qCc",
        "colab_type": "text"
      },
      "source": [
        "## RPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNfww66-Z_GL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<font face=楷体 color=skyblue>构建rpn网络</font>  \n",
        "\n",
        "<font face=楷体>【1】[nn.Conv2d和其中的padding策略](https://blog.csdn.net/g11d111/article/details/82665265)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRYF5x0VlL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "mid_channels = 512\n",
        "in_channels = 512  # depends on the output feature map. in vgg 16 it is equal to 512\n",
        "n_anchor = 9     # Number of anchors at each location\n",
        "conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
        "reg_layer = nn.Conv2d(mid_channels, n_anchor *4, 1, 1, 0)\n",
        "cls_layer = nn.Conv2d(mid_channels, n_anchor *2, 1, 1, 0) # I will be going to use softmax here. you can equally use sigmoid if u replace 2 with 1."
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dR-h3TDascn",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>初始化</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ZaPI5jV4fW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af3ea7cd-7984-4004-9041-91435782eea9"
      },
      "source": [
        "# conv sliding layer\n",
        "conv1.weight.data.normal_(0, 0.01)\n",
        "conv1.bias.data.zero_()\n",
        "\n",
        "# Regression layer\n",
        "reg_layer.weight.data.normal_(0, 0.01)\n",
        "reg_layer.bias.data.zero_()\n",
        "\n",
        "# classification layer\n",
        "cls_layer.weight.data.normal_(0, 0.01)\n",
        "cls_layer.bias.data.zero_()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg45B-SsV7wo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "995dd81e-ea3a-4151-d19c-f7222f10305e"
      },
      "source": [
        "x = conv1(out_map) # out_map is obtained in section 1\n",
        "pred_anchor_locs = reg_layer(x)\n",
        "pred_cls_scores = cls_layer(x)\n",
        "\n",
        "print(pred_cls_scores.shape, pred_anchor_locs.shape)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 18, 50, 50]) torch.Size([1, 36, 50, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOYT4O_T_mNc",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=yellow>疑问：</font>  \n",
        "<font face=楷体>\n",
        "1、objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:, :, :, :, 1] 取[:, :, :, :, 0]呢  \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSC_aCkCV9oL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "9f49e4db-880b-47e5-f0ac-5280f771f296"
      },
      "source": [
        "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
        "print(pred_anchor_locs.shape)\n",
        "\n",
        "#Out: torch.Size([1, 22500, 4])\n",
        "\n",
        "pred_cls_scores = pred_cls_scores.permute(0, 2, 3, 1).contiguous()\n",
        "print(pred_cls_scores.shape)\n",
        "#Out torch.Size([1, 50, 50, 18])\n",
        "\n",
        "objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:, :, :, :, 1].contiguous().view(1, -1)  # 取正的score\n",
        "print(objectness_score.shape)\n",
        "#Out torch.Size([1, 22500])\n",
        "\n",
        "pred_cls_scores  = pred_cls_scores.view(1, -1, 2)\n",
        "print(pred_cls_scores.shape)\n",
        "# Out torch.size([1, 22500, 2])"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 22500, 4])\n",
            "torch.Size([1, 50, 50, 18])\n",
            "torch.Size([1, 22500])\n",
            "torch.Size([1, 22500, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icuffglS8TDZ",
        "colab_type": "text"
      },
      "source": [
        "#### 生成候选区喂给Fast RCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8LffAo2nZLv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<font face=楷体 color=skyblue>设置参数</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-TKjdbpXEkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nms_thresh = 0.7\n",
        "n_train_pre_nms = 12000\n",
        "n_train_post_nms = 2000\n",
        "n_test_pre_nms = 6000\n",
        "n_test_post_nms = 300\n",
        "min_size = 16  # cov5输出的特征图大小为原图1/16，相当于精度只有16个像素点"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGG-NtKdnu_7",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>转换anchor格式从 y1, x1, y2, x2 到 ctr_x, ctr_y, h, w </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYCU_WFQV_0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anc_height = anchors[:, 2] - anchors[:, 0]\n",
        "anc_width = anchors[:, 3] - anchors[:, 1]\n",
        "anc_ctr_y = anchors[:, 0] + 0.5 * anc_height\n",
        "anc_ctr_x = anchors[:, 1] + 0.5 * anc_width"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0r0JbNgn1d1",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>根据预测的四个系数，将anchor框通过平移和缩放转化为预测的目标框</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5X_9U5PWMAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_anchor_locs_numpy = pred_anchor_locs[0].data.numpy()\n",
        "objectness_score_numpy = objectness_score[0].data.numpy()\n",
        "\n",
        "dy = pred_anchor_locs_numpy[:, 0::4]  # 0::4任然保持列，直接取0列会变成普通列表\n",
        "dx = pred_anchor_locs_numpy[:, 1::4]\n",
        "dh = pred_anchor_locs_numpy[:, 2::4]\n",
        "dw = pred_anchor_locs_numpy[:, 3::4]\n",
        "\n",
        "ctr_y = dy * anc_height[:, np.newaxis] + anc_ctr_y[:, np.newaxis]\n",
        "ctr_x = dx * anc_width[:, np.newaxis] + anc_ctr_x[:, np.newaxis]\n",
        "h = np.exp(dh) * anc_height[:, np.newaxis]\n",
        "w = np.exp(dw) * anc_width[:, np.newaxis]"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WObhL6C9oFWB",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将预测的目标框转换为[y1, x1, y2, x2]格式</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LAyJIfSWOw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "d4f33b35-35e5-4e2a-d6d5-dde9aaa4912b"
      },
      "source": [
        "roi = np.zeros(pred_anchor_locs_numpy.shape, dtype=anchor_locs.dtype)\n",
        "roi[:, 0::4] = ctr_y - 0.5 * h\n",
        "roi[:, 1::4] = ctr_x - 0.5 * w\n",
        "roi[:, 2::4] = ctr_y + 0.5 * h\n",
        "roi[:, 3::4] = ctr_x + 0.5 * w\n",
        "print(roi)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -37.254834    -82.50966799   53.254834     98.50966799]\n",
            " [ -82.50966799 -173.01933598   98.50966799  189.01933598]\n",
            " [-173.01933598 -354.03867197  189.01933598  370.03867197]\n",
            " ...\n",
            " [ 701.49033201  746.745166    882.50966799  837.254834  ]\n",
            " [ 610.98066402  701.49033201  973.01933598  882.50966799]\n",
            " [ 429.96132803  610.98066402 1154.03867197  973.01933598]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvxn5DPUuRNR",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>剪辑预测框，超出输入图坐标范围的部分自动转化为边界</font>  \n",
        "<font face=楷体 color=green size=5>绿色链接：\n",
        "</font>  \n",
        "<font face=楷体>\n",
        "【1】[Python slice() 函数](https://zixuephp.net/manual-python3-1716.html)  \n",
        "【2】[np.clip截取函数](https://www.cnblogs.com/cloud-ken/p/9946341.html)\n",
        "</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f23upQ9UWYG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "0866c9bc-e005-463c-98a3-55369e77e5ac"
      },
      "source": [
        "img_size = (800, 800) #Image size\n",
        "roi[:, slice(0, 4, 2)] = np.clip(\n",
        "           roi[:, slice(0, 4, 2)], 0, img_size[0])  # slice(start, stop, step) clip(a, a_min, a_max, out=None)\n",
        "roi[:, slice(1, 4, 2)] = np.clip(\n",
        "   roi[:, slice(1, 4, 2)], 0, img_size[1])\n",
        "\n",
        "print(roi)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.           0.          53.254834    98.50966799]\n",
            " [  0.           0.          98.50966799 189.01933598]\n",
            " [  0.           0.         189.01933598 370.03867197]\n",
            " ...\n",
            " [701.49033201 746.745166   800.         800.        ]\n",
            " [610.98066402 701.49033201 800.         800.        ]\n",
            " [429.96132803 610.98066402 800.         800.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcB215N1ui5a",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>去除高度或宽度 < threshold的预测框(去掉一些极小框)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgxli4l_Wzfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d32d720b-17c3-4575-e0f3-6a5dfb5f9180"
      },
      "source": [
        "hs = roi[:, 2] - roi[:, 0]\n",
        "ws = roi[:, 3] - roi[:, 1]\n",
        "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
        "roi = roi[keep, :]\n",
        "score = objectness_score_numpy[keep]\n",
        "\n",
        "print(score.shape)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRdA4GFHW3fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "beeb9c53-714c-40af-b8c4-7e9c8b7e7a6e"
      },
      "source": [
        "order = score.ravel().argsort()[::-1]  # # 按分数从高到低排序所有的\n",
        "print(order)\n",
        "print(order.shape)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22499  7502  7494 ... 15003 15004     0]\n",
            "(22500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g8TrMkqu-Ws",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>取前几个预测框pre_nms_topN(如训练时12000，测试时300)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcJsd6_MXIdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "07bb1396-85ae-406a-e3e1-2d8d4c882465"
      },
      "source": [
        "order = order[:n_train_pre_nms]\n",
        "roi = roi[order, :]\n",
        "\n",
        "print(roi.shape)\n",
        "print(roi)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12000, 4)\n",
            "[[429.96132803 610.98066402 800.         800.        ]\n",
            " [280.           8.         792.         520.        ]\n",
            " [429.49033201 218.745166   610.50966799 309.254834  ]\n",
            " ...\n",
            " [  0.         514.98066402 562.03867197 800.        ]\n",
            " [125.49033201 514.98066402 306.50966799 800.        ]\n",
            " [  0.         333.96132803 317.01933598 800.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVAdCGy67pLO",
        "colab_type": "text"
      },
      "source": [
        "#### NMS\n",
        "<font face=楷体>去除和极大值anchor框IOU大于0.7的框(去重)，保留score大，且基本不重叠的框</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot_EYdhHXPom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ea6f0197-a929-4968-9c9a-d23ed5955629"
      },
      "source": [
        "y1 = roi[:, 0]\n",
        "x1 = roi[:, 1]\n",
        "y2 = roi[:, 2]\n",
        "x2 = roi[:, 3]\n",
        "\n",
        "areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "print(order.shape)\n",
        "score = score[order]\n",
        "order = score.argsort()[::-1]  \n",
        "print(order)\n",
        "keep = []\n",
        "while order.size > 0:\n",
        "   i = order[0]\n",
        "   keep.append(i)\n",
        "   xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "   yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "   xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "   yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "  \n",
        "   w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "   h = np.maximum(0.0, yy2 - yy1 + 1)    \n",
        "   inter = w * h\n",
        "   ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "   \n",
        "   inds = np.where(ovr <= nms_thresh)[0]\n",
        "   order = order[inds + 1]  # 最大的作为目标框，从第二大的开始算iou\n",
        "\n",
        "\n",
        "keep = keep[:n_train_post_nms]  # while training/testing , use accordingly\n",
        "roi = roi[keep]  # the final region proposals\n",
        "print(roi.shape)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12000,)\n",
            "[11999  3996  4005 ...  7995  7994     0]\n",
            "(1758, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r5L4lZ2sYjI",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体><font color=skyblue>n_sample</font>：roi中采样的样本数目，默认为128  \n",
        "<font color=skyblue>pos_ratio</font>：n_samples中的正样本的比例，默认为0.25   \n",
        "<font color=skyblue>pos_iou_thresh</font>：设置为正样本region proposal与ground-truth目标之间最小的重叠值阈值  \n",
        "<font color=skyblue>[neg_iou_threshold_lo, neg_iou_threshold_hi]</font> : [0.0, 0.5], 设置为负样本[背景]的重叠值阈值  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlQywwtRXTRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_sample = 128\n",
        "pos_ratio = 0.25\n",
        "pos_iou_thresh = 0.5\n",
        "neg_iou_thresh_hi = 0.5\n",
        "neg_iou_thresh_lo = 0.0  # 可作一定调节，如0.01，相当于挑选出较为困难的样本训练（样本在目标附近）"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlWQIRY4xey7",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>找到每个ground-truth 目标与region proposal的iou</font> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdAj04iYXnwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05ce457d-0e31-412c-8171-0fabcae329d1"
      },
      "source": [
        "ious = np.empty((len(roi), 2), dtype=np.float32)\n",
        "ious.fill(0)\n",
        "for num1, i in enumerate(roi):\n",
        "   ya1, xa1, ya2, xa2 = i  \n",
        "   anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
        "   for num2, j in enumerate(bbox):\n",
        "       yb1, xb1, yb2, xb2 = j\n",
        "       box_area = (yb2- yb1) * (xb2 - xb1)\n",
        "\n",
        "       inter_x1 = max([xb1, xa1])\n",
        "       inter_y1 = max([yb1, ya1])\n",
        "       inter_x2 = min([xb2, xa2])\n",
        "       inter_y2 = min([yb2, ya2])\n",
        "\n",
        "       if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
        "           iter_area = (inter_y2 - inter_y1) * \\\n",
        "(inter_x2 - inter_x1)\n",
        "           iou = iter_area / (anchor_area+ \\\n",
        "box_area - iter_area)            \n",
        "       else:\n",
        "           iou = 0.\n",
        "\n",
        "       ious[num1, num2] = iou\n",
        "print(ious.shape)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1758, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6TASG5rxzR6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<font face=楷体 color=skyblue>找到与每个region proposal具有较高IoU的ground truth，得到其列索引及相应的IoU</font>   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZEY5MBiXsum",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b78343aa-d25a-4cd8-9b8e-a55cc3e3bf1f"
      },
      "source": [
        "gt_assignment = ious.argmax(axis=1)\n",
        "max_iou = ious.max(axis=1)\n",
        "print(gt_assignment.shape)\n",
        "print(gt_assignment)\n",
        "print(max_iou.shape)\n",
        "print(max_iou)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1758,)\n",
            "[0 0 1 ... 0 0 0]\n",
            "(1758,)\n",
            "[0.17802154 0.17926688 0.04676318 ... 0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0xDzLYO6rTp",
        "colab_type": "text"
      },
      "source": [
        "#### 为每个proposal分配标签"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP9CILLnx9RY",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>分类标签</font>   \n",
        "<font face=楷体>根据ROIs与真实目标框IOU分配类别标签</font>  \n",
        "<font face=楷体><font face=楷体 color=red>注意：</font>这里默认背景标记为0</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJOAHrHOXvWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "635ca980-464b-495f-c241-fa7c2a4ed687"
      },
      "source": [
        "gt_roi_label = labels[gt_assignment]\n",
        "print(gt_roi_label)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 6 8 ... 6 6 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qsZHgnqyvFk",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "根据每个pos_iou_thresh选择前景rois。只保留n_sample*pos_ratio（128*0.25=32）个前景样本，因此如果只得到少于32个正样本，保持原状。如果得到多余32个前景目标，从中采样32个样本\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUDWuAQfXyhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ee233a44-74f0-48f7-f99d-01f589ee6be6"
      },
      "source": [
        "pos_roi_per_image = 32\n",
        "pos_index = np.where(max_iou >= pos_iou_thresh)[0]\n",
        "pos_roi_per_this_image = int(min(pos_roi_per_image, pos_index.size))\n",
        "if pos_index.size > 0:\n",
        "   pos_index = np.random.choice(\n",
        "       pos_index, size=pos_roi_per_this_image, replace=False)\n",
        "print(pos_roi_per_this_image)\n",
        "print(pos_index)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n",
            "[1206  584  130  805   34  895  429  751  369  137  487  135  217   37\n",
            "  762  637  427  409  569]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le7-0XyhzGml",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "针对负[背景]region proposal进行相似处理，如果对于之前分配的ground truth目标，region proposal的IoU在neg_iou_thresh_lo和neg_iou_thresh_hi之间，对该region proposal分配0标签，从这些负样本中采样n(n_sample-pos_samples,128-32=96)个region proposals\n",
        "</font>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pbl1KAAGIwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "cfd2943a-7864-4a51-bd22-13ba8da80344"
      },
      "source": [
        "neg_index = np.where((max_iou < neg_iou_thresh_hi) &\n",
        "            (max_iou >= neg_iou_thresh_lo))[0]\n",
        "neg_roi_per_this_image = n_sample - pos_roi_per_this_image\n",
        "neg_roi_per_this_image = int(min(neg_roi_per_this_image, neg_index.size))\n",
        "if  neg_index.size > 0 :\n",
        "   neg_index = np.random.choice(\n",
        "       neg_index, size=neg_roi_per_this_image, replace=False)\n",
        "print(neg_roi_per_this_image)\n",
        "print(neg_index)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109\n",
            "[ 933 1018 1338 1433  269   13 1750 1681  994  614 1387   23  556  834\n",
            " 1268  164 1687 1711 1239 1107  868  256 1498  266  950  454  607  464\n",
            " 1076 1197  891  133  807 1480 1429 1289  186  491 1081 1137 1038 1207\n",
            "  957 1625  557  783  626  816 1638 1580  867  490 1751 1175  822  428\n",
            "  244  764  713 1134 1021   44 1172  725  579 1380  365  821 1409  629\n",
            "  265  179 1082 1157  242 1312 1402 1695  808  687  897   51  481  431\n",
            " 1191  354  889  886 1294  554 1348  523  168  809 1242  380  323  371\n",
            " 1205 1055 1104  645  766  798  169  448  196 1253  338]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpA2nzZTzRWl",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>整合正样本索引和负样本索引，及其各自的标签和region proposals</font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ0IISW9zZ5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49c8fa1d-3dae-4ead-bacd-c5060f42f5e2"
      },
      "source": [
        "keep_index = np.append(pos_index, neg_index)\n",
        "gt_roi_labels = gt_roi_label[keep_index]\n",
        "gt_roi_labels[pos_roi_per_this_image:] = 0  # negative labels --> 0\n",
        "sample_roi = roi[keep_index]\n",
        "print(sample_roi.shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKPo0Pqzljt",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>对这些sample_roi选择ground truth目标之后按照为anchor boxes分配位置的方式进行参数化</font>\n",
        "$$\\begin{matrix}\n",
        "&t_{x} = (x - x_{a})/w_{a} \n",
        "&t_{y} = (y - y_{a})/h_{a}\\\\\n",
        "&t_{w} = \\log(w/ w_a)\n",
        "&t_{h} = \\log(h/ h_a)\n",
        "\\end{matrix}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0KZoJUVzdhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "163a0787-0e54-4975-e8af-807bf835a5bf"
      },
      "source": [
        "# 根据预测框和对应目标框，计算参数（平移参数：dy, dx； 缩放参数：dh, dw）\n",
        "bbox_for_sampled_roi = bbox[gt_assignment[keep_index]]  # 标签对应的目标框\n",
        "print(bbox_for_sampled_roi.shape)\n",
        "#Out\n",
        "#(128, 4)\n",
        "height = sample_roi[:, 2] - sample_roi[:, 0]\n",
        "width = sample_roi[:, 3] - sample_roi[:, 1]\n",
        "ctr_y = sample_roi[:, 0] + 0.5 * height\n",
        "ctr_x = sample_roi[:, 1] + 0.5 * width\n",
        "base_height = bbox_for_sampled_roi[:, 2] - bbox_for_sampled_roi[:, 0]\n",
        "base_width = bbox_for_sampled_roi[:, 3] - bbox_for_sampled_roi[:, 1]\n",
        "base_ctr_y = bbox_for_sampled_roi[:, 0] + 0.5 * base_height\n",
        "base_ctr_x = bbox_for_sampled_roi[:, 1] + 0.5 * base_width"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9fbG0tgzdep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e62cd4ec-ae7b-4e0b-b80a-23b09bb84671"
      },
      "source": [
        "eps = np.finfo(height.dtype).eps\n",
        "height = np.maximum(height, eps)\n",
        "width = np.maximum(width, eps)\n",
        "\n",
        "dy = (base_ctr_y - ctr_y) / height\n",
        "dx = (base_ctr_x - ctr_x) / width\n",
        "dh = np.log(base_height / height)\n",
        "dw = np.log(base_width / width)\n",
        "\n",
        "gt_roi_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
        "print(gt_roi_locs.shape)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOBpUL7qQ1nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rois = torch.from_numpy(sample_roi).float()"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9WglnaTQweo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b743a03-ab2b-49fb-d08a-044e42ca9192"
      },
      "source": [
        "roi_indices = 0 * np.ones((len(rois),), dtype=np.int32) # 图片索引号，这里只有一张直接为0\n",
        "roi_indices = torch.from_numpy(roi_indices).float()\n",
        "print(rois.shape, roi_indices.shape)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 4]) torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DnYgTLF00pB",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>合并 rois and roi_indices, 得到维度为[N, 5] (index, x, y, h, w)的张量<font color=yellow>作为下一步Fast RCNN的训练标签</font>  \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFsG5AoazdY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4643
        },
        "outputId": "849598a5-00d9-415a-de48-b3069d3bcf39"
      },
      "source": [
        "indices_and_rois = torch.cat([roi_indices[:, None], rois], dim=1)\n",
        "print(indices_and_rois)\n",
        "xy_indices_and_rois = indices_and_rois[:, [0, 2, 1, 4, 3]]  # 调整列的次序\n",
        "print(xy_indices_and_rois)\n",
        "indices_and_rois = xy_indices_and_rois.contiguous()\n",
        "print(xy_indices_and_rois.shape)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  0.0000,   0.0000,   2.9807, 466.0387, 365.0193],\n",
            "        [  0.0000,   0.0000,  40.0000, 360.0000, 552.0000],\n",
            "        [  0.0000,   0.0000, 146.9807, 562.0387, 509.0193],\n",
            "        [  0.0000,  82.9807,   0.0000, 445.0193, 594.0387],\n",
            "        [  0.0000,   0.0000, 136.0000, 408.0000, 648.0000],\n",
            "        [  0.0000,   0.0000,  34.9807, 578.0387, 397.0193],\n",
            "        [  0.0000,   0.0000,   0.0000, 360.0000, 328.0000],\n",
            "        [  0.0000,  24.0000,   8.0000, 536.0000, 520.0000],\n",
            "        [  0.0000,  98.9807,   0.0000, 461.0193, 434.0387],\n",
            "        [  0.0000,  34.9807,   0.0000, 397.0193, 690.0387],\n",
            "        [  0.0000,   0.0000,  56.0000, 264.0000, 568.0000],\n",
            "        [  0.0000,   0.0000,  72.0000, 488.0000, 584.0000],\n",
            "        [  0.0000,   0.0000, 178.9807, 386.0387, 541.0193],\n",
            "        [  0.0000,   0.0000,  29.9613, 333.0193, 754.0387],\n",
            "        [  0.0000,   0.0000,  82.9807, 466.0387, 445.0193],\n",
            "        [  0.0000,   0.0000,  98.9807, 626.0387, 461.0193],\n",
            "        [  0.0000,   0.0000,   0.0000, 269.0193, 434.0387],\n",
            "        [  0.0000,  18.9807,   0.0000, 381.0193, 434.0387],\n",
            "        [  0.0000,   0.0000, 114.9807, 370.0387, 477.0193],\n",
            "        [  0.0000, 248.0000,  88.0000, 504.0000, 344.0000],\n",
            "        [  0.0000, 557.4904,   0.0000, 738.5096, 301.0193],\n",
            "        [  0.0000,  61.4903, 650.7452, 242.5097, 741.2548],\n",
            "        [  0.0000, 317.4903,  90.7452, 498.5097, 181.2548],\n",
            "        [  0.0000, 173.4903, 210.9807, 354.5097, 573.0193],\n",
            "        [  0.0000, 301.4903, 194.9807, 482.5097, 557.0193],\n",
            "        [  0.0000, 616.0000,   0.0000, 744.0000,  88.0000],\n",
            "        [  0.0000, 376.0000,  88.0000, 504.0000, 216.0000],\n",
            "        [  0.0000, 104.0000,  56.0000, 232.0000, 184.0000],\n",
            "        [  0.0000, 338.9807, 125.4903, 701.0193, 306.5097],\n",
            "        [  0.0000, 552.0000,  72.0000, 680.0000, 200.0000],\n",
            "        [  0.0000,  77.4903, 346.7452, 258.5097, 437.2548],\n",
            "        [  0.0000, 392.0000, 216.0000, 520.0000, 344.0000],\n",
            "        [  0.0000, 632.0000, 104.0000, 800.0000, 360.0000],\n",
            "        [  0.0000, 648.0000, 600.0000, 776.0000, 728.0000],\n",
            "        [  0.0000, 605.4904, 194.9807, 786.5096, 557.0193],\n",
            "        [  0.0000, 418.9807,  77.4903, 781.0193, 258.5097],\n",
            "        [  0.0000, 301.4903,   0.0000, 482.5097,  53.2548],\n",
            "        [  0.0000,   0.0000, 424.0000, 264.0000, 800.0000],\n",
            "        [  0.0000, 410.7452,  13.4903, 501.2548, 194.5097],\n",
            "        [  0.0000, 370.9807, 269.4903, 733.0193, 450.5097],\n",
            "        [  0.0000, 410.7452, 301.4903, 501.2548, 482.5097],\n",
            "        [  0.0000, 386.9807,   0.0000, 749.0193, 162.5097],\n",
            "        [  0.0000, 616.0000, 328.0000, 744.0000, 456.0000],\n",
            "        [  0.0000,   0.0000, 170.7452, 130.5097, 261.2548],\n",
            "        [  0.0000, 648.0000, 232.0000, 776.0000, 360.0000],\n",
            "        [  0.0000, 490.7452, 189.4903, 581.2548, 370.5097],\n",
            "        [  0.0000, 589.4904, 250.7452, 770.5096, 341.2548],\n",
            "        [  0.0000, 189.4903,  58.7452, 370.5097, 149.2548],\n",
            "        [  0.0000,  61.4903, 154.7452, 242.5097, 245.2548],\n",
            "        [  0.0000, 602.7452, 125.4903, 693.2548, 306.5097],\n",
            "        [  0.0000, 120.0000, 264.0000, 248.0000, 392.0000],\n",
            "        [  0.0000,  45.4903, 186.7452, 226.5097, 277.2548],\n",
            "        [  0.0000,  90.7452,   0.0000, 181.2548, 114.5097],\n",
            "        [  0.0000, 392.0000,  72.0000, 520.0000, 200.0000],\n",
            "        [  0.0000, 472.0000, 600.0000, 600.0000, 728.0000],\n",
            "        [  0.0000, 570.7452, 221.4903, 661.2548, 402.5097],\n",
            "        [  0.0000,   0.0000, 264.0000, 120.0000, 392.0000],\n",
            "        [  0.0000, 573.4904,  58.7452, 754.5096, 149.2548],\n",
            "        [  0.0000, 616.0000, 120.0000, 744.0000, 248.0000],\n",
            "        [  0.0000, 162.9807,  93.4903, 525.0193, 274.5097],\n",
            "        [  0.0000, 202.7452,  93.4903, 293.2548, 274.5097],\n",
            "        [  0.0000, 610.9807, 109.4903, 800.0000, 290.5097],\n",
            "        [  0.0000, 648.0000,   8.0000, 776.0000, 136.0000],\n",
            "        [  0.0000, 410.7452, 189.4903, 501.2548, 370.5097],\n",
            "        [  0.0000, 568.0000, 184.0000, 696.0000, 312.0000],\n",
            "        [  0.0000, 365.4903,  34.9807, 546.5096, 397.0193],\n",
            "        [  0.0000,  72.0000, 168.0000, 200.0000, 296.0000],\n",
            "        [  0.0000, 408.0000,  24.0000, 536.0000, 152.0000],\n",
            "        [  0.0000, 381.4903,  10.7452, 562.5096, 101.2548],\n",
            "        [  0.0000, 616.0000, 296.0000, 744.0000, 424.0000],\n",
            "        [  0.0000,   0.0000, 146.9807, 178.5097, 509.0193],\n",
            "        [  0.0000, 381.4903,   0.0000, 562.5096,  69.2548],\n",
            "        [  0.0000,  24.0000, 120.0000, 152.0000, 248.0000],\n",
            "        [  0.0000, 266.7452, 141.4903, 357.2548, 322.5097],\n",
            "        [  0.0000,  74.7452,   0.0000, 165.2548, 162.5097],\n",
            "        [  0.0000,   8.0000, 312.0000, 136.0000, 440.0000],\n",
            "        [  0.0000, 461.4903, 202.7452, 642.5096, 293.2548],\n",
            "        [  0.0000, 429.4903, 218.7452, 610.5096, 309.2548],\n",
            "        [  0.0000, 682.7452,  93.4903, 773.2548, 274.5097],\n",
            "        [  0.0000, 301.4903,  74.7452, 482.5097, 165.2548],\n",
            "        [  0.0000,   0.0000, 210.9807, 146.5097, 573.0193],\n",
            "        [  0.0000, 746.7452,  77.4903, 800.0000, 258.5097],\n",
            "        [  0.0000, 394.7452, 173.4903, 485.2548, 354.5097],\n",
            "        [  0.0000, 141.4903, 250.7452, 322.5097, 341.2548],\n",
            "        [  0.0000, 216.0000,  88.0000, 344.0000, 216.0000],\n",
            "        [  0.0000, 474.7452,   0.0000, 565.2548, 162.5097],\n",
            "        [  0.0000, 104.0000, 168.0000, 232.0000, 296.0000],\n",
            "        [  0.0000, 650.7452,  45.4903, 741.2548, 226.5097],\n",
            "        [  0.0000, 296.0000,  88.0000, 552.0000, 344.0000],\n",
            "        [  0.0000, 730.7452, 301.4903, 800.0000, 482.5097],\n",
            "        [  0.0000, 557.4904, 266.7452, 738.5096, 357.2548],\n",
            "        [  0.0000, 685.4904,  58.7452, 800.0000, 149.2548],\n",
            "        [  0.0000, 728.0000,  88.0000, 800.0000, 216.0000],\n",
            "        [  0.0000,   0.0000, 330.7452, 146.5097, 421.2548],\n",
            "        [  0.0000, 226.9807, 301.9613, 589.0193, 800.0000],\n",
            "        [  0.0000, 218.7452,  61.4903, 309.2548, 242.5097],\n",
            "        [  0.0000,  29.4903, 122.7452, 210.5097, 213.2548],\n",
            "        [  0.0000,  56.0000, 104.0000, 312.0000, 360.0000],\n",
            "        [  0.0000, 664.0000, 184.0000, 792.0000, 312.0000],\n",
            "        [  0.0000, 525.4904, 154.7452, 706.5096, 245.2548],\n",
            "        [  0.0000,   0.0000, 264.0000, 168.0000, 520.0000],\n",
            "        [  0.0000,   0.0000, 237.4903,  85.2548, 418.5097],\n",
            "        [  0.0000,   0.0000,  26.7452, 178.5097, 117.2548],\n",
            "        [  0.0000, 365.4903, 138.7452, 546.5096, 229.2548],\n",
            "        [  0.0000,  29.9613,  18.9807, 754.0387, 381.0193],\n",
            "        [  0.0000, 586.7452, 141.4903, 677.2548, 322.5097],\n",
            "        [  0.0000, 410.7452, 141.4903, 501.2548, 322.5097],\n",
            "        [  0.0000, 322.9807, 573.4904, 685.0193, 754.5096],\n",
            "        [  0.0000, 333.4903, 234.7452, 514.5096, 325.2548],\n",
            "        [  0.0000, 456.0000, 584.0000, 584.0000, 712.0000],\n",
            "        [  0.0000, 152.0000, 248.0000, 280.0000, 376.0000],\n",
            "        [  0.0000, 514.9807, 253.4903, 800.0000, 434.5097],\n",
            "        [  0.0000,   0.0000,  50.9807, 178.5097, 413.0193],\n",
            "        [  0.0000,   0.0000, 317.9613, 189.0193, 800.0000],\n",
            "        [  0.0000, 226.9807,   0.0000, 589.0193, 434.0387],\n",
            "        [  0.0000, 525.4904, 282.7452, 706.5096, 373.2548],\n",
            "        [  0.0000, 205.4903,   0.0000, 386.5097, 253.0193],\n",
            "        [  0.0000,  56.0000, 120.0000, 184.0000, 248.0000],\n",
            "        [  0.0000, 157.4903,  74.7452, 338.5097, 165.2548],\n",
            "        [  0.0000, 426.7452,  29.4903, 517.2548, 210.5097],\n",
            "        [  0.0000, 184.0000, 216.0000, 312.0000, 344.0000],\n",
            "        [  0.0000, 173.9613,  66.9807, 800.0000, 429.0193],\n",
            "        [  0.0000, 162.9807, 141.4903, 525.0193, 322.5097],\n",
            "        [  0.0000, 605.4904, 298.7452, 786.5096, 389.2548],\n",
            "        [  0.0000, 637.4904,  10.7452, 800.0000, 101.2548],\n",
            "        [  0.0000, 653.4904, 298.7452, 800.0000, 389.2548],\n",
            "        [  0.0000, 653.4904, 482.9807, 800.0000, 800.0000],\n",
            "        [  0.0000, 306.9807, 253.4903, 669.0193, 434.5097]])\n",
            "tensor([[  0.0000,   2.9807,   0.0000, 365.0193, 466.0387],\n",
            "        [  0.0000,  40.0000,   0.0000, 552.0000, 360.0000],\n",
            "        [  0.0000, 146.9807,   0.0000, 509.0193, 562.0387],\n",
            "        [  0.0000,   0.0000,  82.9807, 594.0387, 445.0193],\n",
            "        [  0.0000, 136.0000,   0.0000, 648.0000, 408.0000],\n",
            "        [  0.0000,  34.9807,   0.0000, 397.0193, 578.0387],\n",
            "        [  0.0000,   0.0000,   0.0000, 328.0000, 360.0000],\n",
            "        [  0.0000,   8.0000,  24.0000, 520.0000, 536.0000],\n",
            "        [  0.0000,   0.0000,  98.9807, 434.0387, 461.0193],\n",
            "        [  0.0000,   0.0000,  34.9807, 690.0387, 397.0193],\n",
            "        [  0.0000,  56.0000,   0.0000, 568.0000, 264.0000],\n",
            "        [  0.0000,  72.0000,   0.0000, 584.0000, 488.0000],\n",
            "        [  0.0000, 178.9807,   0.0000, 541.0193, 386.0387],\n",
            "        [  0.0000,  29.9613,   0.0000, 754.0387, 333.0193],\n",
            "        [  0.0000,  82.9807,   0.0000, 445.0193, 466.0387],\n",
            "        [  0.0000,  98.9807,   0.0000, 461.0193, 626.0387],\n",
            "        [  0.0000,   0.0000,   0.0000, 434.0387, 269.0193],\n",
            "        [  0.0000,   0.0000,  18.9807, 434.0387, 381.0193],\n",
            "        [  0.0000, 114.9807,   0.0000, 477.0193, 370.0387],\n",
            "        [  0.0000,  88.0000, 248.0000, 344.0000, 504.0000],\n",
            "        [  0.0000,   0.0000, 557.4904, 301.0193, 738.5096],\n",
            "        [  0.0000, 650.7452,  61.4903, 741.2548, 242.5097],\n",
            "        [  0.0000,  90.7452, 317.4903, 181.2548, 498.5097],\n",
            "        [  0.0000, 210.9807, 173.4903, 573.0193, 354.5097],\n",
            "        [  0.0000, 194.9807, 301.4903, 557.0193, 482.5097],\n",
            "        [  0.0000,   0.0000, 616.0000,  88.0000, 744.0000],\n",
            "        [  0.0000,  88.0000, 376.0000, 216.0000, 504.0000],\n",
            "        [  0.0000,  56.0000, 104.0000, 184.0000, 232.0000],\n",
            "        [  0.0000, 125.4903, 338.9807, 306.5097, 701.0193],\n",
            "        [  0.0000,  72.0000, 552.0000, 200.0000, 680.0000],\n",
            "        [  0.0000, 346.7452,  77.4903, 437.2548, 258.5097],\n",
            "        [  0.0000, 216.0000, 392.0000, 344.0000, 520.0000],\n",
            "        [  0.0000, 104.0000, 632.0000, 360.0000, 800.0000],\n",
            "        [  0.0000, 600.0000, 648.0000, 728.0000, 776.0000],\n",
            "        [  0.0000, 194.9807, 605.4904, 557.0193, 786.5096],\n",
            "        [  0.0000,  77.4903, 418.9807, 258.5097, 781.0193],\n",
            "        [  0.0000,   0.0000, 301.4903,  53.2548, 482.5097],\n",
            "        [  0.0000, 424.0000,   0.0000, 800.0000, 264.0000],\n",
            "        [  0.0000,  13.4903, 410.7452, 194.5097, 501.2548],\n",
            "        [  0.0000, 269.4903, 370.9807, 450.5097, 733.0193],\n",
            "        [  0.0000, 301.4903, 410.7452, 482.5097, 501.2548],\n",
            "        [  0.0000,   0.0000, 386.9807, 162.5097, 749.0193],\n",
            "        [  0.0000, 328.0000, 616.0000, 456.0000, 744.0000],\n",
            "        [  0.0000, 170.7452,   0.0000, 261.2548, 130.5097],\n",
            "        [  0.0000, 232.0000, 648.0000, 360.0000, 776.0000],\n",
            "        [  0.0000, 189.4903, 490.7452, 370.5097, 581.2548],\n",
            "        [  0.0000, 250.7452, 589.4904, 341.2548, 770.5096],\n",
            "        [  0.0000,  58.7452, 189.4903, 149.2548, 370.5097],\n",
            "        [  0.0000, 154.7452,  61.4903, 245.2548, 242.5097],\n",
            "        [  0.0000, 125.4903, 602.7452, 306.5097, 693.2548],\n",
            "        [  0.0000, 264.0000, 120.0000, 392.0000, 248.0000],\n",
            "        [  0.0000, 186.7452,  45.4903, 277.2548, 226.5097],\n",
            "        [  0.0000,   0.0000,  90.7452, 114.5097, 181.2548],\n",
            "        [  0.0000,  72.0000, 392.0000, 200.0000, 520.0000],\n",
            "        [  0.0000, 600.0000, 472.0000, 728.0000, 600.0000],\n",
            "        [  0.0000, 221.4903, 570.7452, 402.5097, 661.2548],\n",
            "        [  0.0000, 264.0000,   0.0000, 392.0000, 120.0000],\n",
            "        [  0.0000,  58.7452, 573.4904, 149.2548, 754.5096],\n",
            "        [  0.0000, 120.0000, 616.0000, 248.0000, 744.0000],\n",
            "        [  0.0000,  93.4903, 162.9807, 274.5097, 525.0193],\n",
            "        [  0.0000,  93.4903, 202.7452, 274.5097, 293.2548],\n",
            "        [  0.0000, 109.4903, 610.9807, 290.5097, 800.0000],\n",
            "        [  0.0000,   8.0000, 648.0000, 136.0000, 776.0000],\n",
            "        [  0.0000, 189.4903, 410.7452, 370.5097, 501.2548],\n",
            "        [  0.0000, 184.0000, 568.0000, 312.0000, 696.0000],\n",
            "        [  0.0000,  34.9807, 365.4903, 397.0193, 546.5096],\n",
            "        [  0.0000, 168.0000,  72.0000, 296.0000, 200.0000],\n",
            "        [  0.0000,  24.0000, 408.0000, 152.0000, 536.0000],\n",
            "        [  0.0000,  10.7452, 381.4903, 101.2548, 562.5096],\n",
            "        [  0.0000, 296.0000, 616.0000, 424.0000, 744.0000],\n",
            "        [  0.0000, 146.9807,   0.0000, 509.0193, 178.5097],\n",
            "        [  0.0000,   0.0000, 381.4903,  69.2548, 562.5096],\n",
            "        [  0.0000, 120.0000,  24.0000, 248.0000, 152.0000],\n",
            "        [  0.0000, 141.4903, 266.7452, 322.5097, 357.2548],\n",
            "        [  0.0000,   0.0000,  74.7452, 162.5097, 165.2548],\n",
            "        [  0.0000, 312.0000,   8.0000, 440.0000, 136.0000],\n",
            "        [  0.0000, 202.7452, 461.4903, 293.2548, 642.5096],\n",
            "        [  0.0000, 218.7452, 429.4903, 309.2548, 610.5096],\n",
            "        [  0.0000,  93.4903, 682.7452, 274.5097, 773.2548],\n",
            "        [  0.0000,  74.7452, 301.4903, 165.2548, 482.5097],\n",
            "        [  0.0000, 210.9807,   0.0000, 573.0193, 146.5097],\n",
            "        [  0.0000,  77.4903, 746.7452, 258.5097, 800.0000],\n",
            "        [  0.0000, 173.4903, 394.7452, 354.5097, 485.2548],\n",
            "        [  0.0000, 250.7452, 141.4903, 341.2548, 322.5097],\n",
            "        [  0.0000,  88.0000, 216.0000, 216.0000, 344.0000],\n",
            "        [  0.0000,   0.0000, 474.7452, 162.5097, 565.2548],\n",
            "        [  0.0000, 168.0000, 104.0000, 296.0000, 232.0000],\n",
            "        [  0.0000,  45.4903, 650.7452, 226.5097, 741.2548],\n",
            "        [  0.0000,  88.0000, 296.0000, 344.0000, 552.0000],\n",
            "        [  0.0000, 301.4903, 730.7452, 482.5097, 800.0000],\n",
            "        [  0.0000, 266.7452, 557.4904, 357.2548, 738.5096],\n",
            "        [  0.0000,  58.7452, 685.4904, 149.2548, 800.0000],\n",
            "        [  0.0000,  88.0000, 728.0000, 216.0000, 800.0000],\n",
            "        [  0.0000, 330.7452,   0.0000, 421.2548, 146.5097],\n",
            "        [  0.0000, 301.9613, 226.9807, 800.0000, 589.0193],\n",
            "        [  0.0000,  61.4903, 218.7452, 242.5097, 309.2548],\n",
            "        [  0.0000, 122.7452,  29.4903, 213.2548, 210.5097],\n",
            "        [  0.0000, 104.0000,  56.0000, 360.0000, 312.0000],\n",
            "        [  0.0000, 184.0000, 664.0000, 312.0000, 792.0000],\n",
            "        [  0.0000, 154.7452, 525.4904, 245.2548, 706.5096],\n",
            "        [  0.0000, 264.0000,   0.0000, 520.0000, 168.0000],\n",
            "        [  0.0000, 237.4903,   0.0000, 418.5097,  85.2548],\n",
            "        [  0.0000,  26.7452,   0.0000, 117.2548, 178.5097],\n",
            "        [  0.0000, 138.7452, 365.4903, 229.2548, 546.5096],\n",
            "        [  0.0000,  18.9807,  29.9613, 381.0193, 754.0387],\n",
            "        [  0.0000, 141.4903, 586.7452, 322.5097, 677.2548],\n",
            "        [  0.0000, 141.4903, 410.7452, 322.5097, 501.2548],\n",
            "        [  0.0000, 573.4904, 322.9807, 754.5096, 685.0193],\n",
            "        [  0.0000, 234.7452, 333.4903, 325.2548, 514.5096],\n",
            "        [  0.0000, 584.0000, 456.0000, 712.0000, 584.0000],\n",
            "        [  0.0000, 248.0000, 152.0000, 376.0000, 280.0000],\n",
            "        [  0.0000, 253.4903, 514.9807, 434.5097, 800.0000],\n",
            "        [  0.0000,  50.9807,   0.0000, 413.0193, 178.5097],\n",
            "        [  0.0000, 317.9613,   0.0000, 800.0000, 189.0193],\n",
            "        [  0.0000,   0.0000, 226.9807, 434.0387, 589.0193],\n",
            "        [  0.0000, 282.7452, 525.4904, 373.2548, 706.5096],\n",
            "        [  0.0000,   0.0000, 205.4903, 253.0193, 386.5097],\n",
            "        [  0.0000, 120.0000,  56.0000, 248.0000, 184.0000],\n",
            "        [  0.0000,  74.7452, 157.4903, 165.2548, 338.5097],\n",
            "        [  0.0000,  29.4903, 426.7452, 210.5097, 517.2548],\n",
            "        [  0.0000, 216.0000, 184.0000, 344.0000, 312.0000],\n",
            "        [  0.0000,  66.9807, 173.9613, 429.0193, 800.0000],\n",
            "        [  0.0000, 141.4903, 162.9807, 322.5097, 525.0193],\n",
            "        [  0.0000, 298.7452, 605.4904, 389.2548, 786.5096],\n",
            "        [  0.0000,  10.7452, 637.4904, 101.2548, 800.0000],\n",
            "        [  0.0000, 298.7452, 653.4904, 389.2548, 800.0000],\n",
            "        [  0.0000, 482.9807, 653.4904, 800.0000, 800.0000],\n",
            "        [  0.0000, 253.4903, 306.9807, 434.5097, 669.0193]])\n",
            "torch.Size([128, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FOX6bFb05qe",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将rois映射回feature map，取出rois对应的feature map，然后传到roi_pooling层（7 x 7）</font>\n",
        "\n",
        "<font face=楷体 color=green size=5>绿色链接：</font>\n",
        "\n",
        "<font face=楷体>【1】[pytorch中torch.narrow()函数](https://www.cnblogs.com/qinduanyinghua/p/11862641.html)  \n",
        "【2】[python中[...,1]与[...,1:2]](https://blog.csdn.net/weixin_41637329/article/details/88362345)\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvti5QXyzdVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = (7, 7)\n",
        "adaptive_max_pool = torch.nn.AdaptiveMaxPool2d(size[0], size[1])\n",
        "output = []\n",
        "rois = indices_and_rois.data.float()\n",
        "rois[:, 1:].mul_(1/16.0)  # Subsampling ratio\n",
        "rois = rois.long()  # 取整\n",
        "num_rois = rois.size(0)\n",
        "for i in range(num_rois):\n",
        "   roi = rois[i]\n",
        "   im_idx = roi[0]  # tensor(0)\n",
        "   # [..., roi[2]:(roi[4]+1), roi[1]:(roi[3]+1)]：在特征图谱上得到roi对应的特征图\n",
        "   im = out_map.narrow(0, im_idx, 1)[..., roi[2]:(roi[4]+1), roi[1]:(roi[3]+1)]  # out_map:torch.Size([1, 512, 50, 50])  out_map = faster_rcnn_fe_extractor(image)\n",
        "   #output.append(adaptive_max_pool(im))\n",
        "   output.append(adaptive_max_pool(im)[0].data)  # 修改\n",
        "output = torch.cat(output, 0)\n",
        "print(output.size())\n",
        "#output = torch.stack(output)\n",
        "print(output.shape)\n",
        "#Out:\n",
        "# torch.Size([128, 512, 7, 7])\n",
        "# Reshape the tensor so that we can pass it through the feed forward layer.\n",
        "k = output.view(output.size(0), -1)\n",
        "print(k.shape)\n",
        "#Out:\n",
        "# torch.Size([128, 25088])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woExUKDt1Bk9",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>定义Fast RCNN的classification  和 位置regression网络 </font> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEo8fsBKzdSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roi_head_classifier = nn.Sequential(*[nn.Linear(25088, 4096),\n",
        "                    nn.Linear(4096, 4096)])\n",
        "cls_loc = nn.Linear(4096, 21 * 4) # (VOC 20 classes + 1 background. Each wil\n",
        "cls_loc.weight.data.normal_(0, 0.01)\n",
        "cls_loc.bias.data.zero_()\n",
        "score = nn.Linear(4096, 21) # (VOC 20 classes + 1 background)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yNl6GjQ1UYg",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将roi-pooling的输出传到上面定义的网络</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yowLzkPszcxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7fec57c7-f35c-4a61-8e34-5f7d4be7779d"
      },
      "source": [
        "k = roi_head_classifier(k)\n",
        "roi_cls_loc = cls_loc(k)\n",
        "roi_cls_score = score(k)\n",
        "print(roi_cls_loc.shape, roi_cls_score.shape)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 84]) torch.Size([128, 21])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNC-ySHw1fkk",
        "colab_type": "text"
      },
      "source": [
        "## 损失函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znR21725mVtL",
        "colab_type": "text"
      },
      "source": [
        "#### RPN损失"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RFVcah11d_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f798c2e4-a531-4b38-f9fc-f84c2490deea"
      },
      "source": [
        "print(pred_anchor_locs.shape)  # RPN网络预测的坐标系数\n",
        "print(pred_cls_scores.shape)  # RPN网络预测的类别\n",
        "print(anchor_locations.shape)   # anchor对应的实际坐标系数\n",
        "print(anchor_labels.shape)  # anchor的实际类别"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 22500, 4])\n",
            "torch.Size([1, 22500, 2])\n",
            "(22500, 4)\n",
            "(22500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFzuDZeH24BC",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>重新排列，将输入和输出排成一行</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iVcPOV61d7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebb6fac6-9364-4c75-e27c-22c51184487c"
      },
      "source": [
        "rpn_loc = pred_anchor_locs[0]\n",
        "rpn_score = pred_cls_scores[0]\n",
        "gt_rpn_loc = torch.from_numpy(anchor_locations)\n",
        "gt_rpn_score = torch.from_numpy(anchor_labels)\n",
        "print(rpn_loc.shape, rpn_score.shape, gt_rpn_loc.shape, gt_rpn_score.shape)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([22500, 4]) torch.Size([22500, 2]) torch.Size([22500, 4]) torch.Size([22500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT1tBGgC2_8R",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>pred_cls_scores 和 anchor_labels 是RPN网络的预测对象值和实际对象值  \n",
        "对classification用Cross Entropy损失:</font>\n",
        "$$H(y)=(-1)*\\sum_iy_i*\\log(y_i)\\\\\n",
        "Softmax = e^{l_{ina}}/(\\sum^3_{a=1}e^{O_{ina}})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6iEbQoN37HP",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>用Pytorch计算损失  \n",
        "rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_score.long(), ignore_index = -1)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcOEyCO31d4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91f60e8a-af0c-452d-c158-d04f2dd63a73"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "#gt_rpn_score = torch.autograd.Variable(gt_rpn_score.long())\n",
        "rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_score.long(), ignore_index = -1)\n",
        "print(rpn_cls_loss)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6931, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3bPcGlr3_Pm",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "对于 Regression 用smooth L1 损失:\n",
        "$$\\begin{aligned}\n",
        "L_{Loc}(t^u,v)&=\\sum_{i\\in x,y,w,h}smooth_{L_1}(t^u_i-V_i)\\\\\n",
        "smooth_{L_1} &=\\left\\{ \\begin{aligned} 0.5*x^2 \\quad if |x|<1\\\\\n",
        "|x|-0.5 \\quad otherwise\\end{aligned}\\right.\n",
        "\\end{aligned}$$\n",
        "\n",
        "使用 L1 而不是 L2 损失，是因为RPN的预测回归头的值不是有限的。 Regression 损失也被应用在有正标签的边界区域中：\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HWFpWAO1d0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "89f91898-7c72-4e1a-d7fe-84ad975a9a66"
      },
      "source": [
        "pos = gt_rpn_score > 0  # Anchor label大于0\n",
        "print(pos.shape)\n",
        "mask = pos.unsqueeze(1).expand_as(rpn_loc)  # unsqueeze(1)增加维度\n",
        "print(mask.shape)\n",
        "print(mask)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([22500])\n",
            "torch.Size([22500, 4])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        ...,\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVBbBsOU7LYA",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>取有正数标签的边界区域：</font>  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFHMGtKL1dxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e753fd22-3584-4e62-8ead-bf23dd50b67f"
      },
      "source": [
        "mask_loc_preds = rpn_loc[mask].view(-1, 4)\n",
        "mask_loc_targets = gt_rpn_loc[mask].view(-1, 4)\n",
        "print(mask_loc_preds.shape, mask_loc_preds.shape)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([18, 4]) torch.Size([18, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z8nnuyt7N4V",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>regression损失</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prJ_6vBI1dtl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa7d1c67-2431-46e1-da8c-18133a96ba00"
      },
      "source": [
        "x = torch.abs(mask_loc_targets - mask_loc_preds)\n",
        "rpn_loc_loss = ((x < 1).float() * 0.5 * x**2) + ((x >= 1).float() * (x-0.5))\n",
        "print(rpn_loc_loss.sum())"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1629, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHJ3d2Go7YiG",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>合并rpn_cls_loss 和 rpn_reg_loss, 因为class loss 应用在标签框，而交叉损失已归一化，regression loss 之应用在正标签框上，所以要除以正标签框数量，rpn_lambda是一个超参数，使网络更专注于回归任务：</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDD2Zysp7YBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a192fba-ee12-4aed-a783-b033e2f99652"
      },
      "source": [
        "rpn_lambda = 10.  \n",
        "N_reg = (gt_rpn_score >0).float().sum()\n",
        "rpn_loc_loss = rpn_loc_loss.sum() / N_reg\n",
        "rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)\n",
        "print(rpn_loss)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.3392, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnwcjlxc7eOn",
        "colab_type": "text"
      },
      "source": [
        "#### Fast RCNN 损失"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPI5FwBl7rZ8",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>Fast RCNN预测</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaYAQ_wC7X9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "55e5b66d-ec00-4cf8-b2ed-c3bb76581f73"
      },
      "source": [
        "print(roi_cls_loc.shape)\n",
        "print(roi_cls_score.shape)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 84])\n",
            "torch.Size([128, 21])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAHnsR-47unI",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>训练标签 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vBeTFMJ7X50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "18609787-9aca-4fb1-b603-b83775952877"
      },
      "source": [
        "print(gt_roi_locs.shape)\n",
        "print(gt_roi_labels.shape)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 4)\n",
            "(128,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAhWn1nm70TF",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>转化到Torch变量</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3osWlmpD7X2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bba287e-faa5-4f89-a5b1-7661e2a69384"
      },
      "source": [
        "gt_roi_loc = torch.from_numpy(gt_roi_locs)\n",
        "gt_roi_label = torch.from_numpy(np.float32(gt_roi_labels)).long()\n",
        "print(gt_roi_loc.shape, gt_roi_label.shape)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 4]) torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yalIF3SB74Y7",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>分类损失</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if1jzNJI7Xy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "316da184-2f82-4618-bcae-6db15f351fc7"
      },
      "source": [
        "#gt_roi_label = torch.autograd.Variable(gt_roi_label)\n",
        "roi_cls_loss = F.cross_entropy(roi_cls_score, gt_roi_label, ignore_index=-1)\n",
        "print(roi_cls_loss)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.0366, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ib5ZS3I8CUI",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>回归损失  \n",
        "每个ROI位置有21（num_classes+background）预测边界框。只使用带有正标签的边界框（P_i^*）计算损失</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4koMWcO7XvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e3220a42-4b86-4e76-c19b-cb4417ae6031"
      },
      "source": [
        "n_sample = roi_cls_loc.shape[0]\n",
        "roi_loc = roi_cls_loc.view(n_sample, -1, 4)\n",
        "print(roi_loc.shape)\n",
        "#Out:\n",
        "#torch.Size([128, 21, 4])\n",
        "roi_loc = roi_loc[torch.arange(0, n_sample).long(), gt_roi_label]\n",
        "print(roi_loc.shape)\n",
        "#Out:\n",
        "#torch.Size([128, 4])"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 21, 4])\n",
            "torch.Size([128, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itG87bU18Lrq",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>\n",
        "用计算RPN网络回归损失的方法计算回归损失\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE91alEl8GP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "eeb0dd4d-8164-4e8e-88bf-58786e0ec06a"
      },
      "source": [
        "# 用计算RPN网络回归损失的方法计算回归损失\n",
        "# roi_loc_loss = REGLoss(roi_loc, gt_roi_loc)\n",
        "\n",
        "pos = gt_roi_label.data > 0  # Regression 损失也被应用在有正标签的边界区域中\n",
        "mask = pos.unsqueeze(1).expand_as(roi_loc)\n",
        "print(mask.shape)  # (128, 4L)\n",
        "\n",
        "# 现在取有正数标签的边界区域\n",
        "mask_loc_preds = roi_loc[mask].view(-1, 4)\n",
        "mask_loc_targets = gt_roi_loc[mask].view(-1, 4)\n",
        "print(mask_loc_preds.shape, mask_loc_targets.shape)  # ((19L, 4L), (19L, 4L))\n",
        "\n",
        "x = np.abs(mask_loc_targets.numpy() - mask_loc_preds.data.numpy())\n",
        "print (x.shape)  # (19, 4)\n",
        "\n",
        "roi_loc_loss = ((x < 1) * 0.5 * x**2) + ((x >= 1) * (x-0.5))\n",
        "print(roi_loc_loss.sum())  # 1.4645805211187053\n",
        "\n",
        "N_reg = (gt_roi_label > 0).float().sum()\n",
        "N_reg = np.squeeze(N_reg.data.numpy())\n",
        "roi_loc_loss = roi_loc_loss.sum() / N_reg\n",
        "roi_loc_loss = np.float32(roi_loc_loss)\n",
        "print (roi_loc_loss)  # 0.077294916\n",
        "# roi_loc_loss = torch.autograd.Variable(torch.from_numpy(roi_loc_loss))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 4])\n",
            "torch.Size([19, 4]) torch.Size([19, 4])\n",
            "(19, 4)\n",
            "1.4763964655548227\n",
            "0.07770508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h936vHzB8U_4",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>ROI损失总和</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33D2g3fS8GJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "748ea687-90ec-4d37-d7c8-c55816901e80"
      },
      "source": [
        "roi_lambda = 10.\n",
        "#roi_cls_loss = np.squeeze(roi_cls_loss.data.numpy())\n",
        "roi_loss = roi_cls_loss + (roi_lambda * roi_loc_loss)\n",
        "print(roi_loss)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.8137, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXrDUyKH8cbx",
        "colab_type": "text"
      },
      "source": [
        "#### 总损失：RPN+ Fast RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0L3uZuJ8GFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2402941-1533-4f80-f337-d9f5c52a7d7b"
      },
      "source": [
        "total_loss = rpn_loss + roi_loss\n",
        "print(total_loss)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.1529, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}