{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster-RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/master/Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MF2Suorb2s7",
        "colab_type": "text"
      },
      "source": [
        "# <font face=STCAIYUN size=10 color=purple>构建Faster RCNN</font>\n",
        "<font face=楷体 color=skyblue>\n",
        "\n",
        "- Region Proposal network (RPN)  \n",
        "- RPN loss functions  \n",
        "- Region of Interest Pooling (ROI)  \n",
        "- ROI loss functions\n",
        "</font>\n",
        "\n",
        "**<font face=楷体 color=skyblue size=5>训练Faster RCNN时通常的数据流</font>**\n",
        "\n",
        "<font face=楷体>1、从图像中提取特征  \n",
        "2、产生anchor目标  \n",
        "3、RPN网络中得到位置和目标预测分值  \n",
        "4、取前N个坐标及其目标得分即建议层  \n",
        "5、传递前N个坐标通过Fast R-CNN网络，生成4中建议的每个位置的位置和cls预测  \n",
        "6、对4中建议的每个坐标生成建议目标  \n",
        "7、采用2,3计算rpn_cls_loss和rpn_reg_loss  \n",
        "8、采用5,6计算roi_cls_loss和roi_reg_loss  \n",
        "</font>  \n",
        "<font face=楷体 size=5 color=green>绿色链接：</font>  \n",
        "【1】[Guide to build Faster RCNN in PyTorch](https://medium.com/@fractaldle/guide-to-build-faster-rcnn-in-pytorch-95b10c273439)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhVGR8LPdE3R",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>定义一张图像、两个bbox及其标签</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N1cMxogn1ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "image = torch.zeros((1, 3, 800, 800)).float()\n",
        "\n",
        "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]]) # [y1, x1, y2, x2] format\n",
        "labels = torch.LongTensor([6, 8]) # 0 represents background\n",
        "sub_sample = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWIHh_Y73n6G",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>生成一个dummy image并且设置volatile为False</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk7AeHlHS_vt",
        "colab_type": "code",
        "outputId": "6b823761-0e44-45cd-ddd1-a452dcae38d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torchvision\n",
        "dummy_img = torch.zeros((1, 3, 800, 800)).float()\n",
        "print(dummy_img.shape)\n",
        "#Out: torch.Size([1, 3, 800, 800])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 800, 800])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pApvQWCh4oJc",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>列出VGG16的所有层</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCcqJz0lTCjt",
        "colab_type": "code",
        "outputId": "d6f4d6a7-b15a-42a5-f27f-c9a1931d6c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "# model = torchvision.models.vgg16(pretrained=True)\n",
        "model = torchvision.models.vgg16(pretrained=False)\n",
        "fe = list(model.features)\n",
        "# print(fe) # length is 15\n",
        "for layer in fe:\n",
        "    print (layer)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lFie3NZ4zP2",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将图像喂给网络，确定得到相应的输出尺寸</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVXE5KCITE8R",
        "colab_type": "code",
        "outputId": "ed132fee-beda-4f2d-824f-4bc9058a5a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "req_features = []\n",
        "k = dummy_img.clone()\n",
        "for i in fe:\n",
        "    k = i(k)\n",
        "    if k.size()[2] < 800//16:\n",
        "        break\n",
        "    req_features.append(i)\n",
        "    out_channels = k.size()[1]\n",
        "print(len(req_features)) #30\n",
        "print(out_channels) # 512"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frk664ZF5kG5",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将list转换为Sequential module</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CHH7IXETLZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "faster_rcnn_fe_extractor = torch.nn.Sequential(*req_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "betsGKcr5z1x",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>用构建好的VGG16网络提取特征图</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lo6CllBTa7H",
        "colab_type": "code",
        "outputId": "6f0cd456-5452-4bda-d918-b01423d2d76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "out_map = faster_rcnn_fe_extractor(image)\n",
        "print(out_map.size())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512, 50, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g78lFac06K-3",
        "colab_type": "text"
      },
      "source": [
        "## Anchor boxes\n",
        "<font face=楷体>\n",
        "\n",
        "- 在所有feature map的坐标上生成Anchor\n",
        "- 对每个目标分配标签及坐标（相对于anchor）\n",
        "- 在feature map坐标生成Anchor  \n",
        "\n",
        "采用anchor_scales=[8，16，32] ratio=[0.5，1，2] subsampling=16\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5wVFjHR78ax",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>feature map的一个像素位置生成9个anchor boxes，每个像素对应输入图像中的16*16像素</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYCgkuxDKVjF",
        "colab_type": "code",
        "outputId": "134a3301-ef87-491a-cd37-f09bb79c52d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "import numpy as np\n",
        "ratios = [0.5, 1, 2]\n",
        "anchor_scales = [8, 16, 32]\n",
        "\n",
        "anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4), dtype=np.float32)\n",
        "\n",
        "print(anchor_base)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsQyUHHMVw7",
        "colab_type": "code",
        "outputId": "36e00846-60e8-494c-8307-23448c65b2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "ctr_y = sub_sample / 2.\n",
        "ctr_x = sub_sample / 2.\n",
        "print(ctr_y, ctr_x)\n",
        "\n",
        "for i in range(len(ratios)):\n",
        " for j in range(len(anchor_scales)):\n",
        "   h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])    # 输出的feature map的每个像素对应图像中的16*16像素\n",
        "   w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratios[i])  # ration决定了anchor的长宽比例(同面积)\n",
        "\n",
        "   index = i * len(anchor_scales) + j\n",
        "\n",
        "   anchor_base[index, 0] = ctr_y - h / 2.\n",
        "   anchor_base[index, 1] = ctr_x - w / 2.\n",
        "   anchor_base[index, 2] = ctr_y + h / 2.\n",
        "   anchor_base[index, 3] = ctr_x + w / 2.\n",
        "print(anchor_base)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8.0 8.0\n",
            "[[ -37.254833  -82.50967    53.254833   98.50967 ]\n",
            " [ -82.50967  -173.01933    98.50967   189.01933 ]\n",
            " [-173.01933  -354.03867   189.01933   370.03867 ]\n",
            " [ -56.        -56.         72.         72.      ]\n",
            " [-120.       -120.        136.        136.      ]\n",
            " [-248.       -248.        264.        264.      ]\n",
            " [ -82.50967   -37.254833   98.50967    53.254833]\n",
            " [-173.01933   -82.50967   189.01933    98.50967 ]\n",
            " [-354.03867  -173.01933   370.03867   189.01933 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9WZhhRTbGSA",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>feature map的每一个像素位置都要生成9个anchor boxes，每个像素对应输入图像中的16*16像素</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTw56ZpwNCJG",
        "colab_type": "code",
        "outputId": "8237d705-92cf-402e-ee76-7fc8b49cf676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "fe_size = (800//16)\n",
        "ctr_x = np.arange(16, (fe_size+1) * 16, 16)\n",
        "ctr_y = np.arange(16, (fe_size+1) * 16, 16)\n",
        "print (ctr_x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272 288\n",
            " 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560 576\n",
            " 592 608 624 640 656 672 688 704 720 736 752 768 784 800]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlkvqR4Adi57",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将feature map每个像素位置作为锚点并映射回输入图像中</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI3PdJs5OaaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 0\n",
        "ctr  = np.zeros(shape=(len(ctr_x)*len(ctr_y),2))\n",
        "for x in range(len(ctr_x)):\n",
        "   for y in range(len(ctr_y)):\n",
        "       ctr[index, 1] = ctr_x[x] - 8  # 前面生成中心点位置偏移了8个像素点\n",
        "       ctr[index, 0] = ctr_y[y] - 8\n",
        "       index +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRMZoB4yWfGI",
        "colab_type": "code",
        "outputId": "d8183146-62f7-440e-da1f-f5297fc0b533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "anchors = np.zeros(shape=(fe_size * fe_size * 9, 4))  # 共有2500个锚点，每个锚点9个框，每个框4个参数\n",
        "index = 0\n",
        "for c in ctr:\n",
        " ctr_y, ctr_x = c\n",
        " for i in range(len(ratios)):\n",
        "   for j in range(len(anchor_scales)):\n",
        "     h = sub_sample * anchor_scales[j] * np.sqrt(ratios[i])\n",
        "     w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratios[i])\n",
        "     anchors[index, 0] = ctr_y - h / 2.\n",
        "     anchors[index, 1] = ctr_x - w / 2.\n",
        "     anchors[index, 2] = ctr_y + h / 2.\n",
        "     anchors[index, 3] = ctr_x + w / 2.\n",
        "     index += 1\n",
        "print(anchors.shape)\n",
        "#Out: [22500, 4]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22500, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1bWvWvxdJLY",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=5>给anchor分配标签和位置</font>  \n",
        "<font face=楷体>\n",
        "a)与ground-truth-box IoU最大的anchor标记为正标签  \n",
        "b)与ground-truth-box IoU大于0.7的anchor标记为正标签  \n",
        "c)与ground-truth-box IoU小于0.3的anchor标记为负标签  \n",
        "d)其余anchor既不是正样本的也不是负样本，对训练没有帮助  \n",
        "<font color=red>注意：</font>单个ground-truth对象可以为多个anchor分配正标签  \n",
        "</font>\n",
        "<font face=楷体 color=skyblue>通过如下方式对anchor boxes分配标签和位置：</font>   \n",
        "<font face=楷体>\n",
        "1、找到有效的anchor boxes的索引，并且生成索引数组，生成标签数组其形状索引数组填充-1（无效anchor boxes，对应上文说的处在边框外的anchor boxes）。  \n",
        "2、检查是否满足以上a、b、c条件中的一条，并相应填写标签。如果是正anchor box(标签为1)，注意哪个ground-truth目标可以得到这个结果。  \n",
        "3、计算与anchor box相关的ground-truth的位置(loc)。  \n",
        "4、通过为所有无效的anchor box填充-1和为所有有效锚箱计算的值来重新组织所有anchor box。  \n",
        "5、输出应该是(N, 1)数组的标签和带有(N, 4)数组的locs。  \n",
        "6、找到所有有效anchor boxes的索引：\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yzP6Xs2OAQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox = np.asarray([[20, 30, 400, 500], [300, 400, 500, 600]], dtype=np.float32) # [y1, x1, y2, x2] format\n",
        "labels = np.asarray([6, 8], dtype=np.int8) # 0 represents background "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_VLt6dD6R31",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>去除坐标出界的边框，保留图片内的框</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjpMFy5qOE2w",
        "colab_type": "code",
        "outputId": "955062b8-fe90-4bd8-c67c-fd5e55dd4dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "inside_index = np.where(\n",
        "       (anchors[:, 0] >= 0) &\n",
        "       (anchors[:, 1] >= 0) &\n",
        "       (anchors[:, 2] <= 800) &\n",
        "       (anchors[:, 3] <= 800)\n",
        "   )[0]\n",
        "print(inside_index.shape)\n",
        "#Out: (8940,)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0nv-ugX6eV0",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>初始化标签为-1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPuDM6_RSzdg",
        "colab_type": "code",
        "outputId": "46780c9b-05e9-4071-8e90-701928a53bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "label = np.empty((len(inside_index), ), dtype=np.int32)\n",
        "label.fill(-1)\n",
        "print(label.shape)\n",
        "#Out = (8940, )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqCIyc3k62cL",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>获取有效anchor（图片内anchor）坐标</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfBg94s0TJ4Z",
        "colab_type": "code",
        "outputId": "369fa48f-1d23-442b-a452-edb9879b7839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "valid_anchor_boxes = anchors[inside_index]\n",
        "print(valid_anchor_boxes.shape)\n",
        "#Out = (8940, 4)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Urojwf77xLA",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>计算每个anchor框与所有目标框的IOU，这里目标框共2个</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZSL1KcFTVUI",
        "colab_type": "code",
        "outputId": "7008ece5-dceb-4e81-ccdb-2c105e76392b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "ious = np.empty((len(valid_anchor_boxes), 2), dtype=np.float32)\n",
        "ious.fill(0)\n",
        "print(\"两个目标框为：\\n{}\".format(bbox))\n",
        "for num1, i in enumerate(valid_anchor_boxes):\n",
        "   ya1, xa1, ya2, xa2 = i \n",
        "   anchor_area = (ya2 - ya1) * (xa2 - xa1)  # 有效框面积\n",
        "   for num2, j in enumerate(bbox):\n",
        "       yb1, xb1, yb2, xb2 = j\n",
        "       box_area = (yb2- yb1) * (xb2 - xb1)  # 目标框面积\n",
        "\n",
        "       inter_x1 = max([xb1, xa1])\n",
        "       inter_y1 = max([yb1, ya1])\n",
        "       inter_x2 = min([xb2, xa2])\n",
        "       inter_y2 = min([yb2, ya2])\n",
        "       if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
        "           iter_area = (inter_y2 - inter_y1) * \\\n",
        "(inter_x2 - inter_x1)\n",
        "           iou = iter_area / \\\n",
        "(anchor_area + box_area - iter_area) \n",
        "       else:\n",
        "           iou = 0.\n",
        "\n",
        "       ious[num1, num2] = iou\n",
        "print(ious.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "两个目标框为：\n",
            "tensor([[ 20.,  30., 400., 500.],\n",
            "        [300., 400., 500., 600.]])\n",
            "(8940, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvcJ9zabkmkP",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>分别找到与每个gt_box iou最高的 anchor box(两个)</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWg8E-xHThar",
        "colab_type": "code",
        "outputId": "64007105-26d8-451f-c914-1886aed58024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "gt_argmax_ious = ious.argmax(axis=0)\n",
        "print(gt_argmax_ious)\n",
        "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n",
        "print(gt_max_ious)\n",
        "# Out:\n",
        "# [2262 5620]\n",
        "# [0.68130493 0.61035156]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2262 5620]\n",
            "[0.68130493 0.61035156]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBvOPwkclPKv",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>得到每个anchor box与所有ground-truth box中 的最高iou</font> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQrIneFgUN6l",
        "colab_type": "code",
        "outputId": "2b96a252-cc57-41da-caf1-b4f17411dc7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "argmax_ious = ious.argmax(axis=1)\n",
        "print(argmax_ious.shape)\n",
        "print(argmax_ious)\n",
        "max_ious = ious[np.arange(len(inside_index)), argmax_ious]\n",
        "print(max_ious.shape)\n",
        "print(max_ious)\n",
        "# Out:\n",
        "# (22500,)\n",
        "# [0, 1, 0, ..., 1, 0, 0]\n",
        "# [0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940,)\n",
            "[0 0 0 ... 0 0 0]\n",
            "(8940,)\n",
            "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI7btHDJDqT-",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>根据上面获取的目标最大IOU值，获取等于该值的index</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IFkuG7IURfM",
        "colab_type": "code",
        "outputId": "84b1219f-6809-4838-9e03-1ceb6ad5649b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
        "print(ious[np.where(ious == gt_max_ious)])\n",
        "print(gt_argmax_ious)\n",
        "# Out:\n",
        "# [2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
        "#        6120, 6128, 6136, 6358, 6366, 6374, 6382]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.68130493 0.68130493 0.61035156 0.61035156 0.61035156 0.61035156\n",
            " 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156\n",
            " 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156 0.61035156]\n",
            "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
            " 6358 6366 6374 6382]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdsU7-w-Ej_M",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>设置正负样本阈值</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmlR9UOrUfM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_iou_threshold  = 0.7\n",
        "neg_iou_threshold = 0.3\n",
        "\n",
        "label[max_ious < neg_iou_threshold] = 0  # 小于0.3为负样本\n",
        "label[gt_argmax_ious] = 1  # 最大IOU对应anchor为正样本\n",
        "label[max_ious >= pos_iou_threshold] = 1  # 大于0.7为正"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Mbi1UuGZjk",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>设置正负样本比例及总量<font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwju5732UtZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_ratio = 0.5  # 正样本比例\n",
        "n_sample = 256  # 样本总量\n",
        "\n",
        "n_pos = pos_ratio * n_sample  # 正样本数量"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOhtVN-mO086",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>如果正样本数量大于n_pos，则随机抽取n_pos个正样本</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVP0qf5XUwm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "63fbf143-6b74-460b-9899-dab134ff4e43"
      },
      "source": [
        "pos_index = np.where(label == 1)[0]\n",
        "print(np.where(label == 1))\n",
        "print(pos_index)\n",
        "if len(pos_index) > n_pos:\n",
        "   disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace=False)\n",
        "   label[disable_index] = -1"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
            "       6120, 6128, 6136, 6358, 6366, 6374, 6382]),)\n",
            "[2262 2508 5620 5628 5636 5644 5866 5874 5882 5890 6112 6120 6128 6136\n",
            " 6358 6366 6374 6382]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE8B6EWIUzc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_neg = n_sample * np.sum(label == 1)\n",
        "neg_index = np.where(label == 0)[0]\n",
        "if len(neg_index) > n_neg:\n",
        "   disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
        "   label[disable_index] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80E5VzZuU1E9",
        "colab_type": "code",
        "outputId": "b31abb15-3459-4fae-c191-c7a09f4b0b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "print(bbox)  \n",
        "print(argmax_ious)\n",
        "max_iou_bbox = bbox[argmax_ious]\n",
        "print(max_iou_bbox)\n",
        "#Out\n",
        "# [[ 20.,  30., 400., 500.],\n",
        "#  [ 20.,  30., 400., 500.],\n",
        "#  [ 20.,  30., 400., 500.],\n",
        "#  ...,\n",
        "#  [ 20.,  30., 400., 500.],\n",
        "#  [ 20.,  30., 400., 500.],\n",
        "#  [ 20.,  30., 400., 500.]]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 20.,  30., 400., 500.],\n",
            "        [300., 400., 500., 600.]])\n",
            "[0 0 0 ... 0 0 0]\n",
            "tensor([[ 20.,  30., 400., 500.],\n",
            "        [ 20.,  30., 400., 500.],\n",
            "        [ 20.,  30., 400., 500.],\n",
            "        ...,\n",
            "        [ 20.,  30., 400., 500.],\n",
            "        [ 20.,  30., 400., 500.],\n",
            "        [ 20.,  30., 400., 500.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6qOl85AQ-Z-",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>有效anchor的中心点和宽高：ctr_x, ctr_y, width, height  \n",
        "有效anchor对应目标框的中心点和宽高: base_ctr_x, base_ctr_y, base_width, base_height</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV2fy7qeU9Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:, 0]\n",
        "width = valid_anchor_boxes[:, 3] - valid_anchor_boxes[:, 1]\n",
        "ctr_y = valid_anchor_boxes[:, 0] + 0.5 * height\n",
        "ctr_x = valid_anchor_boxes[:, 1] + 0.5 * width\n",
        "\n",
        "base_height = max_iou_bbox[:, 2] - max_iou_bbox[:, 0]\n",
        "base_width = max_iou_bbox[:, 3] - max_iou_bbox[:, 1]\n",
        "base_ctr_y = max_iou_bbox[:, 0] + 0.5 * base_height\n",
        "base_ctr_x = max_iou_bbox[:, 1] + 0.5 * base_width"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqXDjvN_RxYC",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=red>有效anchor转为目标框的系数（dy，dx是平移系数；dh，dw是缩放系数）  \n",
        "【1】[python numpy np.finfo()函数 eps](https://blog.csdn.net/Dontla/article/details/103062246)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDNkIdsVCU5",
        "colab_type": "code",
        "outputId": "5be849d8-463c-413a-87eb-2d1223abe5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "eps = np.finfo(height.dtype).eps  # 代表非负的最小值\n",
        "height = np.maximum(height, eps)\n",
        "width = np.maximum(width, eps)\n",
        "dy = (base_ctr_y - ctr_y) / height\n",
        "dx = (base_ctr_x - ctr_x) / width\n",
        "dh = np.log(base_height / height)\n",
        "dw = np.log(base_width / width)\n",
        "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
        "print(anchor_locs)\n",
        "#Out:\n",
        "# [[ 0.5855727   2.3091455   0.7415673   1.647276  ]\n",
        "#  [ 0.49718437  2.3091455   0.7415673   1.647276  ]\n",
        "#  [ 0.40879607  2.3091455   0.7415673   1.647276  ]\n",
        "#  ...\n",
        "#  [-2.50802    -5.292254    0.7415677   1.6472763 ]\n",
        "#  [-2.5964084  -5.292254    0.7415677   1.6472763 ]\n",
        "#  [-2.6847968  -5.292254    0.7415677   1.6472763 ]]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.5855728   2.30914558  0.7415674   1.64727602]\n",
            " [ 0.49718446  2.30914558  0.7415674   1.64727602]\n",
            " [ 0.40879611  2.30914558  0.7415674   1.64727602]\n",
            " ...\n",
            " [-2.50801936 -5.29225232  0.7415674   1.64727602]\n",
            " [-2.59640771 -5.29225232  0.7415674   1.64727602]\n",
            " [-2.68479606 -5.29225232  0.7415674   1.64727602]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnsFQev4RaaO",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>每个anchor框对应的label（-1：无效anchor，0：负有效anchor，1：正有效anchor）</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qHwQzPUVcr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anchor_labels = np.empty((len(anchors),), dtype=label.dtype)\n",
        "anchor_labels.fill(-1)\n",
        "anchor_labels[inside_index] = label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SkyOD_hVgMT",
        "colab_type": "code",
        "outputId": "6924fc35-d916-4d6a-ba20-808c4114e6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "anchor_locations = np.empty((len(anchors),) + anchors.shape[1:], dtype=anchor_locs.dtype)\n",
        "anchor_locations.fill(0)\n",
        "anchor_locations[inside_index, :] = anchor_locs\n",
        "print(anchor_locs.shape)\n",
        "print(anchor_locations.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8940, 4)\n",
            "(22500, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRYF5x0VlL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "mid_channels = 512\n",
        "in_channels = 512 # depends on the output feature map. in vgg 16 it is equal to 512\n",
        "n_anchor = 9 # Number of anchors at each location\n",
        "conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
        "reg_layer = nn.Conv2d(mid_channels, n_anchor *4, 1, 1, 0)\n",
        "cls_layer = nn.Conv2d(mid_channels, n_anchor *2, 1, 1, 0) ## I will be going to use softmax here. you can equally use sigmoid if u replace 2 with 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ZaPI5jV4fW",
        "colab_type": "code",
        "outputId": "29b728eb-d9bb-4bc4-8ba0-670b2098b852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# conv sliding layer\n",
        "conv1.weight.data.normal_(0, 0.01)\n",
        "conv1.bias.data.zero_()\n",
        "\n",
        "# Regression layer\n",
        "reg_layer.weight.data.normal_(0, 0.01)\n",
        "reg_layer.bias.data.zero_()\n",
        "\n",
        "# classification layer\n",
        "cls_layer.weight.data.normal_(0, 0.01)\n",
        "cls_layer.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg45B-SsV7wo",
        "colab_type": "code",
        "outputId": "8ed52453-364a-4661-c335-b3f0fefce9b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = conv1(out_map) # out_map is obtained in section 1\n",
        "pred_anchor_locs = reg_layer(x)\n",
        "pred_cls_scores = cls_layer(x)\n",
        "\n",
        "print(pred_cls_scores.shape, pred_anchor_locs.shape)\n",
        "\n",
        "#Out:\n",
        "#torch.Size([1, 18, 50, 50]) torch.Size([1, 36, 50, 50])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(torch.Size([1, 18, 50, 50]), torch.Size([1, 36, 50, 50]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSC_aCkCV9oL",
        "colab_type": "code",
        "outputId": "3057fa6d-d854-44a1-e964-40f2d74d5c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
        "print(pred_anchor_locs.shape)\n",
        "\n",
        "#Out: torch.Size([1, 22500, 4])\n",
        "\n",
        "pred_cls_scores = pred_cls_scores.permute(0, 2, 3, 1).contiguous()\n",
        "print(pred_cls_scores.shape)\n",
        "#Out torch.Size([1, 50, 50, 18])\n",
        "\n",
        "objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:, :, :, :, 1].contiguous().view(1, -1)\n",
        "print(objectness_score.shape)\n",
        "#Out torch.Size([1, 22500])\n",
        "\n",
        "pred_cls_scores  = pred_cls_scores.view(1, -1, 2)\n",
        "print(pred_cls_scores.shape)\n",
        "# Out torch.size([1, 22500, 2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 22500, 4])\n",
            "torch.Size([1, 50, 50, 18])\n",
            "torch.Size([1, 22500])\n",
            "torch.Size([1, 22500, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-TKjdbpXEkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nms_thresh = 0.7\n",
        "n_train_pre_nms = 12000\n",
        "n_train_post_nms = 2000\n",
        "n_test_pre_nms = 6000\n",
        "n_test_post_nms = 300\n",
        "min_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYCU_WFQV_0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anc_height = anchors[:, 2] - anchors[:, 0]\n",
        "anc_width = anchors[:, 3] - anchors[:, 1]\n",
        "anc_ctr_y = anchors[:, 0] + 0.5 * anc_height\n",
        "anc_ctr_x = anchors[:, 1] + 0.5 * anc_width"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5X_9U5PWMAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_anchor_locs_numpy = pred_anchor_locs[0].data.numpy()\n",
        "objectness_score_numpy = objectness_score[0].data.numpy()\n",
        "\n",
        "dy = pred_anchor_locs_numpy[:, 0::4]\n",
        "dx = pred_anchor_locs_numpy[:, 1::4]\n",
        "dh = pred_anchor_locs_numpy[:, 2::4]\n",
        "dw = pred_anchor_locs_numpy[:, 3::4]\n",
        "\n",
        "ctr_y = dy * anc_height[:, np.newaxis] + anc_ctr_y[:, np.newaxis]\n",
        "ctr_x = dx * anc_width[:, np.newaxis] + anc_ctr_x[:, np.newaxis]\n",
        "h = np.exp(dh) * anc_height[:, np.newaxis]\n",
        "w = np.exp(dw) * anc_width[:, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LAyJIfSWOw3",
        "colab_type": "code",
        "outputId": "1f014684-5b67-4e50-e937-4a79fe45e1a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "roi = np.zeros(pred_anchor_locs_numpy.shape, dtype=anchor_locs.dtype)\n",
        "roi[:, 0::4] = ctr_y - 0.5 * h\n",
        "roi[:, 1::4] = ctr_x - 0.5 * w\n",
        "roi[:, 2::4] = ctr_y + 0.5 * h\n",
        "roi[:, 3::4] = ctr_x + 0.5 * w\n",
        "print(roi)\n",
        "#Out:\n",
        "# [[ -36.897102,  -80.29519 ,   54.09939 ,  100.40507 ],\n",
        "#  [ -83.12463 , -165.74298 ,   98.67854 ,  188.6116  ],\n",
        "#  [-170.7821  , -378.22214 ,  196.20844 ,  349.81198 ],\n",
        "#  ...,\n",
        "#  [ 696.17816 ,  747.13306 ,  883.4582  ,  836.77747 ],\n",
        "#  [ 621.42114 ,  703.0614  ,  973.04626 ,  885.31226 ],\n",
        "#  [ 432.86267 ,  622.48926 , 1146.7059  ,  982.9209  ]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -36.67576154  -79.27511906   51.64738999  100.11247437]\n",
            " [ -83.70975854 -172.16819977   95.69221742  186.44289897]\n",
            " [-181.49092789 -353.39055923  194.17979089  367.47368701]\n",
            " ...\n",
            " [ 707.64184898  748.10783793  885.99900389  837.87469098]\n",
            " [ 621.36531166  701.43897911  973.33845843  877.71796126]\n",
            " [ 430.30310964  604.16962506 1164.04136903  970.94035367]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f23upQ9UWYG8",
        "colab_type": "code",
        "outputId": "64a52cf1-bfa9-451e-9194-bccb56b4db48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "img_size = (800, 800) #Image size\n",
        "roi[:, slice(0, 4, 2)] = np.clip(\n",
        "           roi[:, slice(0, 4, 2)], 0, img_size[0])\n",
        "roi[:, slice(1, 4, 2)] = np.clip(\n",
        "   roi[:, slice(1, 4, 2)], 0, img_size[1])\n",
        "\n",
        "print(roi)\n",
        "\n",
        "#Out:\n",
        "# [[  0.     ,   0.     ,  54.09939, 100.40507],\n",
        "#  [  0.     ,   0.     ,  98.67854, 188.6116 ],\n",
        "#  [  0.     ,   0.     , 196.20844, 349.81198],\n",
        "#  ...,\n",
        "#  [696.17816, 747.13306, 800.     , 800.     ],\n",
        "#  [621.42114, 703.0614 , 800.     , 800.     ],\n",
        "#  [432.86267, 622.48926, 800.     , 800.     ]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.           0.          51.64738999 100.11247437]\n",
            " [  0.           0.          95.69221742 186.44289897]\n",
            " [  0.           0.         194.17979089 367.47368701]\n",
            " ...\n",
            " [707.64184898 748.10783793 800.         800.        ]\n",
            " [621.36531166 701.43897911 800.         800.        ]\n",
            " [430.30310964 604.16962506 800.         800.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgxli4l_Wzfe",
        "colab_type": "code",
        "outputId": "57b23056-6578-49ff-9a16-c9eb1865ae59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "hs = roi[:, 2] - roi[:, 0]\n",
        "ws = roi[:, 3] - roi[:, 1]\n",
        "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
        "roi = roi[keep, :]\n",
        "score = objectness_score_numpy[keep]\n",
        "\n",
        "print(score.shape)\n",
        "#Out:\n",
        "##(22500, ) all the boxes have minimum size of 16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRdA4GFHW3fd",
        "colab_type": "code",
        "outputId": "284f4d6a-0a7a-4316-fbb2-7f8a9dc7efa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "order = score.ravel().argsort()[::-1]\n",
        "print(order)\n",
        "\n",
        "#Out:\n",
        "#[ 889,  929, 1316, ...,  462,  454,    4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 457 1335  898 ...  893  884  461]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he4TxJQyKGYB",
        "colab_type": "code",
        "outputId": "ce193514-bef5-450c-b4dc-117c3b459cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(order)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcJsd6_MXIdS",
        "colab_type": "code",
        "outputId": "ffe9fb18-3153-4d9c-8d2f-309b4ce9749e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "order = order[:n_train_pre_nms]\n",
        "roi = roi[order, :]\n",
        "\n",
        "print(roi.shape)\n",
        "print(roi)\n",
        "\n",
        "#Out\n",
        "# (12000, 4)\n",
        "# [[607.93866,   0.     , 800.     , 113.38187],\n",
        "#  [  0.     ,   0.     , 235.29704, 369.64795],\n",
        "#  [572.177  ,   0.     , 800.     , 373.0086 ],\n",
        "#  ...,\n",
        "#  [250.07968, 186.61633, 434.6356 , 276.70615],\n",
        "#  [490.07974, 154.6163 , 674.6356 , 244.70615],\n",
        "#  [266.07968, 602.61633, 450.6356 , 692.7062 ]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12000, 4)\n",
            "[[  0.           0.         192.55664604 111.93685307]\n",
            " [710.39430714   0.         800.         104.54028177]\n",
            " [623.83468338   0.         800.         110.45556365]\n",
            " ...\n",
            " [337.94808388 200.30745438 800.         711.63463333]\n",
            " [113.94808388 376.30745438 626.82851601 800.        ]\n",
            " [257.94808388 200.30745438 770.82851601 711.63463333]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMwW8pmywjWH",
        "colab_type": "code",
        "outputId": "d1141b77-cbe2-49f5-8928-abddfb0d095c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
        "   for num2, j in enumerate(bbox):\n",
        "       yb1, xb1, yb2, xb2 = j\n",
        "       box_area = (yb2- yb1) * (xb2 - xb1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-b6fd0a28a467>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    for num2, j in enumerate(bbox):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot_EYdhHXPom",
        "colab_type": "code",
        "outputId": "31e56c19-31f0-4ff9-f910-75b2ca03f835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y1 = roi[:, 0]\n",
        "x1 = roi[:, 1]\n",
        "y2 = roi[:, 2]\n",
        "x2 = roi[:, 3]\n",
        "\n",
        "areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "print(order.shape)\n",
        "order = score.argsort()[::-1]  \n",
        "########################################\n",
        "O = []\n",
        "for o in order:\n",
        "    if o < 12000:\n",
        "        O.append(0)\n",
        "order = np.asarray(O)\n",
        "print(order.shape)\n",
        "########################################\n",
        "keep = []\n",
        "\n",
        "while order.size > 0:\n",
        "   i = order[0]\n",
        "   xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "   yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "   xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "   yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "  \n",
        "   w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "   h = np.maximum(0.0, yy2 - yy1 + 1)    \n",
        "   inter = w * h\n",
        "   ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "   \n",
        "   inds = np.where(ovr <= nms_thresh)[0]\n",
        "   order = order[inds + 1]\n",
        "\n",
        "keep = keep[:n_train_post_nms] # while training/testing , use accordingly\n",
        "roi = roi[keep] # the final region proposals"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12000,)\n",
            "(12000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r5L4lZ2sYjI",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>n_sample：roi中采样的样本数目，默认为128  \n",
        "pos_ratio：n_samples中的正样本的比例，默认为0.25   \n",
        "pos_iou_thresh：设置为正样本region proposal与ground-truth目标之间最小的重叠值阈值  \n",
        "[neg_iou_threshold_lo, neg_iou_threshold_hi] : [0.0, 0.5], 设置为负样本[背景]的重叠值阈值  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlQywwtRXTRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_sample = 128\n",
        "pos_ratio = 0.25\n",
        "pos_iou_thresh = 0.5\n",
        "neg_iou_thresh_hi = 0.5\n",
        "neg_iou_thresh_lo = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlWQIRY4xey7",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>找到每个ground-truth 目标与region proposal的iou</font> \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdAj04iYXnwa",
        "colab_type": "code",
        "outputId": "c208e54d-c2e3-4ca0-f49b-01e9d411e249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ious = np.empty((len(roi), 2), dtype=np.float32)\n",
        "ious.fill(0)\n",
        "for num1, i in enumerate(roi):\n",
        "   ya1, xa1, ya2, xa2 = i  \n",
        "   anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
        "   for num2, j in enumerate(bbox):\n",
        "       yb1, xb1, yb2, xb2 = j\n",
        "       box_area = (yb2- yb1) * (xb2 - xb1)\n",
        "\n",
        "       inter_x1 = max([xb1, xa1])\n",
        "       inter_y1 = max([yb1, ya1])\n",
        "       inter_x2 = min([xb2, xa2])\n",
        "       inter_y2 = min([yb2, ya2])\n",
        "\n",
        "       if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
        "           iter_area = (inter_y2 - inter_y1) * \\\n",
        "(inter_x2 - inter_x1)\n",
        "           iou = iter_area / (anchor_area+ \\\n",
        "box_area - iter_area)            \n",
        "       else:\n",
        "           iou = 0.\n",
        "\n",
        "       ious[num1, num2] = iou\n",
        "print(ious.shape)\n",
        "\n",
        "#Out:\n",
        "#[1535, 2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6TASG5rxzR6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<font face=楷体 color=skyblue>找到与每个region proposal具有较高IoU的ground truth，并且找到最大的IoU</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZEY5MBiXsum",
        "colab_type": "code",
        "outputId": "394b86af-392b-4d6f-b7c8-f29ca29b2a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "gt_assignment = iou.argmax(axis=1)\n",
        "max_iou = iou.max(axis=1)\n",
        "print(gt_assignment)\n",
        "print(max_iou)\n",
        "\n",
        "#Out:\n",
        "# [0, 0, 0 ... 1, 1, 0]\n",
        "# [0.016, 0., 0. ... 0.08034518, 0.10739268, 0.]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-aea377d3a4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgt_assignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_assignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'argmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP9CILLnx9RY",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>为每个proposal分配标签</font>   \n",
        "<font face=楷体><font face=楷体 color=red>注意：</font>这里默认背景标记为0</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJOAHrHOXvWG",
        "colab_type": "code",
        "outputId": "f8e67e86-2fc3-4ac0-ed10-f6c7e3fc515c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "gt_roi_label = labels[gt_assignment]\n",
        "print(gt_roi_label)\n",
        "#Out:\n",
        "#[6, 6, 6, ..., 8, 8, 6] q  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-228184808e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgt_roi_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt_assignment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_roi_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Out:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#[6, 6, 6, ..., 8, 8, 6] q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gt_assignment' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qsZHgnqyvFk",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "根据每个pos_iou_thresh选择前景rois。只保留n_sample*pos_ratio（128*0.25=32）个前景样本，因此如果只得到少于32个正样本，保持原状。如果得到多余32个前景目标，从中采样32个样本\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUDWuAQfXyhS",
        "colab_type": "code",
        "outputId": "94f104a8-567b-407b-ccd1-65d916e42437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "pos_index = np.where(max_iou >= pos_iou_thresh)[0]\n",
        "pos_roi_per_this_image = int(min(pos_roi_per_image, pos_index.size))\n",
        "if pos_index.size > 0:\n",
        "   pos_index = np.random.choice(\n",
        "       pos_index, size=pos_roi_per_this_image, replace=False)\n",
        "print(pos_roi_per_this_image)\n",
        "print(pos_index)\n",
        "\n",
        "#Out\n",
        "# 18\n",
        "# [ 257  296  317 1075 1077 1169 1213 1258 1322 1325 1351 1378 1380 1425\n",
        "#  1472 1482 1489 1495]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-296f4798fb05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iou\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mpos_iou_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpos_roi_per_this_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_roi_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpos_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    pos_index = np.random.choice(\n\u001b[1;32m      5\u001b[0m        pos_index, size=pos_roi_per_this_image, replace=False)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'max_iou' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le7-0XyhzGml",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "针对负[背景]region proposal进行相似处理，如果对于之前分配的ground truth目标，region proposal的IoU在neg_iou_thresh_lo和neg_iou_thresh_hi之间，对该region proposal分配0标签，从这些负样本中采样n(n_sample-pos_samples,128-32=96)个region proposals\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pbl1KAAGIwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_index = np.where((max_iou < neg_iou_thresh_hi) &\n",
        "                            (max_iou >= neg_iou_thresh_lo))[0]\n",
        "neg_roi_per_this_image = n_sample - pos_roi_per_this_image\n",
        "neg_roi_per_this_image = int(min(neg_roi_per_this_image,\n",
        "                                neg_index.size))\n",
        "if  neg_index.size > 0 :\n",
        "   neg_index = np.random.choice(\n",
        "       neg_index, size=neg_roi_per_this_image, replace=False)\n",
        "print(neg_roi_per_this_image)\n",
        "print(neg_index)\n",
        "\n",
        "#Out:\n",
        "#110\n",
        "# [  79  688  160  ...  376  712 1235  148 1001]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpA2nzZTzRWl",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>整合正样本索引和负样本索引，及他们各自的标签和region proposals</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ0IISW9zZ5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keep_index = np.append(pos_index, neg_index)\n",
        "gt_roi_labels = gt_roi_label[keep_index]\n",
        "gt_roi_labels[pos_roi_per_this_image:] = 0  # negative labels --> 0\n",
        "sample_roi = roi[keep_index]\n",
        "print(sample_roi.shape)\n",
        "\n",
        "#Out:\n",
        "#(128, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxKPo0Pqzljt",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>对这些sample_roi选择ground truth目标之后按照第二节中为anchor boxes分配位置的方式进行参数化</font>\n",
        "$$\\begin{matrix}\n",
        "&t_{x} = (x - x_{a})/w_{a} \n",
        "&t_{y} = (y - y_{a})/h_{a}\\\\\n",
        "&t_{w} = log(w/ w_a)\n",
        "&t_{h} = log(h/ h_a)\n",
        "\\end{matrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0KZoJUVzdhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox_for_sampled_roi = bbox[gt_assignment[keep_index]]\n",
        "print(bbox_for_sampled_roi.shape)\n",
        "#Out\n",
        "#(128, 4)\n",
        "height = sample_roi[:, 2] - sample_roi[:, 0]\n",
        "width = sample_roi[:, 3] - sample_roi[:, 1]\n",
        "ctr_y = sample_roi[:, 0] + 0.5 * height\n",
        "ctr_x = sample_roi[:, 1] + 0.5 * width\n",
        "base_height = bbox_for_sampled_roi[:, 2] - bbox_for_sampled_roi[:, 0]\n",
        "base_width = bbox_for_sampled_roi[:, 3] - bbox_for_sampled_roi[:, 1]\n",
        "base_ctr_y = bbox_for_sampled_roi[:, 0] + 0.5 * base_height\n",
        "base_ctr_x = bbox_for_sampled_roi[:, 1] + 0.5 * base_width"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9fbG0tgzdep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#t_{x} = (x - x_{a})/w_{a}\n",
        "#t_{y} = (y - y_{a})/h_{a}\n",
        "#t_{w} = log(w/ w_a)\n",
        "#t_{h} = log(h/ h_a)\n",
        "\n",
        "eps = np.finfo(height.dtype).eps\n",
        "height = np.maximum(height, eps)\n",
        "width = np.maximum(width, eps)\n",
        "\n",
        "dy = (base_ctr_y - ctr_y) / height\n",
        "dx = (base_ctr_x - ctr_x) / width\n",
        "dh = np.log(base_height / height)\n",
        "dw = np.log(base_width / width)\n",
        "\n",
        "gt_roi_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
        "print(gt_roi_locs)\n",
        "\n",
        "#Out:\n",
        "# [[-0.08075945, -0.14638858, -0.23822695, -0.23150307],\n",
        "#  [ 0.04865225,  0.15570255,  0.08902431, -0.5969549 ],\n",
        "#  [ 0.17411101,  0.2244332 ,  0.19870323,  0.25063717],\n",
        "#  .....\n",
        "#  [-0.13976236,  0.121031  ,  0.03863466,  0.09662855],\n",
        "#  [-0.59361845, -2.5121436 ,  0.04558792,  0.9731178 ],\n",
        "#  [ 0.1041566 , -0.7840459 ,  1.4283055 ,  0.95092565]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx5LUFI4zdbu",
        "colab_type": "code",
        "outputId": "11e97fa8-daaa-45f7-cbbe-7139481b4b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "rois = torch.from_numpy(sample_rois).float()\n",
        "roi_indices = 0 * np.ones((len(rois),), dtype=np.int32)\n",
        "roi_indices = torch.from_numpy(roi_indices).float()\n",
        "print(rois.shape, roi_indices.shape)\n",
        "#Out:\n",
        "#torch.Size([128, 4]) torch.Size([128])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-be7da1f001f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrois\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroi_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mroi_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Out:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_rois' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DnYgTLF00pB",
        "colab_type": "text"
      },
      "source": [
        "合并 rois and roi_indices, 这样我们将会得到维度是[N, 5] (index, x, y, h, w)的张量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFsG5AoazdY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices_and_rois = torch.cat([roi_indices[:, None], rois], dim=1)\n",
        "xy_indices_and_rois = indices_and_rois[:, [0, 2, 1, 4, 3]]\n",
        "indices_and_rois = xy_indices_and_rois.contiguous()\n",
        "print(xy_indices_and_rois.shape)\n",
        "#Out:\n",
        "#torch.Size([128, 5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FOX6bFb05qe",
        "colab_type": "text"
      },
      "source": [
        "要将数组传到roi_pooling层,定义大小为 7 x 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvti5QXyzdVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = (7, 7)\n",
        "adaptive_max_pool = AdaptiveMaxPool2d(size[0], size[1])\n",
        "output = []\n",
        "rois = indices_and_rois.data.float()\n",
        "rois[:, 1:].mul_(1/16.0) # Subsampling ratio\n",
        "rois = rois.long()\n",
        "num_rois = rois.size(0)\n",
        "for i in range(num_rois):\n",
        "   roi = rois[i]\n",
        "   im_idx = roi[0]\n",
        "   im = out_map.narrow(0, im_idx, 1)[..., roi[2]:(roi[4]+1), roi[1]:(roi[3]+1)]\n",
        "   output.append(adaptive_max_pool(im))\n",
        "output = torch.cat(output, 0)\n",
        "print(output.size())\n",
        "#Out:\n",
        "# torch.Size([128, 512, 7, 7])\n",
        "# Reshape the tensor so that we can pass it through the feed forward layer.\n",
        "k = output.view(output.size(0), -1)\n",
        "print(k.shape)\n",
        "#Out:\n",
        "# torch.Size([128, 25088])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woExUKDt1Bk9",
        "colab_type": "text"
      },
      "source": [
        "这将会是一个classifier层的输入, 进一步将会如同下面图表所示的分出classification head 和 regression head 。 现在让我们定义网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEo8fsBKzdSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roi_head_classifier = nn.Sequential(*[nn.Linear(25088, 4096),\n",
        "                                     nn.Linear(4096, 4096)])\n",
        "cls_loc = nn.Linear(4096, 21 * 4) # (VOC 20 classes + 1 background. Each wil\n",
        "cls_loc.weight.data.normal_(0, 0.01)\n",
        "cls_loc.bias.data.zero_()\n",
        "score = nn.Linear(4096, 21) # (VOC 20 classes + 1 background)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yNl6GjQ1UYg",
        "colab_type": "text"
      },
      "source": [
        "将roi-pooling的输出传到上面我们定义的网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yowLzkPszcxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = roi_head_classifier(k)\n",
        "roi_cls_loc = cls_loc(k)\n",
        "roi_cls_score = score(k)\n",
        "print(roi_cls_loc.shape, roi_cls_score.shape)\n",
        "#Out:\n",
        "# torch.Size([128, 84]), torch.Size([128, 21])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnkzOmdI1ctR",
        "colab_type": "text"
      },
      "source": [
        "roi_cls_loc 和 roi_cls_score 是从实际边界区域得到的两个输出张量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNC-ySHw1fkk",
        "colab_type": "text"
      },
      "source": [
        "## 损失函数\n",
        "<font face=楷体>\n",
        "其中$p_{i}$是预测的班级标签，$p_{i}^*$是实际的班级分数。$t_{i}$并且$t_{i}^*$是预测的原点和实际的坐标。$p_{i}^*$如果锚点为正，则地面真实标签为1；如果锚点为负，则地面真实标签为0。我们将在Pytorch中看到如何完成此操作    \n",
        "RPN和Fast-RCNN都含有两种损失Regression和 classification\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RFVcah11d_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pred_anchor_locs.shape)\n",
        "print(pred_cls_scores.shape)\n",
        "print(anchor_locations.shape)\n",
        "print(anchor_labels.shape)\n",
        "#Out:\n",
        "# torch.Size([1, 12321, 4])\n",
        "# torch.Size([1, 12321, 2])\n",
        "# (12321, 4)\n",
        "# (12321,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFzuDZeH24BC",
        "colab_type": "text"
      },
      "source": [
        "将输入和输出排成一行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iVcPOV61d7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rpn_loc = pred_anchor_locs[0]\n",
        "rpn_score = pred_cls_scores[0]\n",
        "gt_rpn_loc = torch.from_numpy(anchor_locations)\n",
        "gt_rpn_score = torch.from_numpy(anchor_labels)\n",
        "print(rpn_loc.shape, rpn_score.shape, gt_rpn_loc.shape, gt_rpn_score.shape)\n",
        "#Out\n",
        "# torch.Size([12321, 4]) torch.Size([12321, 2]) torch.Size([12321, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT1tBGgC2_8R",
        "colab_type": "text"
      },
      "source": [
        "pred_cls_scores 和 anchor_labels 是RPN网络的预测对象值和实际对象值  \n",
        "对classification用Cross Entropy损失:\n",
        "$$H(y)=(-1)*\\sum_iy_i*log(y_i)\\\\\n",
        "Softmax = e^{l_{ina}}/(\\sum^3_{a=1}e^{O_{ina}})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6iEbQoN37HP",
        "colab_type": "text"
      },
      "source": [
        "用Pytorch计算损失"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcOEyCO31d4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_score.long(), ignore_index = -1)\n",
        "print(rpn_cls_loss)\n",
        "#Out:\n",
        "# Variable containing:\n",
        "#  0.6940\n",
        "# [torch.FloatTensor of size 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3bPcGlr3_Pm",
        "colab_type": "text"
      },
      "source": [
        "对于 Regression 用smooth L1 损失:\n",
        "$$\\begin{aligned}\n",
        "L_{Loc}(t^u,v)&=\\sum_{i\\in x,y,w,h}smooth_{L_1}(t^u_i-V_i)\\\\\n",
        "smooth_{L_1} &=\\left\\{ \\begin{aligned} 0.5*x^2 \\quad if |x|<1\\\\\n",
        "|x|-0.5 \\quad otherwise\\end{aligned}\\right.\n",
        "\\end{aligned}$$\n",
        "\n",
        "使用 L1 而不是 L2 损失，是因为RPN的预测回归头的值不是有限的。 Regression 损失也被应用在有正标签的边界区域中："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HWFpWAO1d0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos = gt_rpn_score > 0\n",
        "mask = pos.unsqueeze(1).expand_as(rpn_loc)\n",
        "print(mask.shape)\n",
        "#Out:\n",
        "# torch.Size(12321, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVBbBsOU7LYA",
        "colab_type": "text"
      },
      "source": [
        "取有正数标签的边界区域："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFHMGtKL1dxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_loc_preds = rpn_loc[mask].view(-1, 4)\n",
        "mask_loc_targets = gt_rpn_loc[mask].view(-1, 4)\n",
        "print(mask_loc_preds.shape, mask_loc_preds.shape)\n",
        "#Out:\n",
        "# torch.Size([6, 4]) torch.Size([6, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z8nnuyt7N4V",
        "colab_type": "text"
      },
      "source": [
        "regression损失应用如下"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prJ_6vBI1dtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.abs(mask_loc_targets - mask_loc_preds)\n",
        "rpn_loc_loss = ((x < 1).float() * 0.5 * x**2) + ((x >= 1).float() * (x-0.5))\n",
        "print(rpn_loc_loss.sum())\n",
        "#Out:\n",
        "# Variable containing:\n",
        "#  0.3826\n",
        "# [torch.FloatTensor of size 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHJ3d2Go7YiG",
        "colab_type": "text"
      },
      "source": [
        "合并rpn_cls_loss 和 rpn_reg_loss, 因为class loss 应用在全部的边界区域，regression loss 应用在正数标签边界区域,作者已经介绍 Λ 作为超参数。通过使用边界区域的数量："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDD2Zysp7YBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rpn_lambda = 10.\n",
        "N_reg = (gt_rpn_score >0).float().sum()\n",
        "rpn_loc_loss = rpn_loc_loss.sum() / N_reg\n",
        "rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)\n",
        "print(rpn_loss)\n",
        "#Out:0.00248"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnwcjlxc7eOn",
        "colab_type": "text"
      },
      "source": [
        "Fast RCNN 损失"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPI5FwBl7rZ8",
        "colab_type": "text"
      },
      "source": [
        "预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaYAQ_wC7X9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(roi_cls_loc.shape)\n",
        "print(roi_cls_score.shape)\n",
        "#Out:\n",
        "# torch.Size([128, 84])\n",
        "# torch.Size([128, 21])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAHnsR-47unI",
        "colab_type": "text"
      },
      "source": [
        "真实"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vBeTFMJ7X50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(gt_roi_locs.shape)\n",
        "print(gt_roi_labels.shape)\n",
        "#Out:\n",
        "#(128, 4)\n",
        "#(128, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAhWn1nm70TF",
        "colab_type": "text"
      },
      "source": [
        "转化到Torch变量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3osWlmpD7X2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gt_roi_loc = torch.from_numpy(gt_roi_locs)\n",
        "gt_roi_label = torch.from_numpy(np.float32(gt_roi_labels)).long()\n",
        "print(gt_roi_loc.shape, gt_roi_label.shape)\n",
        "#Out:\n",
        "#torch.Size([128, 4]) torch.Size([128])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yalIF3SB74Y7",
        "colab_type": "text"
      },
      "source": [
        "分类损失"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if1jzNJI7Xy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roi_clss_loss = F.cross_entropy(roi_cls_score, rt_roi_label, ignore_index=-1)\n",
        "print(roi_cls_loss.shape)\n",
        "#Out:\n",
        "#Variable containing:\n",
        "#  3.0458\n",
        "# [torch.FloatTensor of size 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ib5ZS3I8CUI",
        "colab_type": "text"
      },
      "source": [
        "对于回归损失，每个ROI位置有21（num_classes+background）预测边界框。为了计算损失，我们将只使用带有正标签的边界框（P_i^*）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4koMWcO7XvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_sample = roi_cls_loc.shape[0]\n",
        "roi_loc = roi_cls_loc.view(n_sample, -1, 4)\n",
        "print(roi_loc.shape)\n",
        "#Out:\n",
        "#torch.Size([128, 21, 4])\n",
        "roi_loc = roi_loc[torch.arange(0, n_sample).long(), gt_roi_label]\n",
        "print(roi_loc.shape)\n",
        "#Out:\n",
        "#torch.Size([128, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itG87bU18Lrq",
        "colab_type": "text"
      },
      "source": [
        "用计算RPN网络回归损失的方法计算回归损失\n",
        "注意，我们这里没有写任何regloss函数。读者可以包装在RPN Reg Loss中讨论的所有方法，并实现这个函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE91alEl8GP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roi_loc_loss = REGLoss(roi_loc, gt_roi_loc)\n",
        "print(roi_loc_loss)\n",
        "#Out:\n",
        "#Variable containing:\n",
        "#  0.1895\n",
        "# [torch.FloatTensor of size 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h936vHzB8U_4",
        "colab_type": "text"
      },
      "source": [
        "ROI损失总和"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33D2g3fS8GJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roi_lambda = 10.\n",
        "roi_loss = roi_cls_loss + (roi_lambda * roi_loc_loss)\n",
        "print(roi_loss)\n",
        "#Out:\n",
        "#Variable containing:\n",
        "#  4.2353\n",
        "# [torch.FloatTensor of size 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXrDUyKH8cbx",
        "colab_type": "text"
      },
      "source": [
        "损失总和\n",
        "RPN损失+ Fast RCNN损失"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0L3uZuJ8GFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_loss = rpn_loss + roi_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J-r_dwo8GB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2QwswT18F-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMigVM0v8F7V",
        "colab_type": "code",
        "outputId": "8ba65d3c-5914-4c0a-c898-36104801aca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "!wget https://github.com/liuyuemaicha/simple_faster_rcnn.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-09 02:17:01--  https://github.com/liuyuemaicha/simple_faster_rcnn.git\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/liuyuemaicha/simple_faster_rcnn [following]\n",
            "--2020-02-09 02:17:01--  https://github.com/liuyuemaicha/simple_faster_rcnn\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘simple_faster_rcnn.git’\n",
            "\n",
            "\rsimple_faster_rcnn.     [<=>                 ]       0  --.-KB/s               \rsimple_faster_rcnn.     [ <=>                ]  76.76K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2020-02-09 02:17:02 (10.0 MB/s) - ‘simple_faster_rcnn.git’ saved [78607]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtfAhyR68F3h",
        "colab_type": "code",
        "outputId": "340aafce-1a8c-4ba6-a559-6573836df993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "#coding:utf8\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "from model import VGG\n",
        "import utils\n",
        "\n",
        "\n",
        "# 大体流程：\n",
        "# 1. 图像通过vgg获得特征图，\n",
        "# 2. 特征图通过RPN获得有效anchor的置信度(foreground)和转为预测框的坐标系数\n",
        "# 3. 特征图和预测框通过ROI Pooling获取固定尺寸的预测目标特征图,即利用预测框，从特征图中把目标抠出来，\n",
        "#    因为目标尺寸不一，再通过ROI Pooling的方法把目标转为统一的固定尺寸（7*7），这样就可以方便做目标的分类和预测框的修正处理。\n",
        "# 4. 固定尺寸的预测目标特征图通过类别分类模型（self.score）获取预测框所属的类别，\n",
        "# 5. 固定尺寸的预测目标特征图通过坐标分类模型(self.cls_loc)获取置信度和预测框修正的坐标系数。\n",
        "\n",
        "# 假设 图片中的两个目标框\"ground-truth\"\n",
        "bbox = np.asarray([[20, 30, 400, 500], [300, 400, 500, 600]], dtype=np.float32) # [y1, x1, y2, x2] format\n",
        "# 假设 图片中两个目标框分别对应的标签\n",
        "labels = np.asarray([6, 8], dtype=np.int8)  # 0 represents background\n",
        "\n",
        "img_tensor = torch.zeros((1, 3, 800, 800)).float()\n",
        "img_var = torch.autograd.Variable(img_tensor)\n",
        "\n",
        "\n",
        "# ---------------------step_1: 获取目标anchor的置信度（anchor_conf）和平移缩放系数（anchor_locations）\n",
        "# 初始化所有anchors, 并找出有效anchors和对应的index\n",
        "# anchors： (22500, 4)  valid_anchor_boxes： (8940, 4)  valid_anchor_index：8940\n",
        "anchors, valid_anchor_boxes, valid_anchor_index = utils.init_anchor()\n",
        "# 计算有效anchors与所有目标框的IOU\n",
        "# ious：（8940, 2) 每个有效anchor框与目标实体框的IOU\n",
        "ious = utils.compute_iou(valid_anchor_boxes, bbox)\n",
        "valid_anchor_len = len(valid_anchor_boxes)\n",
        "# 在有效框中找到一定比例的正例和负例\n",
        "label, argmax_ious = utils.get_pos_neg_sample(ious, valid_anchor_len, pos_iou_threshold=0.7,\n",
        "                                 neg_iou_threshold=0.3, pos_ratio=0.5, n_sample=256)\n",
        "# print np.sum(label == 1)  # 18个正例\n",
        "# print np.sum(label == 0)  # 256-18=238个负例\n",
        "\n",
        "# 现在让我们用具有最大iou的ground truth对象为每个anchor box分配位置。\n",
        "# 注意，我们将为所有有效的anchor box分配anchor locs，而不考虑其标签，稍后在计算损失时，我们可以使用简单的过滤器删除它们。\n",
        "# 每个有效anchor对应的目标框bbox\n",
        "max_iou_bbox = bbox[argmax_ious]  # 有效anchor框对应的目标框坐标  (8940, 4)\n",
        "# print max_iou_bbox.shape  # (8940, 4)，共有8940个有效anchor框，每个anchor有坐标值（y1, x1, y2, x2）\n",
        "# 为所有有效的anchor_box分配anchor_locs，anchor_locs是每个有效的anchors转为对应目标框（bbox）的平移缩放系数\n",
        "anchor_locs = utils.get_coefficient(valid_anchor_boxes, max_iou_bbox)\n",
        "# print(anchor_locs.shape)  # (8940, 4)  4维参数（平移参数：dy, dx； 缩放参数：dh, dw）\n",
        "\n",
        "# anchor_conf ： 所有anchor框对应的label（-1：无效anchor，0：负例有效anchor，1：正例有效anchor）\n",
        "anchor_conf = np.empty((len(anchors),), dtype=label.dtype)\n",
        "anchor_conf.fill(-1)\n",
        "anchor_conf[valid_anchor_index] = label\n",
        "print anchor_conf.shape  # 所有anchor对应的label（feature_size*feature_size*9）=》 (22500,)\n",
        "\n",
        "# anchor_locations： 所有anchor框转为目标实体框的系数，无效anchor系数全部为0，有效anchor有有效系数\n",
        "anchor_locations = np.empty((len(anchors),) + anchors.shape[1:], dtype=anchor_locs.dtype)\n",
        "anchor_locations.fill(0)\n",
        "anchor_locations[valid_anchor_index, :] = anchor_locs\n",
        "print anchor_locations.shape  # 所有anchor对应的平移缩放系数（feature_size*feature_size*9，4）=》(22500, 4)\n",
        "\n",
        "# 这里通过候选anchor与目标实体框计算得到anchor框的置信度（anchor_conf）和平移缩放系数（anchor_locations）\n",
        "# ----------------------\n",
        "\n",
        "\n",
        "# --------------------step_2: VGG 和 RPN 模型: RPN 预测的是anchor转为目标框的平移缩放系数\n",
        "vgg = VGG()\n",
        "# out_map 特征图， # pred_anchor_locs 预测anchor框到目标框转化的系数， pred_anchor_conf 预测anchor框的分数\n",
        "out_map, pred_anchor_locs, pred_anchor_conf = vgg.forward(img_var)\n",
        "print out_map.data.shape  # (batch_size, num, feature_size, feature_size) => (1, 512, 50, 50)\n",
        "\n",
        "# 1. pred_anchor_locs 预测每个anchor框到目标框转化的系数（平移缩放），与 anchor_locations对应\n",
        "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
        "print(pred_anchor_locs.shape)  # Out: torch.Size([1, 22500, 4])\n",
        "\n",
        "# 2. 预测anchor框的置信度，每个anchor框都会对应一个置信度，与 anchor_conf对应\n",
        "pred_anchor_conf = pred_anchor_conf.permute(0, 2, 3, 1).contiguous()\n",
        "print(pred_anchor_conf.shape)  # Out torch.Size([1, 50, 50, 18])\n",
        "objectness_score = pred_anchor_conf.view(1, 50, 50, 9, 2)[:, :, :, :, 1].contiguous().view(1, -1)\n",
        "print(objectness_score.shape)  # Out torch.Size([1, 22500])\n",
        "\n",
        "pred_anchor_conf = pred_anchor_conf.view(1, -1, 2)\n",
        "print(pred_anchor_conf.shape)  # Out torch.size([1, 22500, 2])\n",
        "# ---------------------\n",
        "\n",
        "\n",
        "# ---------------------step_3: RPN 损失 （有效anchor与预测anchor之间的损失--坐标系数损失与置信度损失）\n",
        "# 从上面step_1中，我们得到了目标anchor信息：\n",
        "# 目标anchor坐标系数：anchor_locations  (22500, 4)\n",
        "# 目标anchor置信度：anchor_conf  (22500,)\n",
        "\n",
        "# 从上面step_2中，我们得到了预测anchor信息：\n",
        "# RPN网络预测anchor的坐标系数：pred_anchor_locs  (1, 22500, 4)\n",
        "# RPN网络预测anchor的置信度: pred_anchor_conf  (1, 22500, 2)\n",
        "\n",
        "# 我们将会从新排列，将输入和输出排成一行\n",
        "rpn_anchor_loc = pred_anchor_locs[0]\n",
        "rpn_anchor_conf = pred_anchor_conf[0]\n",
        "anchor_locations = torch.from_numpy(anchor_locations)\n",
        "anchor_conf = torch.from_numpy(anchor_conf)\n",
        "print(rpn_anchor_loc.shape, rpn_anchor_conf.shape, anchor_locations.shape, anchor_conf.shape)\n",
        "# torch.Size([22500, 4]) torch.Size([22500, 2]) torch.Size([22500, 4]) torch.Size([22500])\n",
        "\n",
        "rpn_loss = vgg.roi_loss(rpn_anchor_loc, rpn_anchor_conf, anchor_locations, anchor_conf, weight=10.0)\n",
        "print(\"rpn_loss: {}\".format(rpn_loss))  # 1.33919\n",
        "# ---------------------\n",
        "\n",
        "\n",
        "# ---------------------step_4: 根据anchor和预测anchor系数，计算预测框（roi）和预测框的坐标系数(roi_locs)，\n",
        "# ---------------------并得到每个预测框的所属类别label(roi_labels)\n",
        "# 通过anchors框和模型预测的平移缩放系数，得到预测框ROI；再通过预测的分值和阈值进行过滤精简\n",
        "roi, score, order = utils.get_predict_bbox(anchors, pred_anchor_locs, objectness_score,\n",
        "                                           n_train_pre_nms=12000, min_size=16)\n",
        "\n",
        "# 得到的预测框（ROI）还会有大量重叠，再通过NMS（非极大抑制）做进一步的过滤精简\n",
        "roi = utils.nms(roi, score, order, nms_thresh=0.7, n_train_post_nms=2000)\n",
        "\n",
        "\n",
        "# 根据预测框ROI与目标框BBox的IOU，得到每个预测框所要预测的目标框（预测框与哪个目标框的IOU大，就代表预测哪个目标）；\n",
        "# 并根据IOU对ROI做进一步过滤，并划分正负样例。\n",
        "sample_roi, keep_index, gt_assignment, roi_labels = utils.get_propose_target(roi, bbox, labels,\n",
        "                                                                                n_sample=128,\n",
        "                                                                                pos_ratio=0.25,\n",
        "                                                                                pos_iou_thresh=0.5,\n",
        "                                                                                neg_iou_thresh_hi=0.5,\n",
        "                                                                                neg_iou_thresh_lo=0.0)\n",
        "# print(sample_roi.shape)  # (128, 4)\n",
        "# 预测框对应的目标框 bbox_for_sampled_roi\n",
        "bbox_for_sampled_roi = bbox[gt_assignment[keep_index]]  # 目标框\n",
        "print(bbox_for_sampled_roi.shape)  # (128, 4)\n",
        "# 预测框（ROI）转目标框的真实系数\n",
        "roi_locs = utils.get_coefficient(sample_roi, bbox_for_sampled_roi)\n",
        "# ---------------------\n",
        "\n",
        "\n",
        "# ---------------------step_5: ROI Pooling：\n",
        "# 这一步做了两件事：\n",
        "# 一是从特征图中根据ROI把相应的预测目标框抠出来(im)\n",
        "# 二是将抠出来的预测目标框通过adaptive_max_pool方法，输出为固定尺寸(512, 7, 7)，方便后续的批处理\n",
        "# 这样的特点：\n",
        "# 一是并没有在输入图像上预测，而是在VGG模型的输出特征图上进行预测，这样减少了计算量；\n",
        "# 二是因为目标实体尺寸多种多样，通过ROI Pooling方法将输出统一为固定尺寸(512, 7, 7)，方便进行批处理，\n",
        "# sample_roi：预测的有效框 (128, 4)\n",
        "rois = torch.from_numpy(sample_roi).float()\n",
        "# roi_indices：添加图像的索引[这里我们只有一个图像，其索引号为0]\n",
        "roi_indices = 0 * np.ones((len(rois),), dtype=np.int32)\n",
        "roi_indices = torch.from_numpy(roi_indices).float()\n",
        "print(rois.shape, roi_indices.shape)  # torch.Size([128, 4]) torch.Size([128])\n",
        "\n",
        "# 将图像的索引号和预测的有效框进行合并, 这样我们将会得到维度是[N, 5]  5=>(index, x1, y1, x2, y2)的张量\n",
        "indices_and_rois = torch.cat([roi_indices[:, None], rois], dim=1)  # torch.Size([128, 5])\n",
        "\n",
        "output = []\n",
        "rois = indices_and_rois.float()\n",
        "rois[:, 1:].mul_(1/16.0)  # 对预测框进行下采样，匹配特征图out_map\n",
        "rois = rois.long()\n",
        "num_rois = rois.size(0)\n",
        "# out_map: (batch_size, num, feature_size, feature_size) => (1, 512, 50, 50)\n",
        "for i in range(num_rois):\n",
        "   roi = rois[i]\n",
        "   im_idx = roi[0]  # 图片的索引号\n",
        "   # 取出索引号是im_idx的图片特征图=》(1, 512, 50, 50)，因为本实例就一张图片，所以操作完后shape并不变\n",
        "   out_map = out_map.narrow(0, im_idx, 1)\n",
        "   # 这一步是根据预测框的的x1,y1, x2,y2坐标，从特征图out_map中把目标实体抠出来\n",
        "   im = out_map[..., roi[2]:(roi[4]+1), roi[1]:(roi[3]+1)]\n",
        "   # print im.shape\n",
        "   # 将抠出来的目标实体im，做adaptive_max_pool计算，最后得到一个固定的尺寸(7,7)== > (512, 7, 7)，方便后面进行批处理\n",
        "   output.append(vgg.adaptive_max_pool(im)[0].data)\n",
        "# ---------------------ROI Pooling\n",
        "\n",
        "\n",
        "# ---------------------step_6: Classification 线性分类，预测预测框的类别，置信度和转为目标框的平移缩放系数（要与RPN区分）\n",
        "# note: if your pytorch version is 0.3.1, you must run this:\n",
        "# output = torch.stack(output)\n",
        "output = torch.cat(output, 0)  # torch.Size([128, 512, 7, 7])\n",
        "k = output.view(output.size(0), -1)  # [128, 25088]\n",
        "\n",
        "k = torch.autograd.Variable(k)\n",
        "k = vgg.roi_head_classifier(k)  # (128, 4096)\n",
        "# torch.Size([128, 84])  84 ==> (20+1)*4,表示每个框有20个候选类别和一个置信度（假设为VOC数据集，共20分类），4表示坐标信息\n",
        "pred_roi_locs = vgg.cls_loc(k)\n",
        "# pred_roi_labels： [128, 21] 表示每个框的类别和置信度\n",
        "pred_roi_labels = vgg.score(k)\n",
        "print(pred_roi_locs.data.shape, pred_roi_labels.data.shape)  # torch.Size([128, 84]), torch.Size([128, 21])\n",
        "# ---------------------Classification\n",
        "\n",
        "\n",
        "# ---------------------step_7: 分类损失  (有效预测框真实系数与有效预测框的预测系数间损失，其中系数是转为目标框的坐标系数)\n",
        "# 从上面step_4中，我们得到了预测框转为目标框的目标信息：\n",
        "# 预测框的坐标系数(roi_locs)：  (128, 4)\n",
        "# 预测框的所属类别(roi_labels)：(128, )\n",
        "\n",
        "# 从上面step_6中，我们得到了预测框转为目标框的预测信息：\n",
        "# 预测框的坐标系数：pred_roi_locs  (128, 84)\n",
        "# 预测框的所属类别和置信度: pred_roi_labels  (128, 21)\n",
        "\n",
        "\n",
        "gt_roi_loc = torch.from_numpy(roi_locs)\n",
        "gt_roi_label = torch.from_numpy(np.float32(roi_labels)).long()\n",
        "print(gt_roi_loc.shape, gt_roi_label.shape)  # torch.Size([128, 4]) torch.Size([128])\n",
        "\n",
        "n_sample = pred_roi_locs.shape[0]\n",
        "roi_loc = pred_roi_locs.view(n_sample, -1, 4)  # (128L, 21L, 4L)\n",
        "\n",
        "roi_loc = roi_loc[torch.arange(0, n_sample).long(), gt_roi_label]  # 根据预测框的真实类别，找到真实类别所对应的坐标系数\n",
        "# print(roi_loc.shape)  # torch.Size([128, 4])\n",
        "\n",
        "roi_loss = vgg.roi_loss(roi_loc, pred_roi_labels, gt_roi_loc, gt_roi_label, weight=10.0)\n",
        "print(roi_loss)  # 3.810348778963089\n",
        "\n",
        "\n",
        "# 整体损失函数\n",
        "total_loss = rpn_loss + roi_loss\n",
        "print total_loss  # 5.149546355009079"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-dbaa957d2330>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    print anchor_conf.shape  # 所有anchor对应的label（feature_size*feature_size*9）=》 (22500,)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPaDik7_urZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm simple_faster_rcnn.git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS3MaxECvRTG",
        "colab_type": "code",
        "outputId": "3c4bf70f-f614-449a-ae71-26d1b973fc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget https://github.com/liuyuemaicha/simple_faster_rcnn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-09 02:19:07--  https://github.com/liuyuemaicha/simple_faster_rcnn\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘simple_faster_rcnn’\n",
            "\n",
            "\rsimple_faster_rcnn      [<=>                 ]       0  --.-KB/s               \rsimple_faster_rcnn      [ <=>                ]  75.92K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2020-02-09 02:19:07 (9.28 MB/s) - ‘simple_faster_rcnn’ saved [77739]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbuKOfIEvkaj",
        "colab_type": "code",
        "outputId": "1e8f4011-7aed-4334-8d72-79426c2187bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "cd ./simple_faster_rcnn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 20] Not a directory: './simple_faster_rcnn'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAo3WK6evmaw",
        "colab_type": "code",
        "outputId": "796ca14c-694d-4a47-b620-7d313c92d8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 800, 800])\n",
            "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]\n",
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 64, 800, 800])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 64, 800, 800])\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 64, 800, 800])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 64, 800, 800])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([1, 64, 400, 400])\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 128, 400, 400])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 128, 400, 400])\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 128, 400, 400])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 128, 400, 400])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([1, 128, 200, 200])\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 256, 200, 200])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 256, 200, 200])\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 256, 200, 200])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 256, 200, 200])\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 256, 200, 200])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 256, 200, 200])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([1, 256, 100, 100])\n",
            "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 512, 100, 100])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 512, 100, 100])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 512, 100, 100])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 512, 100, 100])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 512, 100, 100])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 512, 100, 100])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([1, 512, 50, 50])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 512, 50, 50])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 512, 50, 50])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 512, 50, 50])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 512, 50, 50])\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1, 512, 50, 50])\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 512, 50, 50])\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "torch.Size([1, 512, 25, 25])\n",
            "30\n",
            "512\n",
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "ReLU(inplace=True)\n",
            "torch.Size([1, 512, 50, 50])\n",
            "50\n",
            "2500\n",
            "(22500, 4)\n",
            "(22500, 4)\n",
            "(8940,)\n",
            "(8940, 4)\n",
            "[[ 20.  30. 400. 500.]\n",
            " [300. 400. 500. 600.]]\n",
            "(8940, 2)\n",
            "[2262 5620]\n",
            "[0.68130493 0.61035156]\n",
            "(8940,)\n",
            "(8940,)\n",
            "(18,)\n",
            "(8940,)\n",
            "18\n",
            "238\n",
            "[[ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]\n",
            " ...\n",
            " [ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]\n",
            " [ 20.  30. 400. 500.]]\n",
            "(8940, 4)\n",
            "(8940, 4)\n",
            "(torch.Size([1, 18, 50, 50]), torch.Size([1, 36, 50, 50]))\n",
            "torch.Size([1, 22500, 4])\n",
            "torch.Size([1, 50, 50, 18])\n",
            "torch.Size([1, 22500])\n",
            "torch.Size([1, 22500, 2])\n",
            "(22500, 4)\n",
            "(22500,)\n",
            "(12000, 4)\n",
            "[11999  3996  4005 ...  7995  7994     0]\n",
            "(1758, 4)\n",
            "(1758, 2)\n",
            "[0 0 1 ... 0 0 0]\n",
            "[0.17802152 0.17926688 0.04676317 ... 0.         0.         0.        ]\n",
            "[6 6 8 ... 6 6 6]\n",
            "[ 369  569   37  137 1206   34  751  584  409  487  762  895  217  427\n",
            "  135  130  429  805  637]\n",
            "[1216  599   51 1159  410  591  449  469 1688 1017 1225  335  526  377\n",
            " 1371  689 1749 1151 1250 1628  715 1252  549  993  665 1035  186  244\n",
            "  618  395  561 1663 1547 1531 1431 1245 1281 1449  164 1262 1528  848\n",
            " 1658  847 1059   13  646  578  998 1269  730 1275  732 1170 1581  943\n",
            " 1740 1073  944 1210 1303 1278  867  145 1069 1161  666  677  480 1037\n",
            " 1308 1128 1657  533  322  170  968 1246  959 1738 1488  887 1743 1502\n",
            "  278 1713 1092 1311 1021 1086 1042   76  404  727 1483  247 1064  904\n",
            "  495  445 1390  643  843  672 1221 1383 1309  536 1175]\n",
            "(128, 4)\n",
            "(128, 4)\n",
            "(128, 4)\n",
            "(torch.Size([128, 4]), torch.Size([128]))\n",
            "torch.Size([128, 5])\n",
            "torch.Size([128, 1, 512, 7, 7])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-70fdd0e9c267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 尝试加0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# torch.Size([128, 512, 7, 7])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, float), but expected one of:\n * (tuple of Tensors tensors, name dim, Tensor out)\n * (tuple of Tensors tensors, int dim, Tensor out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPZ4PENnvzYI",
        "colab_type": "code",
        "outputId": "7e75dbc1-fe5c-43e6-902b-3e37431fbe0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#coding:utf8\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# cfg = {\n",
        "#     'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "#     'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "#     'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "#     'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "# }\n",
        "\n",
        "featur_cfg = ''\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "\n",
        "        cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512]\n",
        "        self.features = self._make_layers(cfg)\n",
        "        self._rpn_model()\n",
        "\n",
        "        size = (7, 7)\n",
        "        self.adaptive_max_pool = torch.nn.AdaptiveMaxPool2d(size[0], size[1])\n",
        "        self.roi_classifier()\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "\n",
        "        # layers += [nn.Conv2d(in_channels, 512, kernel_size=3, padding=1)]\n",
        "        return nn.Sequential(*layers)\n",
        "        # return layers\n",
        "\n",
        "    def _rpn_model(self, mid_channels=512, in_channels=512, n_anchor=9):\n",
        "        self.rpn_conv = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
        "        self.reg_layer = nn.Conv2d(mid_channels, n_anchor * 4, 1, 1, 0)\n",
        "        # I will be going to use softmax here. you can equally use sigmoid if u replace 2 with 1.\n",
        "        self.cls_layer = nn.Conv2d(mid_channels, n_anchor * 2, 1, 1, 0)\n",
        "\n",
        "        # conv sliding layer\n",
        "        self.rpn_conv.weight.data.normal_(0, 0.01)\n",
        "        self.rpn_conv.bias.data.zero_()\n",
        "\n",
        "        # Regression layer\n",
        "        self.reg_layer.weight.data.normal_(0, 0.01)\n",
        "        self.reg_layer.bias.data.zero_()\n",
        "\n",
        "        # classification layer\n",
        "        self.cls_layer.weight.data.normal_(0, 0.01)\n",
        "        self.cls_layer.bias.data.zero_()\n",
        "\n",
        "    def forward(self, data):\n",
        "        out_map = self.features(data)\n",
        "        # for layer in self.features:\n",
        "        #     # print layer\n",
        "        #     data = layer(data)\n",
        "        #     # print data.data.shape\n",
        "        #\n",
        "        # # out = data.view(data.size(0), -1)\n",
        "        x = self.rpn_conv(out_map)\n",
        "        pred_anchor_locs = self.reg_layer(x)  # 回归层，计算有效anchor转为目标框的四个系数\n",
        "        pred_cls_scores = self.cls_layer(x)  # 分类层，判断该anchor是否可以捕获目标\n",
        "\n",
        "        return out_map, pred_anchor_locs, pred_cls_scores\n",
        "\n",
        "    def roi_classifier(self, class_num=20):  # 假设为VOC数据集，共20分类\n",
        "        # 分类层\n",
        "        self.roi_head_classifier = nn.Sequential(*[nn.Linear(25088, 4096),\n",
        "                                                   nn.ReLU(),\n",
        "                                                   nn.Linear(4096, 4096),\n",
        "                                                   nn.ReLU()])\n",
        "        self.cls_loc = nn.Linear(4096, (class_num+1) * 4)  # (VOC 20 classes + 1 background. Each will have 4 co-ordinates)\n",
        "        self.cls_loc.weight.data.normal_(0, 0.01)\n",
        "        self.cls_loc.bias.data.zero_()\n",
        "\n",
        "\n",
        "        self.score = nn.Linear(4096, class_num+1)  # (VOC 20 classes + 1 background)\n",
        "\n",
        "    def rpn_loss(self, rpn_loc, rpn_score, gt_rpn_loc, gt_rpn_label, weight=10.0):\n",
        "        # 对与classification我们使用Cross Entropy损失\n",
        "        gt_rpn_label = torch.autograd.Variable(gt_rpn_label.long())\n",
        "        rpn_cls_loss = torch.nn.functional.cross_entropy(rpn_score, gt_rpn_label, ignore_index=-1)\n",
        "        # print(rpn_cls_loss)  # Variable containing: 0.6931\n",
        "\n",
        "        # 对于 Regression 我们使用smooth L1 损失\n",
        "        pos = gt_rpn_label.data > 0  # Regression 损失也被应用在有正标签的边界区域中\n",
        "        mask = pos.unsqueeze(1).expand_as(rpn_loc)\n",
        "        # print(mask.shape)  # (22500L, 4L)\n",
        "\n",
        "        # 现在取有正数标签的边界区域\n",
        "        mask_pred_loc = rpn_loc[mask].view(-1, 4)\n",
        "        mask_target_loc = gt_rpn_loc[mask].view(-1, 4)\n",
        "        # print(mask_pred_loc.shape, mask_target_loc.shape)  # ((18L, 4L), (18L, 4L))\n",
        "\n",
        "        # regression损失应用如下\n",
        "        x = np.abs(mask_target_loc.numpy() - mask_pred_loc.data.numpy())\n",
        "        # print x.shape  # (18, 4)\n",
        "        # print (x < 1)\n",
        "        rpn_loc_loss = ((x < 1) * 0.5 * x ** 2) + ((x >= 1) * (x - 0.5))\n",
        "        # print rpn_loc_loss.shape  # (18, 4)\n",
        "        rpn_loc_loss = rpn_loc_loss.sum()  # 1.1628926242031001\n",
        "        # print rpn_loc_loss\n",
        "        # print rpn_loc_loss.shape\n",
        "        # rpn_loc_loss = np.squeeze(rpn_loc_loss)\n",
        "        # print rpn_loc_loss\n",
        "\n",
        "        N_reg = (gt_rpn_label > 0).float().sum()\n",
        "        N_reg = np.squeeze(N_reg.data.numpy())\n",
        "\n",
        "        # print \"N_reg: {}, {}\".format(N_reg, N_reg.shape)\n",
        "        rpn_loc_loss = rpn_loc_loss / N_reg\n",
        "        rpn_loc_loss = np.float32(rpn_loc_loss)\n",
        "        # rpn_loc_loss = torch.autograd.Variable(torch.from_numpy(rpn_loc_loss))\n",
        "\n",
        "        rpn_cls_loss = np.squeeze(rpn_cls_loss.data.numpy())\n",
        "        # print \"rpn_cls_loss: {}\".format(rpn_cls_loss)  # 0.693146109581\n",
        "        # print 'rpn_loc_loss: {}'.format(rpn_loc_loss)  # 0.0646051466465\n",
        "        rpn_loss = rpn_cls_loss + (weight * rpn_loc_loss)\n",
        "        # print(\"rpn_loss: {}\".format(rpn_loss))  # 1.33919757605\n",
        "        return rpn_loss\n",
        "\n",
        "    def roi_loss(self, pre_loc, pre_conf, target_loc, target_conf, weight=10.0):\n",
        "        # 分类损失\n",
        "        target_conf = torch.autograd.Variable(target_conf.long())\n",
        "        pred_conf_loss = torch.nn.functional.cross_entropy(pre_conf, target_conf, ignore_index=-1)\n",
        "        # print(pred_conf_loss)  # Variable containing:  3.0515\n",
        "\n",
        "        #  对于 Regression 我们使用smooth L1 损失\n",
        "        # 用计算RPN网络回归损失的方法计算回归损失\n",
        "        # pre_loc_loss = REGLoss(pre_loc, target_loc)\n",
        "        pos = target_conf.data > 0  # Regression 损失也被应用在有正标签的边界区域中\n",
        "        mask = pos.unsqueeze(1).expand_as(pre_loc)  # (128, 4L)\n",
        "\n",
        "        # 现在取有正数标签的边界区域\n",
        "        mask_pred_loc = pre_loc[mask].view(-1, 4)\n",
        "        mask_target_loc = target_loc[mask].view(-1, 4)\n",
        "        # print(mask_pred_loc.shape, mask_target_loc.shape)  # ((19L, 4L), (19L, 4L))\n",
        "\n",
        "        x = np.abs(mask_target_loc.numpy() - mask_pred_loc.data.numpy())\n",
        "        # print x.shape  # (19, 4)\n",
        "\n",
        "        pre_loc_loss = ((x < 1) * 0.5 * x ** 2) + ((x >= 1) * (x - 0.5))\n",
        "        # print(pre_loc_loss.sum())  # 1.4645805211187053\n",
        "\n",
        "        N_reg = (target_conf > 0).float().sum()\n",
        "        N_reg = np.squeeze(N_reg.data.numpy())\n",
        "        pre_loc_loss = pre_loc_loss.sum() / N_reg\n",
        "        pre_loc_loss = np.float32(pre_loc_loss)\n",
        "        # print pre_loc_loss  # 0.077294916\n",
        "        # pre_loc_loss = torch.autograd.Variable(torch.from_numpy(pre_loc_loss))\n",
        "        # 损失总和\n",
        "        pred_conf_loss = np.squeeze(pred_conf_loss.data.numpy())\n",
        "        total_loss = pred_conf_loss + (weight * pre_loc_loss)\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    vgg = VGG()\n",
        "    print vgg\n",
        "    data = torch.randn((1, 3, 800, 800))\n",
        "    print data.shape\n",
        "    data = torch.autograd.Variable(data)\n",
        "    out = vgg.forward(data)\n",
        "    print out.data.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "  )\n",
            "  (rpn_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (reg_layer): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (cls_layer): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (adaptive_max_pool): AdaptiveMaxPool2d(output_size=7)\n",
            "  (roi_head_classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (cls_loc): Linear(in_features=4096, out_features=84, bias=True)\n",
            "  (score): Linear(in_features=4096, out_features=21, bias=True)\n",
            ")\n",
            "torch.Size([1, 3, 800, 800])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-34ed1aeaaa31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEfNZkVe7QsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}