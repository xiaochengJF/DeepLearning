{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "darknet",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "H9LL9UqISMwe"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/master/darknet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WEuumVfwWze",
        "colab_type": "text"
      },
      "source": [
        "# <font face=STCAIYUN color=purple size=8>YOLOv3</font>\n",
        "<font face=楷体 color=skyblue size=4>YOLO 是 You Only Look Once 的缩写</font>  \n",
        "<font face=楷体 color=skyblue size=4>**全卷积神经网络** </font>  \n",
        "<font face=楷体>\n",
        "YOLO 仅使用卷积层，即：全卷积神经网络（FCN对于输入图像的大小不敏感） ，它拥有 75 个卷积层，带有跳跃连接和上采样层。不使用任何它形式的，使用步幅为 2 的卷积层代替池化层对特征图进行下采样，防止池化导致的低级特征丢失 \n",
        "    \n",
        "问题是：如果我们希望按批次处理图像（批量图像由 GPU 并行处理，这样可以提升速度），我们就需要固定所有图像的高度和宽度。这就需要将多个图像整合进一个大的批次（将许多 PyTorch 张量合并成一个）</font>  \n",
        " \n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**YOLOv3网络结构图** </font>  \n",
        "\n",
        "![替代文字](https://img-blog.csdnimg.cn/20190824145218799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcxMTU1NA==,size_16,color_FFFFFF,t_70)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**网络输出**</font>   \n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo-5.png)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>锚点框（Anchor Box）</font>  \n",
        "<font face=楷体>\n",
        "预测边界框的宽度和高度看上去是最直接的，但实践训练中会带来梯度不稳定，所以现在大部分目标检测器都预测对数空间（log-space）变换量，或者预测与预定义边界框（即锚点）之间的偏移量  \n",
        "这些变换被应用到锚点框来获得预测，YOLO v3 有三个锚点，所以每个单元格会预测 3 个边界框  \n",
        "</font>   \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>中心坐标</font>    \n",
        "<font face=楷体>\n",
        "通过一个sigmoid函数对中心坐标预测，迫使输出介于0和1之间  \n",
        "YOLO通常不会预测边界框中心的绝对坐标而是预测偏移量：  \n",
        "\n",
        "\n",
        "*   相对于预测对象格单元格的左上角\n",
        "*   由特征图中的单元格尺寸标准化，如上图：对狗狗中心的预测是（0.4，0.7），那么中心位于$13 \\times 13$特征图上的（6.4，6.7）位置  \n",
        "</font>\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=5>预测</font>  \n",
        "<font face=楷体>每个bounding box预测5个值：$\\color{pink}{t_x，t_y，t_w，t_h，t_o}$ （$t_o$类似YOLOv1中的confidence）  \n",
        "\n",
        "*   $\\color{pink}{t_x，t_y}$：经过sigmoid函数处理后范围在0到1之间，模型训练更加稳定  \n",
        "*   $\\color{pink}{c_x，c_y}$：表示一个cell和图像左上角的横纵距离 \n",
        "*   $\\color{pink}{p_w，p_h}$：表示bounding box的宽高 \n",
        "</font>\n",
        "\n",
        " \n",
        "$$\n",
        "\\begin{aligned} b_{x} &=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} &=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} &=p_{w} e^{t_{w}} \\\\ b_{h} &=p_{h} e^{t_{h}} \\\\ \\operatorname{Pr}(\\text { object }) * I O U(b, \\text { object }) &=\\sigma\\left(t_{o}\\right)\\end{aligned}\n",
        "$$\n",
        "\n",
        "<font face=楷体 color=yellow>在Faster R-CNN中：</font>\n",
        "$$\\begin{align}\n",
        "t_x &= (x - x_a) /w_a \\ ,\\  \\ t_y = (y - y_a) / h_a\\\\[1ex]t_w &= log(w/ w_a), \\quad \\ \\  t_h = log(h/h_a)\\\\[1ex]t_x^* &= (x^* - x_a) / w_a,\\  t_y^* = (y^* - y_a) /h_a\\\\[1ex]t_w^* &= log(w^* - w),\\ \\  h_h^* = log(h^*/h_a)\n",
        "\\end{align}$$  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>边界框的尺寸</font>   \n",
        "<font face=楷体>\n",
        "将输出进行对数变换乘以锚来预测边界框的尺寸  \n",
        "预测结果$b_w$和$b_h$由图像的高度和宽度标准化，包含狗的框的预测$b_x$和$b_y$是$（0.3，0.8）$，那么$13 \\times 13$特征图上的实际宽度和高度是$（13 \\times 0.3,13 \\times 0.8）$\n",
        "</font>\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo-regression-1.png)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>Score</font>  \n",
        "<font face=楷体>\n",
        "对象得分通过sigmoid转换到0、1之间，可以解释为概率  \n",
        "</font>  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>Class Confidences</font>   \n",
        "<font face=楷体>\n",
        "v3使用sigmoid代替softmax进行分类，原因是Softmax假设所有类别是互斥的，即：如果一个对象属于一个类，那么就一定不属于另一个类（COCO数据库是可以的但如：医生和人就不成立了）  \n",
        "</font>   \n",
        "<font face=楷体 color=skyblue size=4>多尺度预测</font>   \n",
        "<font face=楷体>\n",
        "基于三种不同尺寸的特征图进行检测，<font color=skyblue>有助于检测小物体</font>。如：输入尺寸为$416 \\times 416$，在$13 \\times 13,26 \\times 26,52 \\times 52$的特诊图上进行检测  \n",
        "每个尺度上，每个单元格使用3个anchors预测3个边界框，使得使用的anchors总数为9.（<font color=skyblue>不同尺度上的anchors不同</font>）  \n",
        "</font> \n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo_Scales-1.png)  \n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=5>输出处理</font>  \n",
        "<font face=楷体>  \n",
        "对于尺寸为$416\\times 416$的图像，YOLO预测$（（52\\times 52）+（26\\times 26）+ 13\\times 13））×3 = 10647$个边界框  \n",
        "<font color=skyblue>\n",
        "通过对象置信度进行阈值处理  \n",
        "非极大抑制（NMS）\n",
        "</font>\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxR9iVyej3rh",
        "colab_type": "text"
      },
      "source": [
        "# Darknet.py  \n",
        "<font face=楷体>\n",
        "Darknet是YOLO底层架构的名称，darknet.py包含YOLO网络的代码（util.py将包含各种辅助函数的代码）\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9zJJFZXNrRn",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 解析配置文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lee0sSfNRGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#from util import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJVXBiSkN-HH",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "定义一个函数 parse_cfg，用配置文件的路径作为输入  \n",
        "    \n",
        "将 <font color=skyblue size=4>**Net 、  Convolutional  、 Shortcut  、Upsample 、 Route 、 YOLO**</font> 以列表（blocks）的形式返回\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy3tzMrnNeyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_cfg(cfgfile):\n",
        "    \"\"\"\n",
        "    Takes a configuration file\n",
        "    Returns a list of blocks. Each blocks describes a block in the neural\n",
        "    network to be built. Block is represented as a dictionary in the list    \n",
        "    \"\"\"\n",
        "    file = open(cfgfile, 'r')\n",
        "    lines = file.read().split('\\n')                        # store the lines in a list\n",
        "    lines = [x for x in lines if len(x) > 0]               # get read of the empty lines \n",
        "    lines = [x for x in lines if x[0] != '#']              # get rid of comments\n",
        "    lines = [x.rstrip().lstrip() for x in lines]           # get rid of fringe whitespaces\n",
        "    \n",
        "    block = {}\n",
        "    blocks = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line[0] == \"[\":               # This marks the start of a new block\n",
        "            if len(block) != 0:          # If block is not empty, implies it is storing values of previous block.\n",
        "                blocks.append(block)     # add it the blocks list\n",
        "                block = {}               # re-init the block\n",
        "            block[\"type\"] = line[1:-1].rstrip()     \n",
        "        else:\n",
        "            key,value = line.split(\"=\") \n",
        "            block[key.rstrip()] = value.lstrip()\n",
        "    blocks.append(block)\n",
        "\n",
        "    return blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-ufryjTP1IG",
        "colab_type": "text"
      },
      "source": [
        "###1.2构建 PyTorch 模块   \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**create_modules 函数用 parse_cfg 函数返回的 blocks 列表构建网络模块：**</font>\n",
        "\n",
        "<font face=楷体>\n",
        "\n",
        "*   先定义变量 net_info，来存储该网络的信息\n",
        "\n",
        "*  当添加 nn.ModuleList 作为 nn.Module 对象的一个成员时（即添加模块到网络），所有 nn.ModuleList 内部的 nn.Module 对象（模块）的 parameter 也被添加   作为 nn.Module 对象（即网络添加 nn.ModuleList 作为其成员）的 parameter\n",
        "\n",
        "*   卷积核的深度是由上一层的卷积核数量（或特征图深度）决定的。这意味着需要持续追踪被应用卷积层的卷积核数量，用变量 prev_filter 实现追踪（RGB3通道所以初始化为3）\n",
        "\n",
        "*  路由层（route layer）从前面层得到特征图，不仅需要追踪前一层的卷积核数量，还需要追踪之前每一层。不断地迭代，将每个模块的输出卷积核数量添加到 output_filters 列表 \n",
        "\n",
        "*  nn.Sequential 类是能让nn.Module 对象有序执行的数字，一个模块可能包含多个层，用 nn.Sequential 将这些层串联起来\n",
        "    \n",
        "</font>  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>   \n",
        "\n",
        "detection = DetectionLayer(anchors)  \n",
        "路由层  \n",
        "YOLO层mask  \n",
        "line87: filters = output_filters[index + start] + output_filters[index + end]\n",
        "line107:  anchors = [anchors[i] for i in mask]   \n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接:**</font>  \n",
        "\n",
        "【1】[nn.Conv2d 、nn.BatchNorm2d](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#torchnn)  \n",
        "【2】[torch.nn.Upsample](https://pytorch.org/docs/stable/nn.html?highlight=nn%20upsample#torch.nn.Upsample)  \n",
        "【3】[darknet 所有层功能说明 ](https://blog.csdn.net/zhuiqiuk/article/details/88187034)   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b40dPOsVPGH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_modules(blocks):\n",
        "    net_info = blocks[0]  # Captures the information about the input and pre-processing\n",
        "    module_list = nn.ModuleList()\n",
        "    index = 0  # indexing blocks helps with implementing route  layers (skip connections)\n",
        "    prev_filters = 3\n",
        "    output_filters = []\n",
        "    \n",
        "    # 迭代模块的列表，并为每个模块创建一个 PyTorch 模块\n",
        "    for index, x in enumerate(blocks[1:]): \n",
        "        module = nn.Sequential()\n",
        "        #check the type of block\n",
        "        #create a new module for the block\n",
        "        #append to module_list\n",
        "        \n",
        "       #创建卷积层\n",
        "       # If it's a convolutional layer\n",
        "        if (x[\"type\"] == \"convolutional\"):\n",
        "            # Get the info about the layer\n",
        "            activation = x[\"activation\"]\n",
        "            try:\n",
        "                batch_normalize = int(x[\"batch_normalize\"])\n",
        "                bias = False\n",
        "            except:\n",
        "                batch_normalize = 0\n",
        "                bias = True\n",
        "\n",
        "            filters = int(x[\"filters\"])\n",
        "            padding = int(x[\"pad\"])\n",
        "            kernel_size = int(x[\"size\"])\n",
        "            stride = int(x[\"stride\"])\n",
        "\n",
        "            if padding:\n",
        "                pad = (kernel_size - 1) // 2\n",
        "            else:\n",
        "                pad = 0\n",
        "\n",
        "            # Add the convolutional layer\n",
        "            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=bias)\n",
        "            module.add_module(\"conv_{0}\".format(index), conv)\n",
        "            \n",
        "            # Add the Batch Norm Layer\n",
        "            if batch_normalize:\n",
        "                bn = nn.BatchNorm2d(filters)\n",
        "                module.add_module(\"batch_norm_{0}\".format(index), bn)\n",
        "\n",
        "            # Check the activation.\n",
        "            # It is either Linear or a Leaky ReLU for YOLO\n",
        "            if activation == \"leaky\":\n",
        "                activn = nn.LeakyReLU(0.1, inplace=True)\n",
        "                module.add_module(\"leaky_{0}\".format(index), activn)\n",
        "\n",
        "        # 构建上采样层\n",
        "        # If it's an upsampling layer\n",
        "        # We use Bilinear2dUpsampling\n",
        "        elif (x[\"type\"] == \"upsample\"):\n",
        "            stride = int(x[\"stride\"])\n",
        "            upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
        "            module.add_module(\"upsample_{}\".format(index), upsample)\n",
        "            \n",
        "\n",
        "        # 路由层\n",
        "        # 当layer为正时，输出对应层特征，为负时，输出当前层前往回数第layer层特征\n",
        "        # If it is a route layer\n",
        "        elif (x[\"type\"] == \"route\"):\n",
        "            x[\"layers\"] = x[\"layers\"].split(',')\n",
        "\n",
        "            # Start  of a route\n",
        "            start = int(x[\"layers\"][0])\n",
        "\n",
        "            # end, if there exists one.\n",
        "            try:\n",
        "                end = int(x[\"layers\"][1])\n",
        "            except:\n",
        "                end = 0\n",
        "\n",
        "            # Positive anotation\n",
        "            if start > 0:\n",
        "                start = start - index\n",
        "\n",
        "            if end > 0:\n",
        "                end = end - index\n",
        "\n",
        "            route = EmptyLayer()\n",
        "            module.add_module(\"route_{0}\".format(index), route)\n",
        "\n",
        "            if end < 0:\n",
        "                filters = output_filters[index + start] + output_filters[index + end]\n",
        "            else:\n",
        "                filters = output_filters[index + start]\n",
        "                \n",
        "        # 捷径层       \n",
        "        # shortcut corresponds to skip connection\n",
        "        if x[\"type\"] == \"shortcut\":\n",
        "            shortcut = EmptyLayer()\n",
        "            module.add_module(\"shortcut_{}\".format(index), shortcut)    \n",
        "                      \n",
        "        \n",
        "        # YOLO层\n",
        "        # Yolo is the detection layer\n",
        "        if x[\"type\"] == \"yolo\":\n",
        "            mask = x[\"mask\"].split(\",\") \n",
        "            mask = [int(x) for x in mask] \n",
        "\n",
        "            anchors = x[\"anchors\"].split(\",\")\n",
        "            anchors = [int(a) for a in anchors]\n",
        "            anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
        "            anchors = [anchors[i] for i in mask]  # 取前三个？？\n",
        "\n",
        "            detection = DetectionLayer(anchors)\n",
        "            module.add_module(\"Detection_{}\".format(index), detection)  \n",
        "            \n",
        "        # 回路结束时，做一些统计（bookkeeping.）\n",
        "        module_list.append(module)\n",
        "        prev_filters = filters\n",
        "        output_filters.append(filters)\n",
        "        \n",
        "    return (net_info, module_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-X6Zb85urR3",
        "colab_type": "text"
      },
      "source": [
        "### 1.3定义网络\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>\n",
        "用 nn.Module 在 PyTorch 中构建自定义架构：  \n",
        "    \n",
        "*   定义nn.Module子类Darknet，用 members、blocks、net_info 和 module_list 进行初始化  \n",
        "\n",
        "*   重写forward方法来实现网络的前向传递nn.Module ：1）计算输出；2）以一种可以更容易处理的方式转换输出检测特征图，例如：将它们转换为可以连接多个尺度的检测图（ self.blocks 的第一个元素是 net 块，不属于前向传播，所以迭代的对象是 self.block[1:]）\n",
        "\n",
        "*   与create_modules函数一样，module_list中包含网络的模块。模块顺序与配置文件中的顺序相同。因此，可以输入通过每个模块就可以简单地得到输出\n",
        "*   路由层需要连接两个特征图谱， torch.cat第二个参数为1（沿着深度连接特征图谱） \n",
        "    \n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxd7AJ1NHmVn",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>加载权重</font>   \n",
        "<font face=楷体 color=skyblue>权重是如何存储：</font>  \n",
        "\n",
        "<font face=楷体>\n",
        "权重只属于<font color=skyblue>批量归一化层（batch norm layer）和卷积层</font>  两种类型的层，储存顺序和配置文件中定义层级的顺序完全相同  \n",
        "    \n",
        "下图展示了权重如何储存：\n",
        "</font>\n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/wts-1.png)\n",
        "\n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "<font face=楷体>\n",
        "\\# 卷积和上采样层\n",
        "if module_type == \"convolutional\" or module_type == \"upsample\":  \n",
        "    x = self.module_list\\[i](x)  \n",
        "    outputs[i] = x   \n",
        "line52: anchors = self.module_list[i][0].anchors\n",
        "line59: x = x.data  \n",
        " *  <font color=skyblue>Variable是tensor的外包装，data属性存储着tensor数据，grad属性存储关于该变量的导数，creator是代表该变量的创造者[$^{【2】}$](https://zhuanlan.zhihu.com/p/34298983)  </font>  \n",
        "\n",
        "line73: outputs[i] = x\n",
        "line74: batch_normalize = int(self.blocks[i + 1][\"batch_normalize\"])  \n",
        "line102:  bn_biases = bn_biases.view_as(bn.bias.data)\n",
        "                \n",
        "</font> \n",
        "<font face=楷体 color=green size=4>绿色链接</font>  \n",
        "【1】[Tensor and tensor.data](https://discuss.pytorch.org/t/tensor-and-tensor-data/18427)  \n",
        "【2】[autograd 及Variable](https://zhuanlan.zhihu.com/p/34298983)  \n",
        "【3】[What about .data?](https://pytorch.org/blog/pytorch-0_4_0-migration-guide/#what-about-data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzhDjzWcZrzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Darknet(nn.Module):\n",
        "    def __init__(self, cfgfile):\n",
        "        super(Darknet, self).__init__()\n",
        "        self.blocks = parse_cfg(cfgfile)\n",
        "        self.net_info, self.module_list = create_modules(self.blocks)\n",
        "        \n",
        "    # 前向传播\n",
        "    def forward(self, x, CUDA):\n",
        "        detections = []\n",
        "        modules = self.blocks[1:]\n",
        "        outputs = {}  # We cache the outputs for the route layer    \n",
        "        \n",
        "        # write表示是否遇到第一个检测\n",
        "        # write=0，收集器未初始化\n",
        "        # write=1，收集器已初始化，只需要将检测图与收集器级联起来即可\n",
        "        write = 0\n",
        "        for i in range(len(modules)):\n",
        "            module_type = (modules[i][\"type\"])    \n",
        "            \n",
        "            # 卷积和上采样层\n",
        "            if module_type == \"convolutional\" or module_type == \"upsample\":\n",
        "                x = self.module_list[i](x)\n",
        "                outputs[i] = x     \n",
        "                \n",
        "            # 路由层\n",
        "            elif module_type == \"route\":\n",
        "                layers = modules[i][\"layers\"]\n",
        "                layers = [int(a) for a in layers]\n",
        "\n",
        "                if (layers[0]) > 0:\n",
        "                    layers[0] = layers[0] - i\n",
        "\n",
        "                if len(layers) == 1:\n",
        "                    x = outputs[i + (layers[0])]\n",
        "\n",
        "                else:\n",
        "                    if (layers[1]) > 0:\n",
        "                        layers[1] = layers[1] - i\n",
        "\n",
        "                    map1 = outputs[i + layers[0]]\n",
        "                    map2 = outputs[i + layers[1]]\n",
        "\n",
        "                    x = torch.cat((map1, map2), 1)\n",
        "                \n",
        "            elif module_type == \"shortcut\":\n",
        "                from_ = int(modules[i][\"from\"])\n",
        "                x = outputs[i - 1] + outputs[i + from_]  # 直接相加，不会改变维度\n",
        "            \n",
        "            # YOLO层\n",
        "            elif module_type == 'yolo':        \n",
        "                anchors = self.module_list[i][0].anchors\n",
        "                #Get the input dimensions\n",
        "                inp_dim = int (self.net_info[\"height\"])\n",
        "\n",
        "                #Get the number of classes\n",
        "                num_classes = int (modules[i][\"classes\"])  # module修改成modules[i]\n",
        "\n",
        "                #Transform \n",
        "                # Variable是tensor的外包装，data属性存储着tensor数据，grad属性存储关于该变量的导数，creator是代表该变量的创造者\n",
        "                x = x.data  # x是一个Variable， x.data 则是一个Tensor\n",
        "                x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n",
        "                if not write:              #if no collector has been intialised. \n",
        "                    detections = x\n",
        "                    write = 1\n",
        "\n",
        "                else:\n",
        "                    # 变换后x的维度是(batch_size, grid_size*grid_size*num_anchors, 5+类别数量)\n",
        "                    # 在维度1上合并，即：按anchor数量的维度拼接\n",
        "                    # 对应教程part3中的Bounding Box attributes图的行进行连接\n",
        "                    # 共有3个yolo层，对于每个yolo层的输出先用predict_transform()转换成每行为一个anchor对应的预测值的形式(忽略batch_size维度，x剩下的可看成二维tensor)\n",
        "                    # 3个yolo层的预测值按照每个方框对应的行的维度进行连接，得到了图片所有anchor预测值，以便后面的NMS等操作可以一次完成\n",
        "                    detections = torch.cat((detections, x), 1)\n",
        "\n",
        "            outputs[i] = x  # 储存每一层特征图谱，以便route层和shortcut层调用\n",
        "\n",
        "        return detections\n",
        "    \n",
        "    # 加载权重            \n",
        "    def load_weights(self, weightfile):\n",
        "        # Open the weights file\n",
        "        fp = open(weightfile, \"rb\")\n",
        "\n",
        "        # 第一个 160 比特的权重文件保存了 5 个 int32 值，它们构成了文件的标头\n",
        "        # The first 4 values are header information\n",
        "        # 1. Major version number\n",
        "        # 2. Minor Version Number\n",
        "        # 3. Subversion number\n",
        "        # 4. IMages seen\n",
        "        header = np.fromfile(fp, dtype=np.int32, count=5)\n",
        "        self.header = torch.from_numpy(header)\n",
        "        self.seen = self.header[3]        \n",
        "        \n",
        "        # The rest of the values are the weights\n",
        "        # Let's load them up\n",
        "        weights = np.fromfile(fp, dtype=np.float32)\n",
        "        \n",
        "        # 循环地加载权重文件到网络的模块上\n",
        "        ptr = 0\n",
        "        for i in range(len(self.module_list)):\n",
        "            module_type = self.blocks[i + 1][\"type\"]\n",
        "\n",
        "            if module_type == \"convolutional\":        \n",
        "                \n",
        "                model = self.module_list[i]\n",
        "                try:\n",
        "                    batch_normalize = int(self.blocks[i + 1][\"batch_normalize\"])  # blocks包括Net，module_list只包含网络层\n",
        "                except:\n",
        "                    batch_normalize = 0\n",
        "\n",
        "                conv = model[0]\n",
        "                \n",
        "                #如果 batch_normalize 检查结果是 True，则我们按以下方式加载权重\n",
        "                if (batch_normalize):\n",
        "                    bn = model[1]\n",
        "\n",
        "                    # Get the number of weights of Batch Norm Layer\n",
        "                    num_bn_biases = bn.bias.numel()\n",
        "\n",
        "                    # Load the weights\n",
        "                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    # Cast the loaded weights into dims of model weights.\n",
        "                    bn_biases = bn_biases.view_as(bn.bias.data)\n",
        "                    bn_weights = bn_weights.view_as(bn.weight.data)\n",
        "                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
        "                    bn_running_var = bn_running_var.view_as(bn.running_var)\n",
        "\n",
        "                    # Copy the data to model\n",
        "                    bn.bias.data.copy_(bn_biases)\n",
        "                    bn.weight.data.copy_(bn_weights)\n",
        "                    bn.running_mean.copy_(bn_running_mean)\n",
        "                    bn.running_var.copy_(bn_running_var)     \n",
        "                    \n",
        "                #如果 batch_normalize 的检查结果不是 True，只需要加载卷积层的偏置项。\n",
        "                else:\n",
        "                    # Number of biases\n",
        "                    num_biases = conv.bias.numel()\n",
        "\n",
        "                    # Load the weights\n",
        "                    conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases])\n",
        "                    ptr = ptr + num_biases\n",
        "\n",
        "                    # reshape the loaded weights according to the dims of the model weights\n",
        "                    conv_biases = conv_biases.view_as(conv.bias.data)\n",
        "\n",
        "                    # Finally copy the data\n",
        "                    conv.bias.data.copy_(conv_biases)\n",
        "                    \n",
        "                # Let us load the weights for the Convolutional layers\n",
        "                num_weights = conv.weight.numel()\n",
        "\n",
        "                # Do the same as above for weights\n",
        "                conv_weights = torch.from_numpy(weights[ptr:ptr + num_weights])\n",
        "                ptr = ptr + num_weights\n",
        "\n",
        "                conv_weights = conv_weights.view_as(conv.weight.data)\n",
        "                conv.weight.data.copy_(conv_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOYbAE6MWOy9",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>**为什么要一个空的层？**</font>  \n",
        "<font face=楷体>\n",
        "*   如果像其它层一样，创建路由层需要构建一个 nn.Module 对象并初始化，然后在 forward 函数中拼接特征图，但拼接操作的代码相当简短（ torch.cat），像其它层一样设计route层将导致不必要的抽象，增加代码。可以用一个空的虚拟层代替路由层，然后 forward 函数中直接执行拼接操作  \n",
        "*   shortcut层是一个简单的add操作，也用一个空的虚拟层代替\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8x1JkOOUBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmptyLayer(nn.Module):\n",
        "     def __init__(self):\n",
        "            super(EmptyLayer, self).__init__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpgGOgn2hspz",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=red size=4> 定义DetectionLayer 保存用于检测边界框的锚点？</font>  \n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接：**</font>  \n",
        "【1】[nn.Module](https://blog.csdn.net/u012609509/article/details/81203436)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArUR8AMhaiZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DetectionLayer(nn.Module):\n",
        "    def __init__(self, anchors):\n",
        "        super(DetectionLayer, self).__init__()\n",
        "        self.anchors = anchors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9mhiasvw3Qx",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>\n",
        "将OpenCV读取图片的数据形式转换成Pytorch格式：  \n",
        "$\\color{pink}{RGB\\Longrightarrow BGR}\\ \\ \\ \\color{skyblue}{\\LARGE \\&}\\ \\color{pink}{\\mathrm 【height \\times width \\times channel】\\Longrightarrow 【channel \\times height \\times width】}$\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks30oz6jLdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_input():\n",
        "    img = cv2.imread(\"dog-cycle-car.png\")\n",
        "    img = cv2.resize(img, (416, 416))  # 调整图片尺寸\n",
        "    img_ = img[:, :, ::-1].transpose((2, 0, 1))\n",
        "    img_ = img_[np.newaxis, :, :, :] / 255.0  # Add a channel at 0 (for batch) | Normalise\n",
        "    img_ = torch.from_numpy(img_).float()  # Convert to float\n",
        "    img_ = Variable(img_)   # Convert to Variable\n",
        "    return img_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywbs55hJkfqm",
        "colab_type": "text"
      },
      "source": [
        "# util.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv5gWoIhygEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITl_JgY6ktoL",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>为解决以下问题，引入函数 predict_transform函数，其5个参数：<font color=pink>prediction（输出）、inp_dim（输入图像的维度）、anchors、num_classes、CUDA flag（可选）</font> </font> \n",
        "<font face=楷体> \n",
        "\n",
        "*   在特征图上进行多尺度预测, 在grid每个位置都有三个不同尺度的锚点.predict_transform()利用一个scale得到的feature map预测得到的每个anchor的属性(x,y,w,h,s,s_cls1,s_cls2...),其中x,y,w,h是在网络输入图片坐标系下的值，s是方框含有目标的置信度得分，s_cls1,s_cls_2等是方框所含目标对应每类的概率 \n",
        "\n",
        "*   输入的feature map(prediction变量) 维度为<font color=pink>【batch_size, num_anchors*bbox_attrs, grid_size, grid_size】</font>(类似于一个batch彩色图片$B\\times C\\times H\\times W$存储方式)，这种格式对于输出处理过程（例如通过目标置信度进行阈值处理、添加对中心的网格偏移、应用锚点等）不方便\n",
        "*   将维度变换成<font color=pink>【batch_size, grid_size*grid_size*num_anchors, 5+类别数量】</font>的tensor，同时得到每个方框在网络输入图片(416x416)坐标系下的(x,y,w,h)以及方框含有目标的得分以及每个类的得分\n",
        "\n",
        "</font>\n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png#pic_center)\n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "line5 : stride = inp_dim // prediction.size(2) 输入图像维度不是多维的吗？\n",
        "line12: prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)\n",
        "line14: anchors = [(a[0] / stride, a[1] / stride) for a in anchors]\n",
        "line32: x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0) \n",
        "line34: prediction[:, :, :2] += x_y_offset\n",
        "line35: x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0)   \n",
        "* [[0 1]\n",
        " [0 1]]\n",
        "[[0 0]\n",
        " [1 1]]\n",
        "\n",
        "tensor([[[0., 0.],\n",
        "         [0., 0.],\n",
        "         [0., 0.],\n",
        "         [1., 0.],\n",
        "         [1., 0.],\n",
        "         [1., 0.],\n",
        "         [0., 1.],\n",
        "         [0., 1.],\n",
        "         [0., 1.],\n",
        "         [1., 1.],\n",
        "         [1., 1.],\n",
        "         [1., 1.]]])\n",
        "line42： anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)\n",
        "line43: prediction[:, :, 2:4] = torch.exp(prediction[:, :, 2:4]) * anchors  \n",
        "line48: prediction[:, :, :4] *= stride\n",
        "\n",
        "\n",
        "<font face=楷体 color=yellow size=4>另一个问题是由于检测是在三个尺度上进行的，预测图的维度将是不同的。虽然三个特征图的维度不同，但对它们执行的输出处理过程是相似的。最好能在单个张量上执行这些运算而不是三个单独张量 ？？？？？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrk0_w3Tklp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_transform(prediction, inp_dim, anchors, num_classes, CUDA=True):\n",
        "    \n",
        "    # 将上图代码化\n",
        "    batch_size = prediction.size(0)  # 参数0代表第一个维度，例如：prediction是二维的时候size(0)等于其行数\n",
        "    stride = inp_dim // prediction.size(2) \n",
        "    grid_size = inp_dim // stride\n",
        "    bbox_attrs = 5 + num_classes\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    prediction = prediction.view(batch_size, bbox_attrs * num_anchors, grid_size * grid_size)\n",
        "    prediction = prediction.transpose(1, 2).contiguous()\n",
        "    prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)  # 将所有anchor按行排列\n",
        "    \n",
        "    # anchors变换到相应feature map中的尺寸\n",
        "    anchors = [(a[0] / stride, a[1] / stride) for a in anchors]\n",
        "    \n",
        "    # Sigmoid the  centre_X, centre_Y. and object confidencce\n",
        "    prediction[:, :, 0] = torch.sigmoid(prediction[:, :, 0])\n",
        "    prediction[:, :, 1] = torch.sigmoid(prediction[:, :, 1])\n",
        "    prediction[:, :, 4] = torch.sigmoid(prediction[:, :, 4])\n",
        "    \n",
        "    # Add the center offsets\n",
        "    grid_len = np.arange(grid_size)\n",
        "    a, b = np.meshgrid(grid_len, grid_len)  # a,b均为grid_len*grid_len矩阵，互为转置关系\n",
        "\n",
        "    x_offset = torch.FloatTensor(a).view(-1, 1)\n",
        "    y_offset = torch.FloatTensor(b).view(-1, 1)\n",
        "\n",
        "    if CUDA:\n",
        "        x_offset = x_offset.cuda()\n",
        "        y_offset = y_offset.cuda()\n",
        "\n",
        "    # x_y_offset对应最终feature map中每个格子的左上角坐标，如：13个格子，则x_y_offset对应为(0,0),(0,1)…(12,12) \n",
        "    # .view(-1, 2)：将tensor变成两列；unsqueeze(0)：0维上添加一个维度\n",
        "    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0)\n",
        "    \n",
        "    # bx=sigmoid(tx)+cx,by=sigmoid(ty)+cy\n",
        "    prediction[:, :, :2] += x_y_offset\n",
        "    \n",
        "    # log space transform height and the width\n",
        "    anchors = torch.FloatTensor(anchors)\n",
        "\n",
        "    if CUDA:\n",
        "        anchors = anchors.cuda()\n",
        "        \n",
        "    anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)  # 将三个anchor复制到每个格子\n",
        "    # bw=p_w×exp(t_w)，bh=p_h×exp(t_h)\n",
        "    prediction[:, :, 2:4] = torch.exp(prediction[:, :, 2:4]) * anchors   \n",
        "    \n",
        "    # Softmax the class scores\n",
        "    prediction[:, :, 5: 5 + num_classes] = torch.sigmoid((prediction[:, :, 5: 5 + num_classes]))   # 计算anchor中每个类别的得分\n",
        "    \n",
        "    prediction[:, :, :4] *= stride  # 将相对于feature map的anchorbox尺寸映射回输入网络图片(416x416)尺度\n",
        "    \n",
        "    return prediction    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u5_qUscsN-5",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>输出满足 objectness 分数阈值和非极大值抑制（NMS），以得到后文所提到的「真实（true）」检测结果  \n",
        "创建一个名为 write_results 的函数  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>\n",
        "~~~\n",
        "line5: conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)\n",
        "line6: prediction = prediction * conf_mask   \n",
        "line32: max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)\n",
        "line34: max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)\n",
        "line35: max_conf = max_conf.float().unsqueeze(1)\n",
        "line37: seq = (image_pred[:, :5], max_conf, max_conf_score)   \n",
        "line38: image_pred = torch.cat(seq, 1)\n",
        "line44: image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)  # ????????????\n",
        "line47: img_classes = unique(image_pred_[:, -1])   \n",
        "line58: cls_mask = image_pred_ * (image_pred_[:, -1] == cls).float().unsqueeze(1)   # unsqueeze(1)??????????????????????????????\n",
        "line78: ious=bbox_iou(image_pred_class[i].unsqueeze(0),image_pred_class[i+1:])???????????????????????????????????????????????????????????? \n",
        "line93: iou_mask = (ious < nms_conf).float().unsqueeze(1)？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0iB2MnDr5-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_results(prediction, confidence, num_classes, nms=True, nms_conf=0.4):\n",
        "\n",
        "    # 预测张量包含有关 B x 10647 边界框的信息\n",
        "    # 对于有低于一个阈值的 objectness 分数的每个边界框，将其每个属性的值（表示该边界框的一整行）都设为零\n",
        "    # confidence: 输入预测shape=(1,10647, 85)——>conf_mask: shape=(1,10647) -----> 增加一维度之后 (1, 10647, 1)\n",
        "    conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)  \n",
        "    # 例如：torch.Size([3, 4, 5])____[:, :, 4]____>torch.Size([3, 4])____unsqueeze(2)___>torch.Size([3, 4, 1])\n",
        "    prediction = prediction * conf_mask   \n",
        "    \n",
        "    # 边界框属性是由中心坐标以及边界框的高度和宽度决定\n",
        "    # 使用每个框的两个对角坐标能更轻松地计算两个框的 IoU\n",
        "    # 将框的 (中心 x, 中心 y, 宽, 高) 属性转换成 (左上角 x, 左上角 y, 右下角 x, 右下角 y)\n",
        "    box_a = prediction.new(prediction.shape)  # 构建一个具有相同类型的新张量作中间变量\n",
        "    \n",
        "    box_a[:, :, 0] = (prediction[:, :, 0] - prediction[:, :, 2] / 2)\n",
        "    box_a[:, :, 1] = (prediction[:, :, 1] - prediction[:, :, 3] / 2)\n",
        "    box_a[:, :, 2] = (prediction[:, :, 0] + prediction[:, :, 2] / 2)\n",
        "    box_a[:, :, 3] = (prediction[:, :, 1] + prediction[:, :, 3] / 2)\n",
        "    prediction[:, :, :4] = box_a[:, :, :4]\n",
        "    \n",
        "    # 每张图像中的「真实」检测结果的数量可能存在差异\n",
        "    # 比如，一个大小为 3 的 batch 中有 1、2、3 这 3 张图像，它们各自有 5、2、4 个「真实」检测结果\n",
        "    # 因此，一次只能完成一张图像的置信度阈值设置和 NMS，不能将所涉及的操作向量化，且必须在预测的第一个维度（包含一个 batch 中图像的索引）上循环\n",
        "    batch_size = prediction.size(0)\n",
        "    write = False\n",
        "    for ind in range(batch_size):\n",
        "        # select the image from the batch\n",
        "        image_pred = prediction[ind]\n",
        "        # confidence threshholding\n",
        "        # NMS    \n",
        "\n",
        "        # Get the class having maximum score, and the index of that class\n",
        "        # Get rid of num_classes softmax scores\n",
        "        # Add the class index and the class score of class having maximum score\n",
        "        # max_conf最大得分，max_conf_score索引\n",
        "        max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)  # axis=1纵向比较，返回行索引\n",
        "        max_conf = max_conf.float().unsqueeze(1)\n",
        "        max_conf_score = max_conf_score.float().unsqueeze(1)\n",
        "        seq = (image_pred[:, :5], max_conf, max_conf_score)\n",
        "        # 将每个框的(x1,y1,x2,y2,s)与最高的类的分数s_cls(max_conf)和对应类的索引index_cls(max_conf_score)在列维度上合并(10647, 5+1+1=7) \n",
        "        image_pred = torch.cat(seq, 1)    \n",
        "        \n",
        "        # Get rid of the zero entries\n",
        "        non_zero_ind = (torch.nonzero(image_pred[:, 4]))  # 返回索引（2维tensor）\n",
        "\n",
        "        try:\n",
        "            image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)  # 保留image_pred中非0目标得分行的所有元素(x1, y1, x2, y2, s,  s_class,index_cls)\n",
        "        except:\n",
        "            continue  # 当没有检测到时目标时，直接进入下一次循环  \n",
        "            \n",
        "        # Get the various classes detected in the image\n",
        "        img_classes = unique(image_pred_[:, -1])  # 最后一列保存的是每个框里物体的类别   \n",
        "        \n",
        "        # WE will do NMS classwise\n",
        "        for cls in img_classes:\n",
        "        \n",
        "            # get the detections with one particular class\n",
        "            cls_mask = image_pred_ * (image_pred_[:, -1] == cls).float().unsqueeze(1)   # unsqueeze(1)??????????????????????????????\n",
        "            class_mask_ind = torch.nonzero(cls_mask[:, -2]).squeeze()  # cls_mask[:,-2]是物体类别分数，torch.nonzero(cls_mask[:,-2])得到的是非零元素的索引\n",
        "\n",
        "            image_pred_class = image_pred_[class_mask_ind].view(-1, 7)  # 保留image_pred中包含cls类别的所有结果，且image_pred第二维度不变\n",
        "            #下一步的nms做准备\n",
        "\n",
        "            # sort the detections such that the entry with the maximum objectness\n",
        "            # confidence is at the top\n",
        "            # torch.sort返回降序数组和索引两个Tensor\n",
        "            conf_sort_index = torch.sort(image_pred_class[:, 4], descending=True)[1]  # [1]表示返回索引\n",
        "            image_pred_class = image_pred_class[conf_sort_index]  # 排序后的索引对应出的bbox的坐标与分数\n",
        "            idx = image_pred_class.size(0)  \n",
        "            \n",
        "            # 执行 NMS\n",
        "                # For each detection\n",
        "            for i in range(idx):\n",
        "                # Get the IOUs of all boxes that come after the one we are looking at\n",
        "                # in the loop\n",
        "                try:\n",
        "                    # image_pred_class为（x，7）二维Tensor，image_pred_class[i]是一个长度为7的Tensor，unsqueeze(0)——>(1,7)变成二维\n",
        "                    ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i + 1:])  # 计算第i个方框和i+1到最终的所有方框的IOU\n",
        "                except ValueError:\n",
        "                    break\n",
        "                    '''\n",
        "                    在for i in range(idx):这个循环中，因为有一些框(在image_pred_class对应一行)会被去掉，image_pred_class行数会减少，\n",
        "                    这样在后面的循环中，idx序号会超出image_pred_class的行数的范围，出现ValueError错误。\n",
        "                    所以当抛出这个错误时，则跳出这个循环，因为此时已经没有更多可以去掉的方框了。\n",
        "                    '''\n",
        "                except IndexError:\n",
        "                    break\n",
        "\n",
        "                # Zero out all the detections that have IoU > treshhold\n",
        "                # 计算出需要保留的item（保留ious < nms_conf的框）\n",
        "                #ious < nms_conf得到的是torch.uint8类型，转换为float\n",
        "                #要与image_pred_class[i+1:]相乘，故将长度为7的tensor添加一个维度变成7x1\n",
        "                iou_mask = (ious < nms_conf).float().unsqueeze(1)\n",
        "                image_pred_class[i + 1:] *= iou_mask  # IOU大于阈值的框的预测值全部变成0.得出需要保留的框\n",
        "\n",
        "                # Remove the non-zero entries\n",
        "                non_zero_ind = torch.nonzero(image_pred_class[:, 4]).squeeze()  # 返回得分为非0的方框的索引\n",
        "                image_pred_class = image_pred_class[non_zero_ind].view(-1, 7)  # 得到得分非0框的预测值(x1, y1, x2, y2, s,  s_class,index_cls)\n",
        "                #当前类执行完nms后，下一次循环将对剩下的方框中得分第i+1高的方框进行NMS操作，直到最后一个方框循环完成为止、\n",
        "                    \n",
        "            # 将所得到的检测结果加入到输出张量中\n",
        "            # 创建一个image_pred_class类型相同的tensor，其行数等于cls这个类别NMS剩下的框的个数，即image_pred_class的行数，列数为1\n",
        "            batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)  #用类别代号填充\n",
        "            seq = batch_ind, image_pred_class\n",
        "            # 用write标签来表示张量是否初始化\n",
        "            # 在类别上迭代的循环结束时，将所得到的检测结果合并成输出\n",
        "            if not write:\n",
        "                output = torch.cat(seq, 1)\n",
        "                write = True\n",
        "            else:\n",
        "                out = torch.cat(seq, 1)\n",
        "                output = torch.cat((output, out))     \n",
        "                \n",
        "    try:\n",
        "        return output\n",
        "    except:\n",
        "        return 0               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJOaAfrtujlm",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>同一类别可能会有多个「真实」检测结果，用 unique 函数来去除重复的元素，获取任意给定图像中存在的类别</font>  \n",
        "\n",
        "疑问"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi5iCRlduhDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unique(tensor):\n",
        "    tensor_np = tensor.cpu().numpy()\n",
        "    unique_np = np.unique(tensor_np)  # np.unique去除数组中重复数字，并进行排序\n",
        "    unique_tensor = torch.from_numpy(unique_np)\n",
        "\n",
        "    tensor_res = tensor.new(unique_tensor.shape)\n",
        "    tensor_res.copy_(unique_tensor)\n",
        "    return tensor_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntmMbWb4QD3s",
        "colab_type": "text"
      },
      "source": [
        "**计算IOU**\n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "\n",
        "line19: inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape).cuda()) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape).cuda())\n",
        "b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1) #加1？？？？？、"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqt-jypvP3AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bbox_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Returns the IoU of two bounding boxes\n",
        "\n",
        "    \"\"\"\n",
        "    # Get the coordinates of bounding boxes\n",
        "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
        "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
        "\n",
        "    # get the corrdinates of the intersection rectangle\n",
        "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
        "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
        "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
        "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
        "\n",
        "    # Intersection area\n",
        "    if torch.cuda.is_available():\n",
        "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape).cuda()) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape).cuda())\n",
        "    else:\n",
        "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape)) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape))\n",
        "\n",
        "    # Union Area\n",
        "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
        "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
        "\n",
        "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T-Dj2A3YoMw",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将每个类的索引映射到它的名称字符串，并以字典的形式返回</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问</font>  \n",
        "返回字典？？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBDvlQStYiV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_classes(namesfile):\n",
        "    fp = open(namesfile, \"r\")\n",
        "    names = fp.read().split(\"\\n\")[:-1]\n",
        "    return names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_m7LEHMwquE",
        "colab": {}
      },
      "source": [
        "#def get_test_input():\n",
        "#    img = cv2.imread(\"img/dog-cycle-car.png\")\n",
        "#    img = cv2.resize(img, (416, 416))\n",
        "#    img_ = img[:, :, ::-1].transpose((2, 0, 1))\n",
        "#    img_ = img_[np.newaxis, :, :, :] / 255.0\n",
        "#    img_ = torch.from_numpy(img_).float()\n",
        "#    img_ = Variable(img_)\n",
        "#    return img_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMyv_0JKc7RU",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>OpenCV以numpy数组的形式加载图像，BGR作为颜色通道的顺序。PyTorch的图像输入格式为：<font color=pink>**【批量x通道x高x宽】通道顺序为RGB**</font>  \n",
        "因此，用函数prep_image将numpy数组转换为PyTorch的输入格式</font>  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问</font>  \n",
        "~~~\n",
        "line8: img = cv2.resize(img, (inp_dim, inp_dim))？？？？？？？？？？？？？？？？？？？？？？？？？\n",
        "line9: img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr2WGCivdyCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_image(img, inp_dim):\n",
        "    \"\"\"\n",
        "    Prepare image for inputting to the neural network. \n",
        "    \n",
        "    Returns a Variable \n",
        "    \"\"\"\n",
        "\n",
        "    img = (letterbox_image(img, (inp_dim, inp_dim)))\n",
        "    img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "    img = torch.from_numpy(img).float().div(255.0).unsqueeze(0) # 1x3x416x416\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjO1R_Tvd2tN",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>函数letterbox_image调整图像的大小，保持长宽比一致，并用颜色填充未填充的区域(128,128,128)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y51mHzwac64O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def letterbox_image(img, inp_dim):\n",
        "    '''resize image with unchanged aspect ratio using padding'''\n",
        "    img_w, img_h = img.shape[1], img.shape[0]\n",
        "    w, h = inp_dim  # 目标尺寸\n",
        "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
        "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
        "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)  # 假设：inp_dim：416x416----> 768 x 576的图片缩放成416x312\n",
        "    # 创建画布\n",
        "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
        "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
        "    \n",
        "    return canvas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9LL9UqISMwe",
        "colab_type": "text"
      },
      "source": [
        "# detector.py  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zNC0-wyRB54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 \n",
        "#from util import *\n",
        "import argparse\n",
        "import os \n",
        "import os.path as osp\n",
        "#from darknet import Darknet\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEMMAuQ4SzWm",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>**检测文件需要传递命令行参数，用python的ArgParse模块来实现**</font>  \n",
        "<font face=楷体>\n",
        "如：python detect.py --images dog-cycle-car.png --det det\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZpZolRSUXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def arg_parse():\n",
        "    \"\"\"\n",
        "    Parse arguements to the detect module\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description='YOLO v3 Detection Module')\n",
        "    \n",
        "    parser.add_argument(\"--images\", dest = 'images', help = \n",
        "                        \"Image / Directory containing images to perform detection upon\",\n",
        "                        default = \"imgs\", type = str)\n",
        "    parser.add_argument(\"--det\", dest = 'det', help = \n",
        "                        \"Image / Directory to store detections to\",\n",
        "                        default = \"det\", type = str)\n",
        "    parser.add_argument(\"--bs\", dest = \"bs\", help = \"Batch size\", default = 1)\n",
        "    parser.add_argument(\"--confidence\", dest = \"confidence\", help = \"Object Confidence to filter predictions\", default = 0.5)\n",
        "    parser.add_argument(\"--nms_thresh\", dest = \"nms_thresh\", help = \"NMS Threshhold\", default = 0.4)\n",
        "    parser.add_argument(\"--cfg\", dest = 'cfgfile', help = \n",
        "                        \"Config file\",\n",
        "                        default = \"cfg/yolov3.cfg\", type = str)\n",
        "    parser.add_argument(\"--weights\", dest = 'weightsfile', help = \n",
        "                        \"weightsfile\",\n",
        "                        default = \"yolov3.weights\", type = str)\n",
        "    parser.add_argument(\"--reso\", dest = 'reso', help = \n",
        "                        \"Input resolution of the network. Increase to increase accuracy. Decrease to increase speed\",\n",
        "                        default = \"416\", type = str)\n",
        "    \n",
        "    return parser.parse_args() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYG2CumsSUU6",
        "colab_type": "code",
        "outputId": "083695f4-0b43-4cc8-b479-adcc4903aeb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "args = arg_parse()\n",
        "images = args.images\n",
        "batch_size = int(args.bs)\n",
        "confidence = float(args.confidence)\n",
        "nms_thesh = float(args.nms_thresh)\n",
        "start = 0\n",
        "CUDA = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--images IMAGES] [--det DET] [--bs BS]\n",
            "                             [--confidence CONFIDENCE]\n",
            "                             [--nms_thresh NMS_THRESH] [--cfg CFGFILE]\n",
            "                             [--weights WEIGHTSFILE] [--reso RESO]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-1a290c87-d307-452f-ac75-5c0d3fb8750d.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSrwPpT-YAUx",
        "colab_type": "text"
      },
      "source": [
        "**加载the class file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKKwxW4WX01X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 80    #For COCO\n",
        "classes = load_classes(\"data/coco.names\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CPsrYTkY6pL",
        "colab_type": "text"
      },
      "source": [
        "**初始化网络并加载权重**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg97uOOaSUSU",
        "colab_type": "code",
        "outputId": "8e8a6d1f-ac0f-4b65-dbeb-902298254c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "#Set up the neural network\n",
        "print(\"Loading network.....\")\n",
        "model = Darknet(args.cfgfile)\n",
        "model.load_weights(args.weightsfile)\n",
        "print(\"Network successfully loaded\")\n",
        "\n",
        "model.net_info[\"height\"] = args.reso\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0 \n",
        "assert inp_dim > 32\n",
        "\n",
        "#If there's a GPU availible, put the model on GPU\n",
        "if CUDA:\n",
        "    model.cuda()\n",
        "\n",
        "#Set the model in evaluation mode\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-3382d68fd88c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading network.....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightsfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Network successfully loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X07VlBwZI4X",
        "colab_type": "text"
      },
      "source": [
        "**读取输入图像**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-E5JhMQSUPo",
        "colab_type": "code",
        "outputId": "dc130dbb-20c5-45ed-f332-1d5df10cda36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "read_dir = time.time()\n",
        "#Detection phase\n",
        "try:\n",
        "    imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
        "except NotADirectoryError:\n",
        "    imlist = []\n",
        "    imlist.append(osp.join(osp.realpath('.'), images))\n",
        "except FileNotFoundError:\n",
        "    print (\"No file or directory with the name {}\".format(images))\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-0db93eeaf3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Detection phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNotADirectoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FirEvFSxb6LR",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>如果保存检测的目录(由det标志定义)，不存在则创建它</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud4WkPC1SUMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(args.det):\n",
        "    os.makedirs(args.det)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sEmSpYdcQHV",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>用OpenCV加载图像</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pyKkfzHSUJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_batch = time.time()\n",
        "loaded_ims = [cv2.imread(x) for x in imlist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol6dqwdJcmux",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>除转换后的图像，还保留了原始图像列表和im_dim_list，后者包含原始图像的维度</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "line7：im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DPa7l-qSUGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch Variables for images\n",
        "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))  # prep_image函数需要两个参数\n",
        "\n",
        "#List containing dimensions of original images\n",
        "#opencv读入的图片矩阵对应的是 HxWxC，im_dim_list：【W x H】\n",
        "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "\n",
        "if CUDA:\n",
        "    im_dim_list = im_dim_list.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3lSNMLexMy",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>创建批次（batches）</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "line6：:num_batches = len(imlist) // batch_size + leftover            \n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                       len(im_batches))]))  for i in range(num_batches)]   \n",
        "                       \n",
        "                       \n",
        "Variable(batch)将图片生成一个可导tensor，现在已经不再支持这种写法，Autograd automatically supports Tensors with requires_grad set to True。  \n",
        "prediction是一个batch所有图片通过yolov3模型得到的预测值，维度为1x10647x85，三个scale的图片每个scale的特征图大小为13x13,26x26,52x52,一个元素看作一个格子，每个格子有3个anchor，将一个anchor保存为一行，  \n",
        "所以prediction一共有(13x13+26x26+52x52)x3=10647行，一个anchor预测(x,y,w,h,s,s_cls1,s_cls2...s_cls_80)，一共有85个元素。所以prediction的维度为Bx10647x85，加为这里batch_size为1，所以prediction的维度为1x10647x85\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8etRYGmewB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "leftover = 0\n",
        "if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "\n",
        "if batch_size != 1:\n",
        "    num_batches = len(imlist) // batch_size + leftover   \n",
        "    # 最后一个batch如果用(i + 1)*batch_size索引可能会超过图片数量len(im_batches)，所以取两者最小\n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                       len(im_batches))]))  for i in range(num_batches)]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ0U_svSnKkv",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=yellow size=4>疑问</font>  \n",
        "line9: prediction = model(Variable(batch, volatile = True), CUDA)  \n",
        "line49: objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL0u1zAoi3Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write = 0\n",
        "start_det_loop = time.time()\n",
        "for i, batch in enumerate(im_batches):\n",
        "    #load the image \n",
        "    start = time.time()\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "    with torch.no_grad():\n",
        "        # Variable(batch)将图片生成一个可导tensor，现在已经不再支持这种写法\n",
        "        # prediction是一个batch所有图片通过yolov3模型得到的预测值，维度为1x10647x85\n",
        "        # 三个scale的图片每个scale的特征图大小为13x13,26x26,52x52,一个元素看作一个格子，每个格子有3个anchor，将一个anchor保存为一行\n",
        "        # prediction共有(13x13+26x26+52x52)x3=10647行，一个anchor预测(x,y,w,h,s,s_cls1,s_cls2...s_cls_80)，一共有85个元素\n",
        "        # prediction的维度为Bx10647x85，这里batch_size为1，所以prediction的维度为1x10647x85\n",
        "        prediction = model(Variable(batch, volatile = True), CUDA)\n",
        "\n",
        "    # 经过NMS筛选，每个框属性为(ind,x1,y1,x2,y2,s,s_cls,index_cls) ind:batch序号，x1,y1左上角坐标，x2,y2右下角坐标\n",
        "    # s框是否有目标的得分，s_cls框中所含目标最可能类别的概率得分，index_cls类别代号，prediction维度3x8，则表示有3个框\n",
        "    prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "     # 如果write_results()返回一个batch的结果是int(0)，表没检测到目标，用continue跳过本次循环\n",
        "    if type(prediction) == int:\n",
        "\n",
        "        # 在imlist中遍历一个batch所有的图片对应的元素(存储位置和名字)，同时返回图片在该batch中的序号im_num\n",
        "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "            # 计算图片在imlist中所对应的序号,即在所有图片中的序号\n",
        "            im_id = i*batch_size + im_num\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        continue\n",
        "\n",
        "    # prediction[:,0]取出每个框在所在图片的序号（第i个batch中的图片序号）\n",
        "    # 加上i*batch_size，batch中的图片序号——>图片在imlist中的序号\n",
        "    prediction[:,0] += i * batch_size    #transform the atribute from index in batch to index in imlist \n",
        "\n",
        "    # 因为空的变量不能与tensor连接，用write标记是否是第一次得到输出结果\n",
        "    if not write:                      # If we have't initialised output\n",
        "        output = prediction  \n",
        "        write = 1\n",
        "    else:\n",
        "        # output将每个batch的输出结果在0维进行连接\n",
        "        output = torch.cat((output,prediction))\n",
        "\n",
        "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "        im_id = i * batch_size + im_num\n",
        "        # objs列表包含本批次图片中所有框检测到的目标的类别名称\n",
        "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "    if CUDA:\n",
        "        torch.cuda.synchronize()  # 保证gpu和cpu同步，否则 GPU 工作还未完成， CUDA 核就将控制返回给 CPU（异步调用）       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxNUy-G4jaiF",
        "colab_type": "text"
      },
      "source": [
        "**在图像上绘制边框**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crKUzXlZjZs7",
        "colab_type": "code",
        "outputId": "070e9744-cbd1-427a-fc1c-5a27d12554a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "    output\n",
        "except NameError:\n",
        "    print (\"No detections were made\")\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No detections were made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P9j9C2cj6_1",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>在绘制边界框之前，输出张量中包含的预测符合网络的输入大小，而不是图像的原始大小。因此，在绘制边界框之前，要将每个边界框的角属性转换为图像的原始维度  \n",
        "在绘制边界框之前，输出张量中包含的预测是对填充图像的预测，而不是对原始图像的预测。仅仅将它们重新缩放到输入图像的维数在这里是行不通的。首先，我们需要转换要测量的框的坐标相对于包含原始图像的填充图像上区域的边界。\n",
        "</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "lime15：output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExUgc2Gnj4er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# im_dim_list为4维tensor，一行的元素为(W,H,W,H)，与后面计算x1,y1,x2,y2各自对应的缩放系数时相对应\n",
        "# .index_select()即在im_dim_list中查找output中每行所对应框所在图片在所有图片中的序号所对应im_dim_list中的那行\n",
        "# im_dim_list的行数应该与output的行数相同\n",
        "im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())  # torch.index_select(data, dim, indices)\n",
        "\n",
        "# 将框的坐标转换为相对于填充后的图片中包含原始图片区域的计算方式。\n",
        "# min(416/im_dim_list, 1): 416除以im_dim_list中的每个元素，从得到的tensor的第1维(每行)找到最小元素，并返回（ torch.min 返回tuple， [0]：value；[1]：索引）\n",
        "# 这里没有设置keepdim=True，返回的的最小元素的tensor维度比原来减一\n",
        "# view(-1, 1)变成了【n x 1】维tensor，scaling_factor的每个元素就对应一张图片缩放成416的时候所采用的缩放系数（默认416）  \n",
        "scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)  \n",
        "\n",
        "# 将相对于输入网络图片(416x416)的方框属性变换成原图按照纵横比不变进行缩放后的区域的坐标。\n",
        "# scaling_factor*img_w和scaling_factor*img_h是图片按照纵横比不变进行缩放后的图片，即原图是768x576按照纵横比长边不变缩放到了416*372。\n",
        "# 经坐标换算,得到的坐标还是在输入网络的图片(416x416)坐标系下的绝对坐标，但是此时已经是相对于416*372这个区域的坐标了，而不再相对于(0,0)原点。\n",
        "output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2  # x1=x1−(416−scaling_factor*img_w)/2,x2=x2-(416−scaling_factor*img_w)/2\n",
        "output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2  # y1=y1-(416−scaling_factor*img_h)/2,y2=y2-(416−scaling_factor*img_h)/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu4IMf9okfDl",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "现在，坐标符合填充区域上图像的尺寸。然而，在函数letterbox_image中，通过缩放因子调整了图像的两个维度的大小(两个维度都用一个公共因子来划分，以保持长宽比)，现在要撤消这个，重新缩放，以获得原始图像上的边框的坐标\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTzTjKDkeHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 直接除以缩放系数，将框坐标(x1,y1,x2,y2)映射到原始图片上\n",
        "output[:,1:5] /= scaling_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7SG247keR7",
        "colab_type": "text"
      },
      "source": [
        "Let us now clip any bounding boxes that may have boundaries outside the image to the edges of our image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZcvEtAhkdi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 如果映射回原始图片中的坐标超过了原始图片的区域，x1,x2小于0.0，令x1,x2为0.0，x1,x2大于原始图片宽度，令x1,x2大小为图片的宽度，y坐标同理\n",
        "# clamp()函数就是将第一个输入对数的值限定在后面两个数字的区间\n",
        "for i in range(output.shape[0]):\n",
        "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
        "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyrG0_tlP63",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>用不同的颜色画框</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArA6ATSlUp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_load = time.time()\n",
        "colors = pkl.load(open(\"pallete\", \"rb\"))  # pallete：100种颜色"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8N5Z_EHlifE",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "开始画框\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2_GrGllNoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw = time.time()\n",
        "\n",
        "# x为映射到原始图片中一个框的属性(ind,x1,y1,x2,y2,s,s_cls,index_cls)\n",
        "# results列表保存了所有测试图片，一个元素对应一张图片\n",
        "def write(x, results, color):\n",
        "    c1 = tuple(x[1:3].int())  # c1为方框左上角坐标x1,y1\n",
        "    c2 = tuple(x[3:5].int())  # c2为方框右下角坐标x2,y2\n",
        "    img = results[int(x[0])]  # 在results中找到框所对应的图片\n",
        "    cls = int(x[-1])\n",
        "    label = \"{0}\".format(classes[cls])\n",
        "    cv2.rectangle(img, c1, c2,color, 1)\n",
        "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4  # 得到目标名字的框，在右下角2x,y方向上分别加了3、4个像素\n",
        "    cv2.rectangle(img, c1, c2,color, -1)  # 在图片上画一个实心框\n",
        "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1)  # 在实心框显示标签，(c1[0], c1[1] + t_size[1] + 4)为字符串的左下角坐标\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17VPeFy7mBJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 开始绘制所有框包括目标名字\n",
        "# x是output中的一行，维度为1x8\n",
        "# loaded_ims列表保存了所有图片内容数组,一个元素对应一张图片\n",
        "# 原地修改loaded_ims 中图像\n",
        "list(map(lambda x: write(x, loaded_ims), output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_M64LCdmJh4",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>通过在图像名称前面加上前缀“det_”保存每个图像。我们创建一个地址列表，并将检测图像保存到其中</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(args.det,x.split(\"/\")[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bHr484mCYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将带框的测试图片重命名\n",
        "# det_names 是series对象，类似于列表，pd.Series(imlist)返回一个series对象\n",
        "# 对于imlist这个列表(保存的是所有测试图片的绝对路径+名字，一个元素对应一张图片路径加名字)，生成的series对象包含两列，一列是每个imlist元素的索引，一列是 imlist 元素。\n",
        "# apply()函数将这个series对象传递给apply()里面的函数，以遍历的方式进行。apply()返回结果是经过 apply()里面的函数返回每张测试图片将要保存的文件路径，这里依然是一个series对象\n",
        "# x是Series()返回的对象中的一个元素，即一张图片的绝对路径加名字，args.det是将要保存图片的文件夹(默认det)，返回”det/det_图片名”,x.split(\"/\")[-1]中的 ”/” 是linux下文件路径分隔符\n",
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(args.det,x.split(\"/\")[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IhKhxz5mRwa",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "最后，用det_names将检测到的图像写入地址\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qRen6JRmNE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 保存标注框和目标类别的图片\n",
        "# det_names对应所有测试图片的保存路径，loaded_ims对应所有标注了框和目标名字的图片数组\n",
        "list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i_ifQCgmdZO",
        "colab_type": "text"
      },
      "source": [
        "**打印Time Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG4-OMO3mcyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"SUMMARY\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "print()\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhJpd_NHrl3a",
        "colab_type": "text"
      },
      "source": [
        "# 测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "141yClAmRMlU",
        "colab_type": "text"
      },
      "source": [
        "**测试一**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHqJZq-L3Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir cfg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl6s49f_QUuX",
        "colab_type": "code",
        "outputId": "c84e47e6-4ced-42d9-946f-e83db4a0cac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd cfg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAOk32apZse",
        "colab_type": "code",
        "outputId": "07e354e7-ae01-44e1-b119-617417586408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "blocks = parse_cfg(\"yolov3.cfg\")\n",
        "print(create_modules(blocks))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-08 11:23:41--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "\ryolov3.cfg            0%[                    ]       0  --.-KB/s               \ryolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-08 11:23:41 (98.1 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n",
            "({'type': 'net', 'batch': '64', 'subdivisions': '16', 'width': '608', 'height': '608', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, ModuleList(\n",
            "  (0): Sequential(\n",
            "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (4): Sequential(\n",
            "    (shortcut_4): EmptyLayer()\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (8): Sequential(\n",
            "    (shortcut_8): EmptyLayer()\n",
            "  )\n",
            "  (9): Sequential(\n",
            "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (10): Sequential(\n",
            "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (11): Sequential(\n",
            "    (shortcut_11): EmptyLayer()\n",
            "  )\n",
            "  (12): Sequential(\n",
            "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (13): Sequential(\n",
            "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (14): Sequential(\n",
            "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (15): Sequential(\n",
            "    (shortcut_15): EmptyLayer()\n",
            "  )\n",
            "  (16): Sequential(\n",
            "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (17): Sequential(\n",
            "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (18): Sequential(\n",
            "    (shortcut_18): EmptyLayer()\n",
            "  )\n",
            "  (19): Sequential(\n",
            "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (20): Sequential(\n",
            "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (21): Sequential(\n",
            "    (shortcut_21): EmptyLayer()\n",
            "  )\n",
            "  (22): Sequential(\n",
            "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (23): Sequential(\n",
            "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (24): Sequential(\n",
            "    (shortcut_24): EmptyLayer()\n",
            "  )\n",
            "  (25): Sequential(\n",
            "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (26): Sequential(\n",
            "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (27): Sequential(\n",
            "    (shortcut_27): EmptyLayer()\n",
            "  )\n",
            "  (28): Sequential(\n",
            "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (29): Sequential(\n",
            "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (30): Sequential(\n",
            "    (shortcut_30): EmptyLayer()\n",
            "  )\n",
            "  (31): Sequential(\n",
            "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (32): Sequential(\n",
            "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (33): Sequential(\n",
            "    (shortcut_33): EmptyLayer()\n",
            "  )\n",
            "  (34): Sequential(\n",
            "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (35): Sequential(\n",
            "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (36): Sequential(\n",
            "    (shortcut_36): EmptyLayer()\n",
            "  )\n",
            "  (37): Sequential(\n",
            "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (38): Sequential(\n",
            "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (39): Sequential(\n",
            "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (40): Sequential(\n",
            "    (shortcut_40): EmptyLayer()\n",
            "  )\n",
            "  (41): Sequential(\n",
            "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (42): Sequential(\n",
            "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (43): Sequential(\n",
            "    (shortcut_43): EmptyLayer()\n",
            "  )\n",
            "  (44): Sequential(\n",
            "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (45): Sequential(\n",
            "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (46): Sequential(\n",
            "    (shortcut_46): EmptyLayer()\n",
            "  )\n",
            "  (47): Sequential(\n",
            "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (48): Sequential(\n",
            "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (49): Sequential(\n",
            "    (shortcut_49): EmptyLayer()\n",
            "  )\n",
            "  (50): Sequential(\n",
            "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (51): Sequential(\n",
            "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (52): Sequential(\n",
            "    (shortcut_52): EmptyLayer()\n",
            "  )\n",
            "  (53): Sequential(\n",
            "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (54): Sequential(\n",
            "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (55): Sequential(\n",
            "    (shortcut_55): EmptyLayer()\n",
            "  )\n",
            "  (56): Sequential(\n",
            "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (57): Sequential(\n",
            "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (58): Sequential(\n",
            "    (shortcut_58): EmptyLayer()\n",
            "  )\n",
            "  (59): Sequential(\n",
            "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (60): Sequential(\n",
            "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (61): Sequential(\n",
            "    (shortcut_61): EmptyLayer()\n",
            "  )\n",
            "  (62): Sequential(\n",
            "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (63): Sequential(\n",
            "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (64): Sequential(\n",
            "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (65): Sequential(\n",
            "    (shortcut_65): EmptyLayer()\n",
            "  )\n",
            "  (66): Sequential(\n",
            "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (67): Sequential(\n",
            "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (68): Sequential(\n",
            "    (shortcut_68): EmptyLayer()\n",
            "  )\n",
            "  (69): Sequential(\n",
            "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (70): Sequential(\n",
            "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (71): Sequential(\n",
            "    (shortcut_71): EmptyLayer()\n",
            "  )\n",
            "  (72): Sequential(\n",
            "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (73): Sequential(\n",
            "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (74): Sequential(\n",
            "    (shortcut_74): EmptyLayer()\n",
            "  )\n",
            "  (75): Sequential(\n",
            "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (76): Sequential(\n",
            "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (77): Sequential(\n",
            "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (78): Sequential(\n",
            "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (79): Sequential(\n",
            "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (80): Sequential(\n",
            "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (81): Sequential(\n",
            "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (82): Sequential(\n",
            "    (Detection_82): DetectionLayer()\n",
            "  )\n",
            "  (83): Sequential(\n",
            "    (route_83): EmptyLayer()\n",
            "  )\n",
            "  (84): Sequential(\n",
            "    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (85): Sequential(\n",
            "    (upsample_85): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (86): Sequential(\n",
            "    (route_86): EmptyLayer()\n",
            "  )\n",
            "  (87): Sequential(\n",
            "    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (88): Sequential(\n",
            "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (89): Sequential(\n",
            "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (90): Sequential(\n",
            "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (91): Sequential(\n",
            "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (92): Sequential(\n",
            "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (93): Sequential(\n",
            "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (94): Sequential(\n",
            "    (Detection_94): DetectionLayer()\n",
            "  )\n",
            "  (95): Sequential(\n",
            "    (route_95): EmptyLayer()\n",
            "  )\n",
            "  (96): Sequential(\n",
            "    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (97): Sequential(\n",
            "    (upsample_97): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (98): Sequential(\n",
            "    (route_98): EmptyLayer()\n",
            "  )\n",
            "  (99): Sequential(\n",
            "    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (100): Sequential(\n",
            "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (101): Sequential(\n",
            "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (102): Sequential(\n",
            "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (103): Sequential(\n",
            "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (104): Sequential(\n",
            "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (105): Sequential(\n",
            "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (106): Sequential(\n",
            "    (Detection_106): DetectionLayer()\n",
            "  )\n",
            "))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxUQC1SQmqwG",
        "colab_type": "code",
        "outputId": "148cebcc-1f1a-466f-a944-99acd49255e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd ../"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-uY09vjRf4e",
        "colab_type": "text"
      },
      "source": [
        "**测试二**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr8e5SZBSOG2",
        "colab_type": "code",
        "outputId": "810bf9da-7268-4d10-bd97-0adefd2427c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "!wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-08 11:23:47--  https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png [following]\n",
            "--2019-09-08 11:23:48--  https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347445 (339K) [image/png]\n",
            "Saving to: ‘dog-cycle-car.png’\n",
            "\n",
            "dog-cycle-car.png   100%[===================>] 339.30K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-09-08 11:23:49 (6.51 MB/s) - ‘dog-cycle-car.png’ saved [347445/347445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ75VYVJSWf0",
        "colab_type": "code",
        "outputId": "a704d9d1-3fe0-47ee-dea9-773640a264c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "model = Darknet(\"cfg/yolov3.cfg\")\n",
        "inp = get_test_input()\n",
        "pred = model(inp, torch.cuda.is_available())\n",
        "print (pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c9918410a511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cfg/yolov3.cfg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e57c68f2773c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, CUDA)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m# Variable是tensor的外包装，data属性存储着tensor数据，grad属性存储关于该变量的导数，creator是代表该变量的创造者\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m  \u001b[0;31m# x是一个Variable， x.data 则是一个Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;31m#if no collector has been intialised.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e0464f601d46>\u001b[0m in \u001b[0;36mpredict_transform\u001b[0;34m(prediction, inp_dim, anchors, num_classes, CUDA)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# bx=sigmoid(tx)+cx,by=sigmoid(ty)+cy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx_y_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# log space transform height and the width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected backend CPU and dtype Float but got backend CUDA and dtype Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pATDzJtSWWM",
        "colab_type": "code",
        "outputId": "0b88cf67-9d4d-4b3d-ff96-e3b205b32995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-08 11:24:07--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   222KB/s    in 8m 53s  \n",
            "\n",
            "2019-09-08 11:33:01 (454 KB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4mVJE4nYIRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"yolov3.weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPppKZomfcPZ",
        "colab_type": "text"
      },
      "source": [
        "**测试三**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZl1FtrQwINt",
        "colab_type": "code",
        "outputId": "c576a702-71bc-4dc2-bdee-b0cc090c011c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/pallete"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-08 11:33:03--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/pallete\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 908 [application/octet-stream]\n",
            "Saving to: ‘pallete’\n",
            "\n",
            "\rpallete               0%[                    ]       0  --.-KB/s               \rpallete             100%[===================>]     908  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-08 11:33:04 (72.4 MB/s) - ‘pallete’ saved [908/908]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5fTMYofUG3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNmmX9q9UlM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp dog-cycle-car.png ./images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgDg0jE4j-2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io08_FOElA0s",
        "colab_type": "code",
        "outputId": "1ab94e0f-5879-4c87-888a-5ebbd8885d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAElQnl-lFJ2",
        "colab_type": "code",
        "outputId": "ffd580c8-41dc-468e-bc80-25b3dbe7eb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-08 11:33:15--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "\rcoco.names            0%[                    ]       0  --.-KB/s               \rcoco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-08 11:33:16 (136 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbcqxt8MlIqU",
        "colab_type": "code",
        "outputId": "4b5ca93e-eff4-469f-a2df-2460e3dba405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd ../"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa1ArGLOYICg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "import os\n",
        "import os.path as osp\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJmKLDEGfmPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = \"images\"\n",
        "det = \"det\"\n",
        "cfgfile = \"cfg/yolov3.cfg\"\n",
        "weightsfile = \"yolov3.weights\"\n",
        "batch_size = 1\n",
        "confidence = 0.5\n",
        "nms_thesh = 0.4\n",
        "start = 0\n",
        "CUDA = torch.cuda.is_available()\n",
        "\n",
        "num_classes = 80\n",
        "classes = load_classes(\"data/coco.names\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIbWRZfCfmMn",
        "colab_type": "code",
        "outputId": "fff7c366-f485-43a5-ef80-f4fa7459b3b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Set up the neural network\n",
        "print(\"Loading network.....\")\n",
        "model = Darknet(cfgfile)\n",
        "model.load_weights(weightsfile)\n",
        "print(\"Network successfully loaded\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network.....\n",
            "Network successfully loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnP0M6offmJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.net_info[\"height\"] = \"416\"\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0\n",
        "assert inp_dim > 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRufNvF1TbuZ",
        "colab_type": "code",
        "outputId": "7c4ad360-1650-4a5b-f853-e792081baa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if CUDA:\n",
        "    model.cuda()\n",
        "    \n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Darknet(\n",
              "  (module_list): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (shortcut_4): EmptyLayer()\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (shortcut_8): EmptyLayer()\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (shortcut_11): EmptyLayer()\n",
              "    )\n",
              "    (12): Sequential(\n",
              "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (14): Sequential(\n",
              "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (15): Sequential(\n",
              "      (shortcut_15): EmptyLayer()\n",
              "    )\n",
              "    (16): Sequential(\n",
              "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (17): Sequential(\n",
              "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (18): Sequential(\n",
              "      (shortcut_18): EmptyLayer()\n",
              "    )\n",
              "    (19): Sequential(\n",
              "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (20): Sequential(\n",
              "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (21): Sequential(\n",
              "      (shortcut_21): EmptyLayer()\n",
              "    )\n",
              "    (22): Sequential(\n",
              "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (23): Sequential(\n",
              "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (24): Sequential(\n",
              "      (shortcut_24): EmptyLayer()\n",
              "    )\n",
              "    (25): Sequential(\n",
              "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (26): Sequential(\n",
              "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (27): Sequential(\n",
              "      (shortcut_27): EmptyLayer()\n",
              "    )\n",
              "    (28): Sequential(\n",
              "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (29): Sequential(\n",
              "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (30): Sequential(\n",
              "      (shortcut_30): EmptyLayer()\n",
              "    )\n",
              "    (31): Sequential(\n",
              "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (32): Sequential(\n",
              "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (33): Sequential(\n",
              "      (shortcut_33): EmptyLayer()\n",
              "    )\n",
              "    (34): Sequential(\n",
              "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (35): Sequential(\n",
              "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (36): Sequential(\n",
              "      (shortcut_36): EmptyLayer()\n",
              "    )\n",
              "    (37): Sequential(\n",
              "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (38): Sequential(\n",
              "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (39): Sequential(\n",
              "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (40): Sequential(\n",
              "      (shortcut_40): EmptyLayer()\n",
              "    )\n",
              "    (41): Sequential(\n",
              "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (42): Sequential(\n",
              "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (43): Sequential(\n",
              "      (shortcut_43): EmptyLayer()\n",
              "    )\n",
              "    (44): Sequential(\n",
              "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (45): Sequential(\n",
              "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (46): Sequential(\n",
              "      (shortcut_46): EmptyLayer()\n",
              "    )\n",
              "    (47): Sequential(\n",
              "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (48): Sequential(\n",
              "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (49): Sequential(\n",
              "      (shortcut_49): EmptyLayer()\n",
              "    )\n",
              "    (50): Sequential(\n",
              "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (51): Sequential(\n",
              "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (52): Sequential(\n",
              "      (shortcut_52): EmptyLayer()\n",
              "    )\n",
              "    (53): Sequential(\n",
              "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (54): Sequential(\n",
              "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (55): Sequential(\n",
              "      (shortcut_55): EmptyLayer()\n",
              "    )\n",
              "    (56): Sequential(\n",
              "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (57): Sequential(\n",
              "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (58): Sequential(\n",
              "      (shortcut_58): EmptyLayer()\n",
              "    )\n",
              "    (59): Sequential(\n",
              "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (60): Sequential(\n",
              "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (61): Sequential(\n",
              "      (shortcut_61): EmptyLayer()\n",
              "    )\n",
              "    (62): Sequential(\n",
              "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (63): Sequential(\n",
              "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (64): Sequential(\n",
              "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (65): Sequential(\n",
              "      (shortcut_65): EmptyLayer()\n",
              "    )\n",
              "    (66): Sequential(\n",
              "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (67): Sequential(\n",
              "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (68): Sequential(\n",
              "      (shortcut_68): EmptyLayer()\n",
              "    )\n",
              "    (69): Sequential(\n",
              "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (70): Sequential(\n",
              "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (71): Sequential(\n",
              "      (shortcut_71): EmptyLayer()\n",
              "    )\n",
              "    (72): Sequential(\n",
              "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (73): Sequential(\n",
              "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (74): Sequential(\n",
              "      (shortcut_74): EmptyLayer()\n",
              "    )\n",
              "    (75): Sequential(\n",
              "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (76): Sequential(\n",
              "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (77): Sequential(\n",
              "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (78): Sequential(\n",
              "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (79): Sequential(\n",
              "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (80): Sequential(\n",
              "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (81): Sequential(\n",
              "      (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (82): Sequential(\n",
              "      (Detection_82): DetectionLayer()\n",
              "    )\n",
              "    (83): Sequential(\n",
              "      (route_83): EmptyLayer()\n",
              "    )\n",
              "    (84): Sequential(\n",
              "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (85): Sequential(\n",
              "      (upsample_85): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    )\n",
              "    (86): Sequential(\n",
              "      (route_86): EmptyLayer()\n",
              "    )\n",
              "    (87): Sequential(\n",
              "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (88): Sequential(\n",
              "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (89): Sequential(\n",
              "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (90): Sequential(\n",
              "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (91): Sequential(\n",
              "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (92): Sequential(\n",
              "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (93): Sequential(\n",
              "      (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (94): Sequential(\n",
              "      (Detection_94): DetectionLayer()\n",
              "    )\n",
              "    (95): Sequential(\n",
              "      (route_95): EmptyLayer()\n",
              "    )\n",
              "    (96): Sequential(\n",
              "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (97): Sequential(\n",
              "      (upsample_97): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    )\n",
              "    (98): Sequential(\n",
              "      (route_98): EmptyLayer()\n",
              "    )\n",
              "    (99): Sequential(\n",
              "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (100): Sequential(\n",
              "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (101): Sequential(\n",
              "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (102): Sequential(\n",
              "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (103): Sequential(\n",
              "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (104): Sequential(\n",
              "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (105): Sequential(\n",
              "      (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (106): Sequential(\n",
              "      (Detection_106): DetectionLayer()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3-TuPgcTbrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "read_dir = time.time()\n",
        "# Detection phase\n",
        "try:\n",
        "    imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
        "except NotADirectoryError:\n",
        "    imlist = []\n",
        "    imlist.append(osp.join(osp.realpath('.'), images))\n",
        "except FileNotFoundError:\n",
        "    print (\"No file or directory with the name {}\".format(images))\n",
        "    exit()\n",
        "\n",
        "if not os.path.exists(det):\n",
        "    os.makedirs(det)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blRtZkdFfmGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_batch = time.time()\n",
        "loaded_ims = [cv2.imread(x) for x in imlist]\n",
        "\n",
        "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
        "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz9MddweJS55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "leftover = 0\n",
        "if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "\n",
        "if batch_size != 1:\n",
        "    num_batches = len(imlist) // batch_size + leftover\n",
        "    im_batches = [torch.cat((im_batches[i * batch_size: min((i + 1) * batch_size,\n",
        "                                                            len(im_batches))])) for i in range(num_batches)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfkv-cBRQ-xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write = 0\n",
        "\n",
        "if CUDA:\n",
        "    im_dim_list = im_dim_list.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4yvbHZzVSm3",
        "colab_type": "code",
        "outputId": "8cedfba9-5b75-4499-976e-58ad334c85e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "start_det_loop = time.time()\n",
        "for i, batch in enumerate(im_batches):\n",
        "    # load the image\n",
        "    start = time.time()\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(Variable(batch), CUDA)\n",
        "\n",
        "    prediction = write_results(prediction, confidence, num_classes, nms_conf=nms_thesh)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    if type(prediction) == int:\n",
        "\n",
        "        for im_num, image in enumerate(imlist[i * batch_size: min((i + 1) * batch_size, len(imlist))]):\n",
        "            im_id = i * batch_size + im_num\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start) / batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        continue\n",
        "\n",
        "    prediction[:, 0] += i * batch_size  # transform the atribute from index in batch to index in imlist\n",
        "\n",
        "    if not write:  # If we have't initialised output\n",
        "        output = prediction\n",
        "        write = 1\n",
        "    else:\n",
        "        output = torch.cat((output, prediction))\n",
        "\n",
        "    for im_num, image in enumerate(imlist[i * batch_size: min((i + 1) * batch_size, len(imlist))]):\n",
        "        im_id = i * batch_size + im_num\n",
        "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start) / batch_size))\n",
        "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "    if CUDA:\n",
        "        torch.cuda.synchronize()\n",
        "try:\n",
        "    output\n",
        "except NameError:\n",
        "    print (\"No detections were made\")\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog-cycle-car.png    predicted in  0.156 seconds\n",
            "Objects Detected:    bicycle bicycle bicycle bicycle truck truck truck truck dog dog dog dog dog dog dog dog\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzvLMq6YVSjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_dim_list = torch.index_select(im_dim_list, 0, output[:, 0].long())\n",
        "\n",
        "scaling_factor = torch.min(416 / im_dim_list, 1)[0].view(-1, 1)\n",
        "\n",
        "output[:, [1, 3]] -= (inp_dim - scaling_factor * im_dim_list[:, 0].view(-1, 1)) / 2\n",
        "output[:, [2, 4]] -= (inp_dim - scaling_factor * im_dim_list[:, 1].view(-1, 1)) / 2\n",
        "\n",
        "output[:, 1:5] /= scaling_factor\n",
        "\n",
        "for i in range(output.shape[0]):\n",
        "    output[i, [1, 3]] = torch.clamp(output[i, [1, 3]], 0.0, im_dim_list[i, 0])\n",
        "    output[i, [2, 4]] = torch.clamp(output[i, [2, 4]], 0.0, im_dim_list[i, 1])\n",
        "\n",
        "output_recast = time.time()\n",
        "class_load = time.time()\n",
        "colors = pkl.load(open(\"pallete\", \"rb\"))\n",
        "\n",
        "draw = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0tzFbiNVSd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write(x, results):\n",
        "    c1 = tuple(x[1:3].int())\n",
        "    c2 = tuple(x[3:5].int())\n",
        "    img = results[int(x[0])]\n",
        "    cls = int(x[-1])\n",
        "    color = random.choice(colors)\n",
        "    label = \"{0}\".format(classes[cls])\n",
        "    cv2.rectangle(img, c1, c2, color, 1)\n",
        "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
        "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "    cv2.rectangle(img, c1, c2, color, -1)\n",
        "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225, 255, 255], 1);\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3zZciE2pgEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: write(x, loaded_ims), output))\n",
        "\n",
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(det, x.split(\"/\")[-1]))\n",
        "\n",
        "list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SusNYpd5WD1C",
        "colab_type": "code",
        "outputId": "c6246cba-bd33-4029-f91f-33a55e3c2085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "print(\"SUMMARY\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "print()\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) + \" images)\", output_recast - start_det_loop))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch) / len(imlist)))\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUMMARY\n",
            "----------------------------------------------------------\n",
            "Task                     : Time Taken (in seconds)\n",
            "\n",
            "Reading addresses        : 0.013\n",
            "Loading batch            : 0.085\n",
            "Detection (1 images)     : 0.207\n",
            "Output Processing        : 0.000\n",
            "Drawing Boxes            : 0.069\n",
            "Average time_per_img     : 0.361\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lta1_tUh6L_Z",
        "colab_type": "text"
      },
      "source": [
        "## 训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYZY38t38cha",
        "colab_type": "text"
      },
      "source": [
        "coco.data:  \n",
        "classes= 80  \n",
        "train=data/coco/trainvalno5k.txt  \n",
        "valid=data/coco/5k.txt  \n",
        "names=data/coco.names  \n",
        "backup=backup/  \n",
        "eval=coco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPB2IPFz7zoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=100                  # number of epochs\n",
        "batch_size=8                # size of each image batch\n",
        "gradient_accumulations=2    # number of gradient accums before step\n",
        "model_def = \"cfg/yolov3.cfg\"  # path to model definition file\n",
        "data_config = \"config/coco.data\"   # path to data config file\n",
        "pretrained_weights =   # if specified starts from checkpoint model\n",
        "n_cpu=8             # number of cpu threads to use during batch generation\n",
        "img_size=416        # size of each image dimension\n",
        "checkpoint_interval=1     # interval between saving model weights\n",
        "evaluation_interval=1     # interval evaluations on validation set\n",
        "compute_map=False         # if True computes mAP every tenth batch\n",
        "multiscale_training=True  # allow for multi-scale training\n",
        "#logger = Logger(\"logs\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4jE9BZc6uoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(\"output\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ72Gdcg6uk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get data configuration\n",
        "data_config = parse_data_config(opt.data_config)\n",
        "train_path = data/coco/trainvalno5k.txt\n",
        "valid_path = data/coco/5k.txt\n",
        "class_names = load_classes(data/coco.names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy-TM8yG6_HN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initiate model\n",
        "model = Darknet(model_def).to(device)\n",
        "model.apply(weights_init_normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-OzlIh-6ucW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If specified we start from checkpoint\n",
        "if pretrained_weights:\n",
        "    if pretrained_weights.endswith(\".pth\"):\n",
        "        model.load_state_dict(torch.load(pretrained_weights))\n",
        "    else:\n",
        "        model.load_darknet_weights(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfq_vFp07L4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get dataloader\n",
        "dataset = ListDataset(train_path, augment=True, multiscale=opt.multiscale_training)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=opt.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=opt.n_cpu,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dataset.collate_fn,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgtcZ8357Sba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD-otfqv7oMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = [\n",
        "    \"grid_size\",\n",
        "    \"loss\",\n",
        "    \"x\",\n",
        "    \"y\",\n",
        "    \"w\",\n",
        "    \"h\",\n",
        "    \"conf\",\n",
        "    \"cls\",\n",
        "    \"cls_acc\",\n",
        "    \"recall50\",\n",
        "    \"recall75\",\n",
        "    \"precision\",\n",
        "    \"conf_obj\",\n",
        "    \"conf_noobj\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRRW7u_p7eVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(opt.epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    for batch_i, (_, imgs, targets) in enumerate(dataloader):\n",
        "        batches_done = len(dataloader) * epoch + batch_i\n",
        "\n",
        "        imgs = Variable(imgs.to(device))\n",
        "        targets = Variable(targets.to(device), requires_grad=False)\n",
        "\n",
        "        loss, outputs = model(imgs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        if batches_done % opt.gradient_accumulations:\n",
        "            # Accumulates gradient before each step\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # ----------------\n",
        "        #   Log progress\n",
        "        # ----------------\n",
        "\n",
        "        log_str = \"\\n---- [Epoch %d/%d, Batch %d/%d] ----\\n\" % (epoch, opt.epochs, batch_i, len(dataloader))\n",
        "\n",
        "        metric_table = [[\"Metrics\", *[f\"YOLO Layer {i}\" for i in range(len(model.yolo_layers))]]]\n",
        "\n",
        "        # Log metrics at each YOLO layer\n",
        "        for i, metric in enumerate(metrics):\n",
        "            formats = {m: \"%.6f\" for m in metrics}\n",
        "            formats[\"grid_size\"] = \"%2d\"\n",
        "            formats[\"cls_acc\"] = \"%.2f%%\"\n",
        "            row_metrics = [formats[metric] % yolo.metrics.get(metric, 0) for yolo in model.yolo_layers]\n",
        "            metric_table += [[metric, *row_metrics]]\n",
        "\n",
        "            # Tensorboard logging\n",
        "            tensorboard_log = []\n",
        "            for j, yolo in enumerate(model.yolo_layers):\n",
        "                for name, metric in yolo.metrics.items():\n",
        "                    if name != \"grid_size\":\n",
        "                        tensorboard_log += [(f\"{name}_{j+1}\", metric)]\n",
        "            tensorboard_log += [(\"loss\", loss.item())]\n",
        "            logger.list_of_scalars_summary(tensorboard_log, batches_done)\n",
        "\n",
        "        log_str += AsciiTable(metric_table).table\n",
        "        log_str += f\"\\nTotal loss {loss.item()}\"\n",
        "\n",
        "        # Determine approximate time left for epoch\n",
        "        epoch_batches_left = len(dataloader) - (batch_i + 1)\n",
        "        time_left = datetime.timedelta(seconds=epoch_batches_left * (time.time() - start_time) / (batch_i + 1))\n",
        "        log_str += f\"\\n---- ETA {time_left}\"\n",
        "\n",
        "        print(log_str)\n",
        "\n",
        "        model.seen += imgs.size(0)\n",
        "\n",
        "    if epoch % opt.evaluation_interval == 0:\n",
        "        print(\"\\n---- Evaluating Model ----\")\n",
        "        # Evaluate the model on the validation set\n",
        "        precision, recall, AP, f1, ap_class = evaluate(\n",
        "            model,\n",
        "            path=valid_path,\n",
        "            iou_thres=0.5,\n",
        "            conf_thres=0.5,\n",
        "            nms_thres=0.5,\n",
        "            img_size=opt.img_size,\n",
        "            batch_size=8,\n",
        "        )\n",
        "        evaluation_metrics = [\n",
        "            (\"val_precision\", precision.mean()),\n",
        "            (\"val_recall\", recall.mean()),\n",
        "            (\"val_mAP\", AP.mean()),\n",
        "            (\"val_f1\", f1.mean()),\n",
        "        ]\n",
        "        logger.list_of_scalars_summary(evaluation_metrics, epoch)\n",
        "\n",
        "        # Print class APs and mAP\n",
        "        ap_table = [[\"Index\", \"Class name\", \"AP\"]]\n",
        "        for i, c in enumerate(ap_class):\n",
        "            ap_table += [[c, class_names[c], \"%.5f\" % AP[i]]]\n",
        "        print(AsciiTable(ap_table).table)\n",
        "        print(f\"---- mAP {AP.mean()}\")\n",
        "\n",
        "    if epoch % opt.checkpoint_interval == 0:\n",
        "        torch.save(model.state_dict(), f\"checkpoints/yolov3_ckpt_%d.pth\" % epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu3HWC676KoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceZkUi_76KlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}