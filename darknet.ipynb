{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "darknet",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "HxR9iVyej3rh",
        "R9zJJFZXNrRn",
        "s-ufryjTP1IG",
        "ywbs55hJkfqm",
        "H9LL9UqISMwe",
        "KhJpd_NHrl3a"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/master/darknet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WEuumVfwWze",
        "colab_type": "text"
      },
      "source": [
        "# <font face=STCAIYUN color=purple size=8>YOLOv3</font>\n",
        "<font face=楷体 color=skyblue size=4>YOLO 是 You Only Look Once 的缩写</font>  \n",
        "<font face=楷体 color=skyblue size=4>**全卷积神经网络** </font>  \n",
        "<font face=楷体>\n",
        "YOLO 仅使用卷积层，即：全卷积神经网络（FCN对于输入图像的大小不敏感） ，它拥有 75 个卷积层，带有跳跃连接和上采样层。不使用任何它形式的，使用步幅为 2 的卷积层代替池化层对特征图进行下采样，防止池化导致的低级特征丢失 \n",
        "    \n",
        "问题是：如果我们希望按批次处理图像（批量图像由 GPU 并行处理，这样可以提升速度），我们就需要固定所有图像的高度和宽度。这就需要将多个图像整合进一个大的批次（将许多 PyTorch 张量合并成一个）</font>  \n",
        " \n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**YOLOv3网络结构图** </font>  \n",
        "\n",
        "![替代文字](https://img-blog.csdnimg.cn/20190824145218799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcxMTU1NA==,size_16,color_FFFFFF,t_70)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**网络输出**</font>   \n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo-5.png)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>锚点框（Anchor Box）</font>  \n",
        "<font face=楷体>\n",
        "预测边界框的宽度和高度看上去是最直接的，但实践训练中会带来梯度不稳定，所以现在大部分目标检测器都预测对数空间（log-space）变换量，或者预测与预定义边界框（即锚点）之间的偏移量  \n",
        "这些变换被应用到锚点框来获得预测，YOLO v3 有三个锚点，所以每个单元格会预测 3 个边界框  \n",
        "</font>   \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>中心坐标</font>    \n",
        "<font face=楷体>\n",
        "通过一个sigmoid函数对中心坐标预测，迫使输出介于0和1之间  \n",
        "YOLO通常不会预测边界框中心的绝对坐标而是预测偏移量：  \n",
        "\n",
        "\n",
        "*   相对于预测对象格单元格的左上角\n",
        "*   由特征图中的单元格尺寸标准化，如上图：对狗狗中心的预测是（0.4,0.7），那么中心位于13 x 13特征图上的（6.4,6.7）位置  \n",
        "</font>\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>预测</font>  \n",
        "<font face=楷体>每个bounding box预测5个值：$\\color{pink}{t_x，t_y，t_w，t_h，t_o}$ （$t_o$类似YOLOv1中的confidence）  \n",
        "\n",
        "*   $\\color{pink}{t_x，t_y}$：经过sigmoid函数处理后范围在0到1之间，模型训练更加稳定  \n",
        "*   $\\color{pink}{c_x，c_y}$：表示一个cell和图像左上角的横纵距离 \n",
        "*   $\\color{pink}{p_w，p_h}$：表示bounding box的宽高 \n",
        "</font>\n",
        "\n",
        " \n",
        "$$\n",
        "\\begin{aligned} b_{x} &=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} &=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} &=p_{w} e^{t_{w}} \\\\ b_{h} &=p_{h} e^{t_{h}} \\\\ \\operatorname{Pr}(\\text { object }) * I O U(b, \\text { object }) &=\\sigma\\left(t_{o}\\right)\\end{aligned}\n",
        "$$\n",
        "\n",
        "<font face=楷体 color=yellow>在Faster R-CNN中：</font>\n",
        "$$\\begin{align}\n",
        "t_x &= (x - x_a) /w_a, \\ t_y = (y - y_a) / h_a\\\\[1ex]t_w &= log(w/ w_a), t_h = log(h/h_a)\\\\[1ex]t_x^* &= (x^* - x_a) / w_a, t_y^* = (y^* - y_a) /h_a\\\\[1ex]t_w^* &= log(w^* - w), h_h^* = log(h^*/h_a)\n",
        "\\end{align}$$  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>边界框的尺寸</font>   \n",
        "<font face=楷体>\n",
        "将输出进行对数变换乘以锚来预测边界框的尺寸  \n",
        "\n",
        "</font>\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo-regression-1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxR9iVyej3rh",
        "colab_type": "text"
      },
      "source": [
        "# Darknet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9zJJFZXNrRn",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 解析配置文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lee0sSfNRGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#from util import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJVXBiSkN-HH",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "定义一个函数 parse_cfg，用配置文件的路径作为输入  \n",
        "    \n",
        "将 <font color=skyblue size=4>**Net 、  Convolutional  、 Shortcut  、Upsample 、 Route 、 YOLO**</font> 以blocks 列表的形式返回\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy3tzMrnNeyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_cfg(cfgfile):\n",
        "    \"\"\"\n",
        "    Takes a configuration file\n",
        "    Returns a list of blocks. Each blocks describes a block in the neural\n",
        "    network to be built. Block is represented as a dictionary in the list    \n",
        "    \"\"\"\n",
        "    file = open(cfgfile, 'r')\n",
        "    lines = file.read().split('\\n')                        # store the lines in a list\n",
        "    lines = [x for x in lines if len(x) > 0]               # get read of the empty lines \n",
        "    lines = [x for x in lines if x[0] != '#']              # get rid of comments\n",
        "    lines = [x.rstrip().lstrip() for x in lines]           # get rid of fringe whitespaces\n",
        "    \n",
        "    block = {}\n",
        "    blocks = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line[0] == \"[\":               # This marks the start of a new block\n",
        "            if len(block) != 0:          # If block is not empty, implies it is storing values of previous block.\n",
        "                blocks.append(block)     # add it the blocks list\n",
        "                block = {}               # re-init the block\n",
        "            block[\"type\"] = line[1:-1].rstrip()     \n",
        "        else:\n",
        "            key,value = line.split(\"=\") \n",
        "            block[key.rstrip()] = value.lstrip()\n",
        "    blocks.append(block)\n",
        "\n",
        "    return blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HELg17PPGVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#blocks = parse_cfg(\"/content/gdrive/My Drive/YOLO/v3/cfg/yolov3.cfg\")\n",
        "#blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-ufryjTP1IG",
        "colab_type": "text"
      },
      "source": [
        "###1.2构建 PyTorch 模块   \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**create_modules 函数用 parse_cfg 函数返回的 blocks 列表构建网络模块：**</font>\n",
        "\n",
        "<font face=楷体>\n",
        "\n",
        "*   先定义变量 net_info，来存储该网络的信息\n",
        "\n",
        "*  当添加 nn.ModuleList 作为 nn.Module 对象的一个成员时（即添加模块到网络），所有 nn.ModuleList 内部的 nn.Module 对象（模块）的 parameter 也被添加   作为 nn.Module 对象（即网络添加 nn.ModuleList 作为其成员）的 parameter\n",
        "\n",
        "*   卷积核的深度是由上一层的卷积核数量（或特征图深度）决定的。这意味着我们需要持续追踪被应用卷积层的卷积核数量。用变量 prev_filter 实现追踪（RGB3通道所以初始化为3）\n",
        "\n",
        "*  路由层（route layer）从前面层得到特征图，不仅需要追踪前一层的卷积核数量，还需要追踪之前每一层。不断地迭代，将每个模块的输出卷积核数量添加到 output_filters 列表 \n",
        "\n",
        "*  nn.Sequential 类是能让nn.Module 对象有序执行 的数字，一个模块可能包含多个层，用 nn.Sequential 将这些层串联起来，得到 add_module 函数\n",
        "    \n",
        "</font>  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>   \n",
        "\n",
        "1、anchors = [anchors[i] for i in mask]   \n",
        "2、detection = DetectionLayer(anchors)  \n",
        "3、路由层  \n",
        "4、YOLO层mask  \n",
        "line107:  anchors = [anchors[i] for i in mask]   \n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接:**</font>  \n",
        "\n",
        "[【1】nn.Conv2d 、nn.BatchNorm2d](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#torchnn)  \n",
        "[【2】torch.nn.Upsample](https://pytorch.org/docs/stable/nn.html?highlight=nn%20upsample#torch.nn.Upsample)  \n",
        "[【3】darknet 所有层功能说明 ](https://blog.csdn.net/zhuiqiuk/article/details/88187034)   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b40dPOsVPGH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_modules(blocks):\n",
        "    net_info = blocks[0]  # Captures the information about the input and pre-processing\n",
        "    module_list = nn.ModuleList()\n",
        "    index = 0  # indexing blocks helps with implementing route  layers (skip connections)\n",
        "    prev_filters = 3\n",
        "    output_filters = []\n",
        "    \n",
        "    # 迭代模块的列表，并为每个模块创建一个 PyTorch 模块\n",
        "    for index, x in enumerate(blocks[1:]): \n",
        "        module = nn.Sequential()\n",
        "        #check the type of block\n",
        "        #create a new module for the block\n",
        "        #append to module_list\n",
        "        \n",
        "       #创建卷积层\n",
        "       # If it's a convolutional layer\n",
        "        if (x[\"type\"] == \"convolutional\"):\n",
        "            # Get the info about the layer\n",
        "            activation = x[\"activation\"]\n",
        "            try:\n",
        "                batch_normalize = int(x[\"batch_normalize\"])\n",
        "                bias = False\n",
        "            except:\n",
        "                batch_normalize = 0\n",
        "                bias = True\n",
        "\n",
        "            filters = int(x[\"filters\"])\n",
        "            padding = int(x[\"pad\"])\n",
        "            kernel_size = int(x[\"size\"])\n",
        "            stride = int(x[\"stride\"])\n",
        "\n",
        "            if padding:\n",
        "                pad = (kernel_size - 1) // 2\n",
        "            else:\n",
        "                pad = 0\n",
        "\n",
        "            # Add the convolutional layer\n",
        "            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=bias)\n",
        "            module.add_module(\"conv_{0}\".format(index), conv)\n",
        "            \n",
        "            # Add the Batch Norm Layer\n",
        "            if batch_normalize:\n",
        "                bn = nn.BatchNorm2d(filters)\n",
        "                module.add_module(\"batch_norm_{0}\".format(index), bn)\n",
        "\n",
        "            # Check the activation.\n",
        "            # It is either Linear or a Leaky ReLU for YOLO\n",
        "            if activation == \"leaky\":\n",
        "                activn = nn.LeakyReLU(0.1, inplace=True)\n",
        "                module.add_module(\"leaky_{0}\".format(index), activn)\n",
        "\n",
        "        # 构建上采样层\n",
        "        # If it's an upsampling layer\n",
        "        # We use Bilinear2dUpsampling\n",
        "        elif (x[\"type\"] == \"upsample\"):\n",
        "            stride = int(x[\"stride\"])\n",
        "            upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
        "            module.add_module(\"upsample_{}\".format(index), upsample)\n",
        "            \n",
        "\n",
        "        # 路由层\n",
        "        # If it is a route layer\n",
        "        elif (x[\"type\"] == \"route\"):\n",
        "            x[\"layers\"] = x[\"layers\"].split(',')\n",
        "\n",
        "            # Start  of a route\n",
        "            start = int(x[\"layers\"][0])\n",
        "\n",
        "            # end, if there exists one.\n",
        "            try:\n",
        "                end = int(x[\"layers\"][1])\n",
        "            except:\n",
        "                end = 0\n",
        "\n",
        "            # Positive anotation\n",
        "            if start > 0:\n",
        "                start = start - index\n",
        "\n",
        "            if end > 0:\n",
        "                end = end - index\n",
        "\n",
        "            route = EmptyLayer()\n",
        "            module.add_module(\"route_{0}\".format(index), route)\n",
        "\n",
        "            if end < 0:\n",
        "                filters = output_filters[index + start] + output_filters[index + end]\n",
        "            else:\n",
        "                filters = output_filters[index + start]\n",
        "                \n",
        "        # 捷径层       \n",
        "        # shortcut corresponds to skip connection\n",
        "        if x[\"type\"] == \"shortcut\":\n",
        "            shortcut = EmptyLayer()\n",
        "            module.add_module(\"shortcut_{}\".format(index), shortcut)    \n",
        "            \n",
        "            \n",
        "            \n",
        "        # YOLO层\n",
        "        # Yolo is the detection layer\n",
        "        if x[\"type\"] == \"yolo\":\n",
        "            mask = x[\"mask\"].split(\",\") \n",
        "            mask = [int(x) for x in mask] \n",
        "\n",
        "            anchors = x[\"anchors\"].split(\",\")\n",
        "            anchors = [int(a) for a in anchors]\n",
        "            anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
        "            anchors = [anchors[i] for i in mask]  # 取前三个？？\n",
        "\n",
        "            detection = DetectionLayer(anchors)\n",
        "            module.add_module(\"Detection_{}\".format(index), detection)  \n",
        "            \n",
        "        # 回路结束时，做一些统计（bookkeeping.）\n",
        "        module_list.append(module)\n",
        "        prev_filters = filters\n",
        "        output_filters.append(filters)\n",
        "        \n",
        "    return (net_info, module_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-X6Zb85urR3",
        "colab_type": "text"
      },
      "source": [
        "## 定义网络\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>\n",
        "用 nn.Module 在 PyTorch 中构建自定义架构：  \n",
        "    \n",
        "*   定义nn.Module子类Darknet，用 members、blocks、net_info 和 module_list 进行初始化  \n",
        "\n",
        "*   重写forward方法来实现网络的前向传递nn.Module ：1）计算输出；2）以一种可以更容易处理的方式转换输出检测特征图，例如：将它们转换为可以连接多个尺度的检测图（ self.blocks 的第一个元素是 net 块，不属于前向传播，所以迭代的对象是 self.block[1:]）\n",
        "\n",
        "*   与create_modules函数一样，module_list中包含网络的模块。模块的附加顺序与配置文件中的顺序相同。这意味着，我们可以通过每个模块简单地运行输入以获得输出。\n",
        "*   路由层需要连接两个特征映射， 用torch.cat带有第二个参数的函数为1，因为要沿着深度连接特征映射  \n",
        "    \n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxd7AJ1NHmVn",
        "colab_type": "text"
      },
      "source": [
        "### 加载权重\n",
        "<font face=楷体 color=skyblue size=4>权重是如何存储：</font>  \n",
        "\n",
        "<font face=楷体>\n",
        "权重只属于<font color=skyblue>批量归一化层（batch norm layer）和卷积层</font>  两种类型的层，储存顺序和配置文件中定义层级的顺序完全相同  \n",
        "    \n",
        "下图展示了权重如何储存：\n",
        "</font>\n",
        "\n",
        "![替代文字](https://img-blog.csdn.net/20180507102704610?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTE1MjA1MTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "~~~\n",
        "# 卷积和上采样层\n",
        "if module_type == \"convolutional\" or module_type == \"upsample\":\n",
        "    x = self.module_list[i](x)\n",
        "    outputs[i] = x \n",
        "line74: batch_normalize = int(self.blocks[i + 1][\"batch_normalize\"])    \n",
        "line102:  bn_biases = bn_biases.view_as(bn.bias.data)\n",
        "                \n",
        "~~~\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzhDjzWcZrzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Darknet(nn.Module):\n",
        "    def __init__(self, cfgfile):\n",
        "        super(Darknet, self).__init__()\n",
        "        self.blocks = parse_cfg(cfgfile)\n",
        "        self.net_info, self.module_list = create_modules(self.blocks)\n",
        "        \n",
        "    # 前向传播\n",
        "    def forward(self, x, CUDA):\n",
        "        detections = []\n",
        "        modules = self.blocks[1:]\n",
        "        outputs = {}  # We cache the outputs for the route layer    \n",
        "        \n",
        "        write = 0\n",
        "        for i in range(len(modules)):\n",
        "            module_type = (modules[i][\"type\"])    \n",
        "            \n",
        "            # 卷积和上采样层\n",
        "            if module_type == \"convolutional\" or module_type == \"upsample\":\n",
        "                x = self.module_list[i](x)\n",
        "                outputs[i] = x     \n",
        "                \n",
        "            # 路由层\n",
        "            elif module_type == \"route\":\n",
        "                layers = modules[i][\"layers\"]\n",
        "                layers = [int(a) for a in layers]\n",
        "\n",
        "                if (layers[0]) > 0:\n",
        "                    layers[0] = layers[0] - i\n",
        "\n",
        "                if len(layers) == 1:\n",
        "                    x = outputs[i + (layers[0])]\n",
        "\n",
        "                else:\n",
        "                    if (layers[1]) > 0:\n",
        "                        layers[1] = layers[1] - i\n",
        "\n",
        "                    map1 = outputs[i + layers[0]]\n",
        "                    map2 = outputs[i + layers[1]]\n",
        "\n",
        "                    x = torch.cat((map1, map2), 1)\n",
        "                \n",
        "            elif module_type == \"shortcut\":\n",
        "                from_ = int(modules[i][\"from\"])\n",
        "                x = outputs[i - 1] + outputs[i + from_]\n",
        "                outputs[i] = x\n",
        "                \n",
        "    def load_weights(self, weightfile):\n",
        "        # Open the weights file\n",
        "        fp = open(weightfile, \"rb\")\n",
        "\n",
        "        # 第一个 160 比特的权重文件保存了 5 个 int32 值，它们构成了文件的标头\n",
        "        # The first 4 values are header information\n",
        "        # 1. Major version number\n",
        "        # 2. Minor Version Number\n",
        "        # 3. Subversion number\n",
        "        # 4. IMages seen\n",
        "        header = np.fromfile(fp, dtype=np.int32, count=5)\n",
        "        self.header = torch.from_numpy(header)\n",
        "        self.seen = self.header[3]        \n",
        "        \n",
        "        # The rest of the values are the weights\n",
        "        # Let's load them up\n",
        "        weights = np.fromfile(fp, dtype=np.float32)\n",
        "        \n",
        "        # 循环地加载权重文件到网络的模块上\n",
        "        ptr = 0\n",
        "        for i in range(len(self.module_list)):\n",
        "            module_type = self.blocks[i + 1][\"type\"]\n",
        "\n",
        "            if module_type == \"convolutional\":        \n",
        "                \n",
        "                model = self.module_list[i]\n",
        "                try:\n",
        "                    batch_normalize = int(self.blocks[i + 1][\"batch_normalize\"])  # blocks包括Net，module_list只包含网络层\n",
        "                except:\n",
        "                    batch_normalize = 0\n",
        "\n",
        "                conv = model[0]\n",
        "                \n",
        "                #如果 batch_normalize 检查结果是 True，则我们按以下方式加载权重\n",
        "                if (batch_normalize):\n",
        "                    bn = model[1]\n",
        "\n",
        "                    # Get the number of weights of Batch Norm Layer\n",
        "                    num_bn_biases = bn.bias.numel()\n",
        "\n",
        "                    # Load the weights\n",
        "                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    # Cast the loaded weights into dims of model weights.\n",
        "                    bn_biases = bn_biases.view_as(bn.bias.data)\n",
        "                    bn_weights = bn_weights.view_as(bn.weight.data)\n",
        "                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
        "                    bn_running_var = bn_running_var.view_as(bn.running_var)\n",
        "\n",
        "                    # Copy the data to model\n",
        "                    bn.bias.data.copy_(bn_biases)\n",
        "                    bn.weight.data.copy_(bn_weights)\n",
        "                    bn.running_mean.copy_(bn_running_mean)\n",
        "                    bn.running_var.copy_(bn_running_var)     \n",
        "                    \n",
        "                #如果 batch_normalize 的检查结果不是 True，只需要加载卷积层的偏置项。\n",
        "                else:\n",
        "                    # Number of biases\n",
        "                    num_biases = conv.bias.numel()\n",
        "\n",
        "                    # Load the weights\n",
        "                    conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases])\n",
        "                    ptr = ptr + num_biases\n",
        "\n",
        "                    # reshape the loaded weights according to the dims of the model weights\n",
        "                    conv_biases = conv_biases.view_as(conv.bias.data)\n",
        "\n",
        "                    # Finally copy the data\n",
        "                    conv.bias.data.copy_(conv_biases)\n",
        "                    \n",
        "                # Let us load the weights for the Convolutional layers\n",
        "                num_weights = conv.weight.numel()\n",
        "\n",
        "                # Do the same as above for weights\n",
        "                conv_weights = torch.from_numpy(weights[ptr:ptr + num_weights])\n",
        "                ptr = ptr + num_weights\n",
        "\n",
        "                conv_weights = conv_weights.view_as(conv.weight.data)\n",
        "                conv.weight.data.copy_(conv_weights)                    \n",
        "\n",
        "                    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOYbAE6MWOy9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "创建路由层：首先，我们提取关于层属性的值，将其表示为一个整数，并保存在一个列表中。\n",
        "\n",
        " 然后我们得到一个新的称为 EmptyLayer 的层，即空的层。  \n",
        " \n",
        " <font color=red size=4>**为什么要一个空的层？？**</font>  \n",
        " \n",
        " 在 Route 模块中设计一个层，我们必须建立一个 nn.Module 对象，其作为 layers 的成员被初始化。然后，我们可以写下代码，将 forward 函数中的特征图拼接起来并向前馈送。最后，执行网络的某个 forward 函数的这个层。 \n",
        " \n",
        " 但拼接操作的代码相当地简短（在特征图上调用 torch.cat），像上述过程那样设计一个层将导致不必要的抽象，增加样板代码。取而代之，我们可以将一个假的层置于之前提出的路由层的位置上，然后直接在代表 darknet 的 nn.Module 对象的 forward 函数中执行拼接运算。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8x1JkOOUBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmptyLayer(nn.Module):\n",
        "     def __init__(self):\n",
        "            super(EmptyLayer, self).__init__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpgGOgn2hspz",
        "colab_type": "text"
      },
      "source": [
        "### 定义DetectionLayer 保存用于检测边界框的锚点\n",
        "<font color=red size=4>nn.Module</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArUR8AMhaiZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DetectionLayer(nn.Module):\n",
        "    def __init__(self, anchors):\n",
        "        super(DetectionLayer, self).__init__()\n",
        "        self.anchors = anchors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9mhiasvw3Qx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks30oz6jLdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_input():\n",
        "    img = cv2.imread(\"dog-cycle-car.png\")\n",
        "    img = cv2.resize(img, (416, 416))\n",
        "    img_ = img[:, :, ::-1].transpose((2, 0, 1))\n",
        "    img_ = img_[np.newaxis, :, :, :] / 255.0\n",
        "    img_ = torch.from_numpy(img_).float()\n",
        "    img_ = Variable(img_)\n",
        "    return img_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywbs55hJkfqm",
        "colab_type": "text"
      },
      "source": [
        "# util.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv5gWoIhygEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITl_JgY6ktoL",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "YOLO 的输出是一个卷积特征图，包含沿特征图深度的边界框属性。边界框属性由彼此堆叠的单元格预测得出。因此，如果你需要在 (5,6) 处访问单元格的第二个边框，那么你需要通过 map[5,6, (5+C): 2*(5+C)] 将其编入索引。这种格式对于输出处理过程（例如通过目标置信度进行阈值处理、添加对中心的网格偏移、应用锚点等）很不方便。\n",
        "\n",
        "另一个问题是由于检测是在三个尺度上进行的，预测图的维度将是不同的。虽然三个特征图的维度不同，但对它们执行的输出处理过程是相似的。最好能在单个张量上执行这些运算而不是三个单独张量\n",
        "\n",
        "为了解决这些问题，引入函数 predict_transform.</font>\n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png#pic_center)\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**predict_transform 有 5 个参数：**</font>  \n",
        "\n",
        "<font face=楷体 color=pink>prediction（输出）、inp_dim（输入图像的维度）、anchors、num_classes、CUDA flag（可选）</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "prediction\n",
        "~~~\n",
        "line5 : stride = inp_dim // prediction.size(2) 输入图像维度不是多维的吗？\n",
        "line12: prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)\n",
        "line14: anchors = [(a[0] / stride, a[1] / stride) for a in anchors]\n",
        "line32: x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0) \n",
        "line34: prediction[:, :, :2] += x_y_offset\n",
        "line42： anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)\n",
        "line43: prediction[:, :, 2:4] = torch.exp(prediction[:, :, 2:4]) * anchors  \n",
        "line48: prediction[:, :, :4] *= stride\n",
        "\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrk0_w3Tklp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_transform(prediction, inp_dim, anchors, num_classes, CUDA=True):\n",
        "    \n",
        "    # 将上图代码化\n",
        "    batch_size = prediction.size(0)  # 参数0代表第一个维度，例如：prediction是二维的时候size(0)等于其行数\n",
        "    stride = inp_dim // prediction.size(2) \n",
        "    grid_size = inp_dim // stride\n",
        "    bbox_attrs = 5 + num_classes\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    prediction = prediction.view(batch_size, bbox_attrs * num_anchors, grid_size * grid_size)\n",
        "    prediction = prediction.transpose(1, 2).contiguous()\n",
        "    prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)\n",
        "    \n",
        "    anchors = [(a[0] / stride, a[1] / stride) for a in anchors]\n",
        "    \n",
        "    # Sigmoid the  centre_X, centre_Y. and object confidencce\n",
        "    prediction[:, :, 0] = torch.sigmoid(prediction[:, :, 0])\n",
        "    prediction[:, :, 1] = torch.sigmoid(prediction[:, :, 1])\n",
        "    prediction[:, :, 4] = torch.sigmoid(prediction[:, :, 4])\n",
        "    \n",
        "    # Add the center offsets\n",
        "    grid_len = np.arange(grid_size)\n",
        "    a, b = np.meshgrid(grid_len, grid_len)  # a,b均为grid_len*grid_len矩阵，互为转置关系\n",
        "\n",
        "    x_offset = torch.FloatTensor(a).view(-1, 1)\n",
        "    y_offset = torch.FloatTensor(b).view(-1, 1)\n",
        "\n",
        "    if CUDA:\n",
        "        x_offset = x_offset.cuda()\n",
        "        y_offset = y_offset.cuda()\n",
        "\n",
        "    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0) \n",
        "\n",
        "    prediction[:, :, :2] += x_y_offset    \n",
        "    \n",
        "    # log space transform height and the width\n",
        "    anchors = torch.FloatTensor(anchors)\n",
        "\n",
        "    if CUDA:\n",
        "        anchors = anchors.cuda()\n",
        "\n",
        "    anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)\n",
        "    prediction[:, :, 2:4] = torch.exp(prediction[:, :, 2:4]) * anchors   \n",
        "    \n",
        "    # Softmax the class scores\n",
        "    prediction[:, :, 5: 5 + num_classes] = torch.sigmoid((prediction[:, :, 5: 5 + num_classes])) \n",
        "    \n",
        "    prediction[:, :, :4] *= stride  # ??????????????????????\n",
        "    \n",
        "    return prediction    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u5_qUscsN-5",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>输出满足 objectness 分数阈值和非极大值抑制（NMS），以得到后文所提到的「真实（true）」检测结果  \n",
        "创建一个名为 write_results 的函数  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>\n",
        "~~~\n",
        "line5: conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)\n",
        "line6: prediction = prediction * conf_mask   \n",
        "line32: max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)\n",
        "line34: max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)\n",
        "line35: max_conf = max_conf.float().unsqueeze(1)\n",
        "line37: seq = (image_pred[:, :5], max_conf, max_conf_score)   \n",
        "line38: image_pred = torch.cat(seq, 1)\n",
        "line44: image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)  # ????????????\n",
        "line47: img_classes = unique(image_pred_[:, -1])\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0iB2MnDr5-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_results(prediction, confidence, num_classes, nms=True, nms_conf=0.4):\n",
        "\n",
        "    # 预测张量包含有关 B x 10647 边界框的信息\n",
        "    # 对于有低于一个阈值的 objectness 分数的每个边界框，将其每个属性的值（表示该边界框的一整行）都设为零\n",
        "    conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)  \n",
        "    # 例如：torch.Size([3, 4, 5])____[:, :, 4]____>torch.Size([3, 4])____unsqueeze(2)___>torch.Size([3, 4, 1])\n",
        "    prediction = prediction * conf_mask   \n",
        "    \n",
        "    # 现在的边界框属性是由中心坐标以及边界框的高度和宽度决定\n",
        "    # 使用每个框的两个对角坐标能更轻松地计算两个框的 IoU\n",
        "    # 将框的 (中心 x, 中心 y, 宽, 高) 属性转换成 (左上角 x, 左上角 y, 右下角 x, 右下角 y)\n",
        "    box_a = prediction.new(prediction.shape)  # 构建一个具有相同类型的新张量作中间变量\n",
        "    \n",
        "    box_a[:, :, 0] = (prediction[:, :, 0] - prediction[:, :, 2] / 2)\n",
        "    box_a[:, :, 1] = (prediction[:, :, 1] - prediction[:, :, 3] / 2)\n",
        "    box_a[:, :, 2] = (prediction[:, :, 0] + prediction[:, :, 2] / 2)\n",
        "    box_a[:, :, 3] = (prediction[:, :, 1] + prediction[:, :, 3] / 2)\n",
        "    prediction[:, :, :4] = box_a[:, :, :4]\n",
        "    \n",
        "    # 每张图像中的「真实」检测结果的数量可能存在差异\n",
        "    # 比如，一个大小为 3 的 batch 中有 1、2、3 这 3 张图像，它们各自有 5、2、4 个「真实」检测结果\n",
        "    # 因此，一次只能完成一张图像的置信度阈值设置和 NMS，不能将所涉及的操作向量化，且必须在预测的第一个维度（包含一个 batch 中图像的索引）上循环\n",
        "    batch_size = prediction.size(0)\n",
        "    write = False\n",
        "    for ind in range(batch_size):\n",
        "        # select the image from the batch\n",
        "        image_pred = prediction[ind]\n",
        "        # confidence threshholding\n",
        "        # NMS    \n",
        "\n",
        "        # Get the class having maximum score, and the index of that class\n",
        "        # Get rid of num_classes softmax scores\n",
        "        # Add the class index and the class score of class having maximum score\n",
        "        max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)  # axis=1纵向比较，返回行索引\n",
        "        max_conf = max_conf.float().unsqueeze(1)\n",
        "        max_conf_score = max_conf_score.float().unsqueeze(1)\n",
        "        seq = (image_pred[:, :5], max_conf, max_conf_score)\n",
        "        image_pred = torch.cat(seq, 1)   \n",
        "        \n",
        "        # Get rid of the zero entries\n",
        "        non_zero_ind = (torch.nonzero(image_pred[:, 4]))\n",
        "\n",
        "        try:\n",
        "            image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)  # ????????????\n",
        "        except:\n",
        "            continue  # 跳出本轮循环   \n",
        "            \n",
        "        # Get the various classes detected in the image\n",
        "        img_classes = unique(image_pred_[:, -1])     \n",
        "        \n",
        "        # WE will do NMS classwise\n",
        "        for cls in img_classes:\n",
        "        \n",
        "            # get the detections with one particular class\n",
        "            cls_mask = image_pred_ * (image_pred_[:, -1] == cls).float().unsqueeze(1)\n",
        "            class_mask_ind = torch.nonzero(cls_mask[:, -2]).squeeze()\n",
        "\n",
        "            image_pred_class = image_pred_[class_mask_ind].view(-1, 7)\n",
        "\n",
        "            # sort the detections such that the entry with the maximum objectness\n",
        "            # confidence is at the top\n",
        "            conf_sort_index = torch.sort(image_pred_class[:, 4], descending=True)[1]\n",
        "            image_pred_class = image_pred_class[conf_sort_index]\n",
        "            idx = image_pred_class.size(0)  \n",
        "            \n",
        "                # 执行 NMS\n",
        "                # For each detection\n",
        "                for i in range(idx):\n",
        "                    # Get the IOUs of all boxes that come after the one we are looking at\n",
        "                    # in the loop\n",
        "                    try:\n",
        "                        ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i + 1:])\n",
        "                    except ValueError:\n",
        "                        break\n",
        "\n",
        "                    except IndexError:\n",
        "                        break\n",
        "\n",
        "                    # Zero out all the detections that have IoU > treshhold\n",
        "                    iou_mask = (ious < nms_conf).float().unsqueeze(1)\n",
        "                    image_pred_class[i + 1:] *= iou_mask\n",
        "\n",
        "                    # Remove the non-zero entries\n",
        "                    non_zero_ind = torch.nonzero(image_pred_class[:, 4]).squeeze()\n",
        "                    image_pred_class = image_pred_class[non_zero_ind].view(-1, 7)\n",
        "                    \n",
        "            # 将所得到的检测结果加入到输出张量中\n",
        "            batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)\n",
        "            seq = batch_ind, image_pred_class\n",
        "            if not write:\n",
        "                output = torch.cat(seq, 1)\n",
        "                write = True\n",
        "            else:\n",
        "                out = torch.cat(seq, 1)\n",
        "                output = torch.cat((output, out))     \n",
        "                \n",
        "    try:\n",
        "        return output\n",
        "    except:\n",
        "        return 0               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJOaAfrtujlm",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>同一类别可能会有多个「真实」检测结果，所以我们使用 unique 函数来获取任意给定图像中存在的类别</font>\n",
        "\n",
        "疑问"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi5iCRlduhDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unique(tensor):\n",
        "    tensor_np = tensor.cpu().numpy()\n",
        "    unique_np = np.unique(tensor_np)\n",
        "    unique_tensor = torch.from_numpy(unique_np)\n",
        "\n",
        "    tensor_res = tensor.new(unique_tensor.shape)\n",
        "    tensor_res.copy_(unique_tensor)\n",
        "    return tensor_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntmMbWb4QD3s",
        "colab_type": "text"
      },
      "source": [
        "**计算IOU**\n",
        "\n",
        "疑问：  \n",
        "\n",
        "\n",
        "line19: inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape).cuda()) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape).cuda())\n",
        "b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1) #加1？？？？？、"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqt-jypvP3AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bbox_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Returns the IoU of two bounding boxes\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # Get the coordinates of bounding boxes\n",
        "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
        "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
        "\n",
        "    # get the corrdinates of the intersection rectangle\n",
        "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
        "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
        "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
        "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
        "\n",
        "    # Intersection area\n",
        "    if torch.cuda.is_available():\n",
        "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape).cuda()) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape).cuda())\n",
        "    else:\n",
        "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape)) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape))\n",
        "\n",
        "    # Union Area\n",
        "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
        "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
        "\n",
        "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T-Dj2A3YoMw",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将每个类的索引映射到它的名称字符串，并以字典的形式返回</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBDvlQStYiV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_classes(namesfile):\n",
        "    fp = open(namesfile, \"r\")\n",
        "    names = fp.read().split(\"\\n\")[:-1]\n",
        "    return names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_kvd3JCbwoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_input():\n",
        "    img = cv2.imread(\"img/dog-cycle-car.png\")\n",
        "    img = cv2.resize(img, (416, 416))\n",
        "    img_ = img[:, :, ::-1].transpose((2, 0, 1))\n",
        "    img_ = img_[np.newaxis, :, :, :] / 255.0\n",
        "    img_ = torch.from_numpy(img_).float()\n",
        "    img_ = Variable(img_)\n",
        "    return img_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMyv_0JKc7RU",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>OpenCV以numpy数组的形式加载图像，BGR作为颜色通道的顺序。PyTorch的图像输入格式为：<font color=pink>**【批量x通道x高x宽】通道顺序为RGB**</font>。  \n",
        "因此，用函数prep_image将numpy数组转换为PyTorch的输入格式</font>  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问</font>  \n",
        "~~~\n",
        "line9: img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr2WGCivdyCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_image(img, inp_dim):\n",
        "    \"\"\"\n",
        "    Prepare image for inputting to the neural network. \n",
        "    \n",
        "    Returns a Variable \n",
        "    \"\"\"\n",
        "\n",
        "    img = cv2.resize(img, (inp_dim, inp_dim))\n",
        "    img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "    img = torch.from_numpy(img).float().div(255.0).unsqueeze(0)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjO1R_Tvd2tN",
        "colab_type": "text"
      },
      "source": [
        "函数letterbox_image来调整图像的大小，保持长宽比一致，并用颜色填充未填充的区域(128,128,128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y51mHzwac64O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def letterbox_image(img, inp_dim):\n",
        "    '''resize image with unchanged aspect ratio using padding'''\n",
        "    img_w, img_h = img.shape[1], img.shape[0]\n",
        "    w, h = inp_dim\n",
        "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
        "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
        "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n",
        "    \n",
        "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
        "\n",
        "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
        "    \n",
        "    return canvas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9LL9UqISMwe",
        "colab_type": "text"
      },
      "source": [
        "# detector.py  \n",
        "需要的参数：python detect.py --images dog-cycle-car.png --det det"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zNC0-wyRB54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 \n",
        "#from util import *\n",
        "import argparse\n",
        "import os \n",
        "import os.path as osp\n",
        "#from darknet import Darknet\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEMMAuQ4SzWm",
        "colab_type": "text"
      },
      "source": [
        "**检测文件需要传递命令行参数，用python的ArgParse模块来实现**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZpZolRSUXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def arg_parse():\n",
        "    \"\"\"\n",
        "    Parse arguements to the detect module\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description='YOLO v3 Detection Module')\n",
        "    \n",
        "    parser.add_argument(\"--images\", dest = 'images', help = \n",
        "                        \"Image / Directory containing images to perform detection upon\",\n",
        "                        default = \"imgs\", type = str)\n",
        "    parser.add_argument(\"--det\", dest = 'det', help = \n",
        "                        \"Image / Directory to store detections to\",\n",
        "                        default = \"det\", type = str)\n",
        "    parser.add_argument(\"--bs\", dest = \"bs\", help = \"Batch size\", default = 1)\n",
        "    parser.add_argument(\"--confidence\", dest = \"confidence\", help = \"Object Confidence to filter predictions\", default = 0.5)\n",
        "    parser.add_argument(\"--nms_thresh\", dest = \"nms_thresh\", help = \"NMS Threshhold\", default = 0.4)\n",
        "    parser.add_argument(\"--cfg\", dest = 'cfgfile', help = \n",
        "                        \"Config file\",\n",
        "                        default = \"cfg/yolov3.cfg\", type = str)\n",
        "    parser.add_argument(\"--weights\", dest = 'weightsfile', help = \n",
        "                        \"weightsfile\",\n",
        "                        default = \"yolov3.weights\", type = str)\n",
        "    parser.add_argument(\"--reso\", dest = 'reso', help = \n",
        "                        \"Input resolution of the network. Increase to increase accuracy. Decrease to increase speed\",\n",
        "                        default = \"416\", type = str)\n",
        "    \n",
        "    return parser.parse_args()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYG2CumsSUU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = arg_parse()\n",
        "images = args.images\n",
        "batch_size = int(args.bs)\n",
        "confidence = float(args.confidence)\n",
        "nms_thesh = float(args.nms_thresh)\n",
        "start = 0\n",
        "CUDA = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSrwPpT-YAUx",
        "colab_type": "text"
      },
      "source": [
        "**加载the class file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKKwxW4WX01X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 80    #For COCO\n",
        "classes = load_classes(\"data/coco.names\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CPsrYTkY6pL",
        "colab_type": "text"
      },
      "source": [
        "**初始化网络并加载权重**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg97uOOaSUSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set up the neural network\n",
        "print(\"Loading network.....\")\n",
        "model = Darknet(args.cfgfile)\n",
        "model.load_weights(args.weightsfile)\n",
        "print(\"Network successfully loaded\")\n",
        "\n",
        "model.net_info[\"height\"] = args.reso\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0 \n",
        "assert inp_dim > 32\n",
        "\n",
        "#If there's a GPU availible, put the model on GPU\n",
        "if CUDA:\n",
        "    model.cuda()\n",
        "\n",
        "#Set the model in evaluation mode\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X07VlBwZI4X",
        "colab_type": "text"
      },
      "source": [
        "**读取输入图像**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-E5JhMQSUPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "read_dir = time.time()\n",
        "#Detection phase\n",
        "try:\n",
        "    imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
        "except NotADirectoryError:\n",
        "    imlist = []\n",
        "    imlist.append(osp.join(osp.realpath('.'), images))\n",
        "except FileNotFoundError:\n",
        "    print (\"No file or directory with the name {}\".format(images))\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FirEvFSxb6LR",
        "colab_type": "text"
      },
      "source": [
        "如果保存检测的目录(由det标志定义)，不存在则创建它"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud4WkPC1SUMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(args.det):\n",
        "    os.makedirs(args.det)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sEmSpYdcQHV",
        "colab_type": "text"
      },
      "source": [
        "用OpenCV加载图像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pyKkfzHSUJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_batch = time.time()\n",
        "loaded_ims = [cv2.imread(x) for x in imlist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol6dqwdJcmux",
        "colab_type": "text"
      },
      "source": [
        "除转换后的图像，还保留了原始图像列表和im_dim_list，后者包含原始图像的维度。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DPa7l-qSUGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch Variables for images\n",
        "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
        "\n",
        "#List containing dimensions of original images\n",
        "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "\n",
        "if CUDA:\n",
        "    im_dim_list = im_dim_list.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3lSNMLexMy",
        "colab_type": "text"
      },
      "source": [
        "创建批次（batches）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8etRYGmewB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "leftover = 0\n",
        "if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "\n",
        "if batch_size != 1:\n",
        "    num_batches = len(imlist) // batch_size + leftover            \n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                       len(im_batches))]))  for i in range(num_batches)]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL0u1zAoi3Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write = 0\n",
        "start_det_loop = time.time()\n",
        "for i, batch in enumerate(im_batches):\n",
        "    #load the image \n",
        "    start = time.time()\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "\n",
        "    prediction = model(Variable(batch, volatile = True), CUDA)\n",
        "\n",
        "    prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    if type(prediction) == int:\n",
        "\n",
        "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "            im_id = i*batch_size + im_num\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        continue\n",
        "\n",
        "    prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
        "\n",
        "    if not write:                      #If we have't initialised output\n",
        "        output = prediction  \n",
        "        write = 1\n",
        "    else:\n",
        "        output = torch.cat((output,prediction))\n",
        "\n",
        "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "        im_id = i*batch_size + im_num\n",
        "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "    if CUDA:\n",
        "        torch.cuda.synchronize()           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxNUy-G4jaiF",
        "colab_type": "text"
      },
      "source": [
        "**在图像上绘制边框**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crKUzXlZjZs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    output\n",
        "except NameError:\n",
        "    print (\"No detections were made\")\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P9j9C2cj6_1",
        "colab_type": "text"
      },
      "source": [
        "在绘制边界框之前，输出张量中包含的预测符合网络的输入大小，而不是图像的原始大小。因此，在绘制边界框之前，要将每个边界框的角属性转换为图像的原始维度  \n",
        "在绘制边界框之前，输出张量中包含的预测是对填充图像的预测，而不是对原始图像的预测。仅仅将它们重新缩放到输入图像的维数在这里是行不通的。首先，我们需要转换要测量的框的坐标相对于包含原始图像的填充图像上区域的边界。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExUgc2Gnj4er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
        "\n",
        "scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)\n",
        "\n",
        "\n",
        "output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
        "output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu4IMf9okfDl",
        "colab_type": "text"
      },
      "source": [
        "现在，坐标符合填充区域上图像的尺寸。然而，在函数letterbox_image中，通过缩放因子调整了图像的两个维度的大小(两个维度都用一个公共因子来划分，以保持长宽比)，现在要撤消这个，重新缩放，以获得原始图像上的边框的坐标。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTzTjKDkeHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output[:,1:5] /= scaling_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7SG247keR7",
        "colab_type": "text"
      },
      "source": [
        "Let us now clip any bounding boxes that may have boundaries outside the image to the edges of our image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZcvEtAhkdi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(output.shape[0]):\n",
        "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
        "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyrG0_tlP63",
        "colab_type": "text"
      },
      "source": [
        "用不同的颜色画框"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArA6ATSlUp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_load = time.time()\n",
        "colors = pkl.load(open(\"pallete\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8N5Z_EHlifE",
        "colab_type": "text"
      },
      "source": [
        "开始画框"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2_GrGllNoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw = time.time()\n",
        "\n",
        "def write(x, results, color):\n",
        "    c1 = tuple(x[1:3].int())\n",
        "    c2 = tuple(x[3:5].int())\n",
        "    img = results[int(x[0])]\n",
        "    cls = int(x[-1])\n",
        "    label = \"{0}\".format(classes[cls])\n",
        "    cv2.rectangle(img, c1, c2,color, 1)\n",
        "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "    cv2.rectangle(img, c1, c2,color, -1)\n",
        "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17VPeFy7mBJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(lambda x: write(x, loaded_ims), output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_M64LCdmJh4",
        "colab_type": "text"
      },
      "source": [
        "通过在图像名称前面加上前缀“det_”保存每个图像。我们创建一个地址列表，并将检测图像保存到其中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bHr484mCYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(args.det,x.split(\"/\")[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IhKhxz5mRwa",
        "colab_type": "text"
      },
      "source": [
        "最后，用det_names将检测到的图像写入地址。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qRen6JRmNE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i_ifQCgmdZO",
        "colab_type": "text"
      },
      "source": [
        "**打印Time Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG4-OMO3mcyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"SUMMARY\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "print()\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhJpd_NHrl3a",
        "colab_type": "text"
      },
      "source": [
        "# 测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "141yClAmRMlU",
        "colab_type": "text"
      },
      "source": [
        "<div id=\"测试一\">测试一</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAOk32apZse",
        "colab_type": "code",
        "outputId": "a2c4fd6d-dbb2-4d42-ef51-4be10fb18317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!mkdir cfg\n",
        "!cd cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "blocks = parse_cfg(\"yolov3.cfg\")\n",
        "print(create_modules(blocks))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘cfg’: File exists\n",
            "--2019-08-22 02:51:16--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg.2’\n",
            "\n",
            "yolov3.cfg.2        100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-22 02:51:16 (124 MB/s) - ‘yolov3.cfg.2’ saved [8342/8342]\n",
            "\n",
            "({'type': 'net', 'batch': '64', 'subdivisions': '16', 'width': '608', 'height': '608', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, ModuleList(\n",
            "  (0): Sequential(\n",
            "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (4): Sequential(\n",
            "    (shortcut_4): EmptyLayer()\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (8): Sequential(\n",
            "    (shortcut_8): EmptyLayer()\n",
            "  )\n",
            "  (9): Sequential(\n",
            "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (10): Sequential(\n",
            "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (11): Sequential(\n",
            "    (shortcut_11): EmptyLayer()\n",
            "  )\n",
            "  (12): Sequential(\n",
            "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (13): Sequential(\n",
            "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (14): Sequential(\n",
            "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (15): Sequential(\n",
            "    (shortcut_15): EmptyLayer()\n",
            "  )\n",
            "  (16): Sequential(\n",
            "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (17): Sequential(\n",
            "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (18): Sequential(\n",
            "    (shortcut_18): EmptyLayer()\n",
            "  )\n",
            "  (19): Sequential(\n",
            "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (20): Sequential(\n",
            "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (21): Sequential(\n",
            "    (shortcut_21): EmptyLayer()\n",
            "  )\n",
            "  (22): Sequential(\n",
            "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (23): Sequential(\n",
            "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (24): Sequential(\n",
            "    (shortcut_24): EmptyLayer()\n",
            "  )\n",
            "  (25): Sequential(\n",
            "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (26): Sequential(\n",
            "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (27): Sequential(\n",
            "    (shortcut_27): EmptyLayer()\n",
            "  )\n",
            "  (28): Sequential(\n",
            "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (29): Sequential(\n",
            "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (30): Sequential(\n",
            "    (shortcut_30): EmptyLayer()\n",
            "  )\n",
            "  (31): Sequential(\n",
            "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (32): Sequential(\n",
            "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (33): Sequential(\n",
            "    (shortcut_33): EmptyLayer()\n",
            "  )\n",
            "  (34): Sequential(\n",
            "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (35): Sequential(\n",
            "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (36): Sequential(\n",
            "    (shortcut_36): EmptyLayer()\n",
            "  )\n",
            "  (37): Sequential(\n",
            "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (38): Sequential(\n",
            "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (39): Sequential(\n",
            "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (40): Sequential(\n",
            "    (shortcut_40): EmptyLayer()\n",
            "  )\n",
            "  (41): Sequential(\n",
            "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (42): Sequential(\n",
            "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (43): Sequential(\n",
            "    (shortcut_43): EmptyLayer()\n",
            "  )\n",
            "  (44): Sequential(\n",
            "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (45): Sequential(\n",
            "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (46): Sequential(\n",
            "    (shortcut_46): EmptyLayer()\n",
            "  )\n",
            "  (47): Sequential(\n",
            "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (48): Sequential(\n",
            "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (49): Sequential(\n",
            "    (shortcut_49): EmptyLayer()\n",
            "  )\n",
            "  (50): Sequential(\n",
            "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (51): Sequential(\n",
            "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (52): Sequential(\n",
            "    (shortcut_52): EmptyLayer()\n",
            "  )\n",
            "  (53): Sequential(\n",
            "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (54): Sequential(\n",
            "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (55): Sequential(\n",
            "    (shortcut_55): EmptyLayer()\n",
            "  )\n",
            "  (56): Sequential(\n",
            "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (57): Sequential(\n",
            "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (58): Sequential(\n",
            "    (shortcut_58): EmptyLayer()\n",
            "  )\n",
            "  (59): Sequential(\n",
            "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (60): Sequential(\n",
            "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (61): Sequential(\n",
            "    (shortcut_61): EmptyLayer()\n",
            "  )\n",
            "  (62): Sequential(\n",
            "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (63): Sequential(\n",
            "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (64): Sequential(\n",
            "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (65): Sequential(\n",
            "    (shortcut_65): EmptyLayer()\n",
            "  )\n",
            "  (66): Sequential(\n",
            "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (67): Sequential(\n",
            "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (68): Sequential(\n",
            "    (shortcut_68): EmptyLayer()\n",
            "  )\n",
            "  (69): Sequential(\n",
            "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (70): Sequential(\n",
            "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (71): Sequential(\n",
            "    (shortcut_71): EmptyLayer()\n",
            "  )\n",
            "  (72): Sequential(\n",
            "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (73): Sequential(\n",
            "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (74): Sequential(\n",
            "    (shortcut_74): EmptyLayer()\n",
            "  )\n",
            "  (75): Sequential(\n",
            "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (76): Sequential(\n",
            "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (77): Sequential(\n",
            "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (78): Sequential(\n",
            "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (79): Sequential(\n",
            "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (80): Sequential(\n",
            "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (81): Sequential(\n",
            "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (82): Sequential(\n",
            "    (Detection_82): DetectionLayer()\n",
            "  )\n",
            "  (83): Sequential(\n",
            "    (route_83): EmptyLayer()\n",
            "  )\n",
            "  (84): Sequential(\n",
            "    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (85): Sequential(\n",
            "    (upsample_85): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (86): Sequential(\n",
            "    (route_86): EmptyLayer()\n",
            "  )\n",
            "  (87): Sequential(\n",
            "    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (88): Sequential(\n",
            "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (89): Sequential(\n",
            "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (90): Sequential(\n",
            "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (91): Sequential(\n",
            "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (92): Sequential(\n",
            "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (93): Sequential(\n",
            "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (94): Sequential(\n",
            "    (Detection_94): DetectionLayer()\n",
            "  )\n",
            "  (95): Sequential(\n",
            "    (route_95): EmptyLayer()\n",
            "  )\n",
            "  (96): Sequential(\n",
            "    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (97): Sequential(\n",
            "    (upsample_97): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (98): Sequential(\n",
            "    (route_98): EmptyLayer()\n",
            "  )\n",
            "  (99): Sequential(\n",
            "    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (100): Sequential(\n",
            "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (101): Sequential(\n",
            "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (102): Sequential(\n",
            "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (103): Sequential(\n",
            "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (104): Sequential(\n",
            "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (105): Sequential(\n",
            "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (106): Sequential(\n",
            "    (Detection_106): DetectionLayer()\n",
            "  )\n",
            "))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-uY09vjRf4e",
        "colab_type": "text"
      },
      "source": [
        "测试一"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgZiTiYiQ86V",
        "colab_type": "code",
        "outputId": "e59bb13b-37e2-491c-abdd-2bbb907eff84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "model = Darknet(\"yolov3.cfg\")\n",
        "model.load_weights(\"yolov3.weights\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-22 03:00:24--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  57.9MB/s    in 4.3s    \n",
            "\n",
            "2019-08-22 03:00:29 (55.2 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95xiJJ7vQ-z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfkv-cBRQ-xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3zZciE2pgEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-EzKUPXxrMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTiq-J8pluS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-5W-ugVnNJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ajaoj3olnVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Darknet(\"yolov3.cfg\")\n",
        "inp = get_test_input()\n",
        "pred = model(inp, torch.cuda.is_available())\n",
        "print (pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S1yXdMimrG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Darknet(\"yolov3.cfg\")\n",
        "model.load_weights(\"yolov3.weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Sst-uirOVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS5G5mEnppv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_YAhguVprhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcZ17FGsAMLm",
        "colab_type": "code",
        "outputId": "9a8847c7-764d-4111-b903-37bab03f04ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "st0= 'iisongiiihuaniiiigongi'\n",
        "\n",
        "print(st0.split('i'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '', 'song', '', '', 'huan', '', '', '', 'gong', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAtJstEpANG0",
        "colab_type": "code",
        "outputId": "12e6b618-4911-403a-899f-15fd1ae67451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "str=\"hello boy<[www.doiido.com]>byebye\"\n",
        "st = str.split(\"[\")[1]\n",
        "print(st)\n",
        "print(type(st))\n",
        "s = st.split(\"]\")[0]\n",
        "print(s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "www.doiido.com]>byebye\n",
            "<class 'str'>\n",
            "www.doiido.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk-oFU9WAupo",
        "colab_type": "code",
        "outputId": "01ff07d4-0504-48be-be19-b221dca39fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s[1:-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ww.doiido.co'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBRksbsci1Wc",
        "colab_type": "code",
        "outputId": "783ec80b-8d25-4307-bcc5-6e061efb5b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'m'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq6OcIyWjG5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqRptp_8pn4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "for i in range(0, 9,8):\n",
        "    a.append(i)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWfKfpu3p3r1",
        "colab_type": "code",
        "outputId": "8ea674b8-2ec8-492b-ad38-986bf170f2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZWUcSt28AWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}