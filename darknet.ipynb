{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "darknet",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "HxR9iVyej3rh",
        "R9zJJFZXNrRn",
        "s-ufryjTP1IG",
        "b-X6Zb85urR3",
        "H9LL9UqISMwe",
        "KhJpd_NHrl3a"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/master/darknet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WEuumVfwWze",
        "colab_type": "text"
      },
      "source": [
        "# <font face=STCAIYUN color=purple size=8>YOLOv3</font>\n",
        "<font face=楷体 color=skyblue size=4>YOLO 是 You Only Look Once 的缩写</font>  \n",
        "<font face=楷体 color=skyblue size=4>**全卷积神经网络** </font>  \n",
        "<font face=楷体>\n",
        "YOLO 仅使用卷积层，即：全卷积神经网络（FCN对于输入图像的大小不敏感） ，它拥有 75 个卷积层，带有跳跃连接和上采样层。不使用任何它形式的，使用步幅为 2 的卷积层代替池化层对特征图进行下采样，防止池化导致的低级特征丢失 \n",
        "    \n",
        "问题是：如果我们希望按批次处理图像（批量图像由 GPU 并行处理，这样可以提升速度），我们就需要固定所有图像的高度和宽度。这就需要将多个图像整合进一个大的批次（将许多 PyTorch 张量合并成一个）</font>  \n",
        " \n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**YOLOv3网络结构图** </font>  \n",
        "\n",
        "![替代文字](https://img-blog.csdnimg.cn/20190824145218799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzcxMTU1NA==,size_16,color_FFFFFF,t_70)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**网络输出**</font>   \n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo-5.png)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>锚点框（Anchor Box）</font>  \n",
        "<font face=楷体>\n",
        "预测边界框的宽度和高度看上去是最直接的，但实践训练中会带来梯度不稳定，所以现在大部分目标检测器都预测对数空间（log-space）变换量，或者预测与预定义边界框（即锚点）之间的偏移量  \n",
        "这些变换被应用到锚点框来获得预测，YOLO v3 有三个锚点，所以每个单元格会预测 3 个边界框  \n",
        "</font>   \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>中心坐标</font>    \n",
        "<font face=楷体>\n",
        "通过一个sigmoid函数对中心坐标预测，迫使输出介于0和1之间  \n",
        "YOLO通常不会预测边界框中心的绝对坐标而是预测偏移量：  \n",
        "\n",
        "\n",
        "*   相对于预测对象格单元格的左上角\n",
        "*   由特征图中的单元格尺寸标准化，如上图：对狗狗中心的预测是（0.4，0.7），那么中心位于$13 \\times 13$特征图上的（6.4，6.7）位置  \n",
        "</font>\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=5>预测</font>  \n",
        "<font face=楷体>每个bounding box预测5个值：$\\color{pink}{t_x，t_y，t_w，t_h，t_o}$ （$t_o$类似YOLOv1中的confidence）  \n",
        "\n",
        "*   $\\color{pink}{t_x，t_y}$：经过sigmoid函数处理后范围在0到1之间，模型训练更加稳定  \n",
        "*   $\\color{pink}{c_x，c_y}$：表示一个cell和图像左上角的横纵距离 \n",
        "*   $\\color{pink}{p_w，p_h}$：表示bounding box的宽高 \n",
        "</font>\n",
        "\n",
        " \n",
        "$$\n",
        "\\begin{aligned} b_{x} &=\\sigma\\left(t_{x}\\right)+c_{x} \\\\ b_{y} &=\\sigma\\left(t_{y}\\right)+c_{y} \\\\ b_{w} &=p_{w} e^{t_{w}} \\\\ b_{h} &=p_{h} e^{t_{h}} \\\\ \\operatorname{Pr}(\\text { object }) * I O U(b, \\text { object }) &=\\sigma\\left(t_{o}\\right)\\end{aligned}\n",
        "$$\n",
        "\n",
        "<font face=楷体 color=yellow>在Faster R-CNN中：</font>\n",
        "$$\\begin{align}\n",
        "t_x &= (x - x_a) /w_a \\ ,\\  \\ t_y = (y - y_a) / h_a\\\\[1ex]t_w &= log(w/ w_a), \\quad \\ \\  t_h = log(h/h_a)\\\\[1ex]t_x^* &= (x^* - x_a) / w_a,\\  t_y^* = (y^* - y_a) /h_a\\\\[1ex]t_w^* &= log(w^* - w),\\ \\  h_h^* = log(h^*/h_a)\n",
        "\\end{align}$$  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>边界框的尺寸</font>   \n",
        "<font face=楷体>\n",
        "将输出进行对数变换乘以锚来预测边界框的尺寸  \n",
        "预测结果$b_w$和$b_h$由图像的高度和宽度标准化，包含狗的框的预测$b_x$和$b_y$是$（0.3，0.8）$，那么$13 \\times 13$特征图上的实际宽度和高度是$（13 \\times 0.3,13 \\times 0.8）$\n",
        "</font>\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo-regression-1.png)  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>Score</font>  \n",
        "<font face=楷体>\n",
        "对象得分通过sigmoid转换到0、1之间，可以解释为概率  \n",
        "</font>  \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>Class Confidences</font>   \n",
        "<font face=楷体>\n",
        "v3使用sigmoid代替softmax进行分类，原因是Softmax假设所有类别是互斥的，即：如果一个对象属于一个类，那么就一定不属于另一个类（COCO数据库是可以的但如：医生和人就不成立了）  \n",
        "</font>   \n",
        "<font face=楷体 color=skyblue size=4>多尺度预测</font>   \n",
        "<font face=楷体>\n",
        "基于三种不同尺寸的特征图进行检测，<font color=skyblue>有助于检测小物体</font>。如：输入尺寸为$416 \\times 416$，在$13 \\times 13,26 \\times 26,52 \\times 52$的特诊图上进行检测  \n",
        "每个尺度上，每个单元格使用3个anchors预测3个边界框，使得使用的anchors总数为9.（<font color=skyblue>不同尺度上的anchors不同</font>）  \n",
        "</font> \n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/yolo_Scales-1.png)  \n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=5>输出处理</font>  \n",
        "<font face=楷体>  \n",
        "对于尺寸为$416\\times 416$的图像，YOLO预测$（（52\\times 52）+（26\\times 26）+ 13\\times 13））×3 = 10647$个边界框  \n",
        "<font color=skyblue>\n",
        "通过对象置信度进行阈值处理  \n",
        "非极大抑制（NMS）\n",
        "</font>\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxR9iVyej3rh",
        "colab_type": "text"
      },
      "source": [
        "# Darknet.py  \n",
        "<font face=楷体>\n",
        "Darknet是YOLO底层架构的名称，darknet.py包含YOLO网络的代码（util.py将包含各种辅助函数的代码）\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9zJJFZXNrRn",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 解析配置文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lee0sSfNRGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#from util import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJVXBiSkN-HH",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "定义一个函数 parse_cfg，用配置文件的路径作为输入  \n",
        "    \n",
        "将 <font color=skyblue size=4>**Net 、  Convolutional  、 Shortcut  、Upsample 、 Route 、 YOLO**</font> 以列表（blocks）的形式返回\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy3tzMrnNeyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_cfg(cfgfile):\n",
        "    \"\"\"\n",
        "    Takes a configuration file\n",
        "    Returns a list of blocks. Each blocks describes a block in the neural\n",
        "    network to be built. Block is represented as a dictionary in the list    \n",
        "    \"\"\"\n",
        "    file = open(cfgfile, 'r')\n",
        "    lines = file.read().split('\\n')                        # store the lines in a list\n",
        "    lines = [x for x in lines if len(x) > 0]               # get read of the empty lines \n",
        "    lines = [x for x in lines if x[0] != '#']              # get rid of comments\n",
        "    lines = [x.rstrip().lstrip() for x in lines]           # get rid of fringe whitespaces\n",
        "    \n",
        "    block = {}\n",
        "    blocks = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line[0] == \"[\":               # This marks the start of a new block\n",
        "            if len(block) != 0:          # If block is not empty, implies it is storing values of previous block.\n",
        "                blocks.append(block)     # add it the blocks list\n",
        "                block = {}               # re-init the block\n",
        "            block[\"type\"] = line[1:-1].rstrip()     \n",
        "        else:\n",
        "            key,value = line.split(\"=\") \n",
        "            block[key.rstrip()] = value.lstrip()\n",
        "    blocks.append(block)\n",
        "\n",
        "    return blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-ufryjTP1IG",
        "colab_type": "text"
      },
      "source": [
        "###1.2构建 PyTorch 模块   \n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**create_modules 函数用 parse_cfg 函数返回的 blocks 列表构建网络模块：**</font>\n",
        "\n",
        "<font face=楷体>\n",
        "\n",
        "*   先定义变量 net_info，来存储该网络的信息\n",
        "\n",
        "*  当添加 nn.ModuleList 作为 nn.Module 对象的一个成员时（即添加模块到网络），所有 nn.ModuleList 内部的 nn.Module 对象（模块）的 parameter 也被添加   作为 nn.Module 对象（即网络添加 nn.ModuleList 作为其成员）的 parameter\n",
        "\n",
        "*   卷积核的深度是由上一层的卷积核数量（或特征图深度）决定的。这意味着需要持续追踪被应用卷积层的卷积核数量，用变量 prev_filter 实现追踪（RGB3通道所以初始化为3）\n",
        "\n",
        "*  路由层（route layer）从前面层得到特征图，不仅需要追踪前一层的卷积核数量，还需要追踪之前每一层。不断地迭代，将每个模块的输出卷积核数量添加到 output_filters 列表 \n",
        "\n",
        "*  nn.Sequential 类是能让nn.Module 对象有序执行的数字，一个模块可能包含多个层，用 nn.Sequential 将这些层串联起来\n",
        "    \n",
        "</font>  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>   \n",
        "\n",
        "detection = DetectionLayer(anchors)  \n",
        "路由层  \n",
        "YOLO层mask  \n",
        "line87: filters = output_filters[index + start] + output_filters[index + end]\n",
        "line107:  anchors = [anchors[i] for i in mask]   \n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接:**</font>  \n",
        "\n",
        "【1】[nn.Conv2d 、nn.BatchNorm2d](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#torchnn)  \n",
        "【2】[torch.nn.Upsample](https://pytorch.org/docs/stable/nn.html?highlight=nn%20upsample#torch.nn.Upsample)  \n",
        "【3】[darknet 所有层功能说明 ](https://blog.csdn.net/zhuiqiuk/article/details/88187034)   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b40dPOsVPGH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_modules(blocks):\n",
        "    net_info = blocks[0]  # Captures the information about the input and pre-processing\n",
        "    module_list = nn.ModuleList()\n",
        "    index = 0  # indexing blocks helps with implementing route  layers (skip connections)\n",
        "    prev_filters = 3\n",
        "    output_filters = []\n",
        "    \n",
        "    # 迭代模块的列表，并为每个模块创建一个 PyTorch 模块\n",
        "    for index, x in enumerate(blocks[1:]): \n",
        "        module = nn.Sequential()\n",
        "        #check the type of block\n",
        "        #create a new module for the block\n",
        "        #append to module_list\n",
        "        \n",
        "       #创建卷积层\n",
        "       # If it's a convolutional layer\n",
        "        if (x[\"type\"] == \"convolutional\"):\n",
        "            # Get the info about the layer\n",
        "            activation = x[\"activation\"]\n",
        "            try:\n",
        "                batch_normalize = int(x[\"batch_normalize\"])\n",
        "                bias = False\n",
        "            except:\n",
        "                batch_normalize = 0\n",
        "                bias = True\n",
        "\n",
        "            filters = int(x[\"filters\"])\n",
        "            padding = int(x[\"pad\"])\n",
        "            kernel_size = int(x[\"size\"])\n",
        "            stride = int(x[\"stride\"])\n",
        "\n",
        "            if padding:\n",
        "                pad = (kernel_size - 1) // 2\n",
        "            else:\n",
        "                pad = 0\n",
        "\n",
        "            # Add the convolutional layer\n",
        "            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=bias)\n",
        "            module.add_module(\"conv_{0}\".format(index), conv)\n",
        "            \n",
        "            # Add the Batch Norm Layer\n",
        "            if batch_normalize:\n",
        "                bn = nn.BatchNorm2d(filters)\n",
        "                module.add_module(\"batch_norm_{0}\".format(index), bn)\n",
        "\n",
        "            # Check the activation.\n",
        "            # It is either Linear or a Leaky ReLU for YOLO\n",
        "            if activation == \"leaky\":\n",
        "                activn = nn.LeakyReLU(0.1, inplace=True)\n",
        "                module.add_module(\"leaky_{0}\".format(index), activn)\n",
        "\n",
        "        # 构建上采样层\n",
        "        # If it's an upsampling layer\n",
        "        # We use Bilinear2dUpsampling\n",
        "        elif (x[\"type\"] == \"upsample\"):\n",
        "            stride = int(x[\"stride\"])\n",
        "            upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
        "            module.add_module(\"upsample_{}\".format(index), upsample)\n",
        "            \n",
        "\n",
        "        # 路由层\n",
        "        # 当layer为正时，输出对应层特征，为负时，输出当前层前往回数第layer层特征\n",
        "        # If it is a route layer\n",
        "        elif (x[\"type\"] == \"route\"):\n",
        "            x[\"layers\"] = x[\"layers\"].split(',')\n",
        "\n",
        "            # Start  of a route\n",
        "            start = int(x[\"layers\"][0])\n",
        "\n",
        "            # end, if there exists one.\n",
        "            try:\n",
        "                end = int(x[\"layers\"][1])\n",
        "            except:\n",
        "                end = 0\n",
        "\n",
        "            # Positive anotation\n",
        "            if start > 0:\n",
        "                start = start - index\n",
        "\n",
        "            if end > 0:\n",
        "                end = end - index\n",
        "\n",
        "            route = EmptyLayer()\n",
        "            module.add_module(\"route_{0}\".format(index), route)\n",
        "\n",
        "            if end < 0:\n",
        "                filters = output_filters[index + start] + output_filters[index + end]\n",
        "            else:\n",
        "                filters = output_filters[index + start]\n",
        "                \n",
        "        # 捷径层       \n",
        "        # shortcut corresponds to skip connection\n",
        "        if x[\"type\"] == \"shortcut\":\n",
        "            shortcut = EmptyLayer()\n",
        "            module.add_module(\"shortcut_{}\".format(index), shortcut)    \n",
        "                      \n",
        "        \n",
        "        # YOLO层\n",
        "        # Yolo is the detection layer\n",
        "        if x[\"type\"] == \"yolo\":\n",
        "            mask = x[\"mask\"].split(\",\") \n",
        "            mask = [int(x) for x in mask] \n",
        "\n",
        "            anchors = x[\"anchors\"].split(\",\")\n",
        "            anchors = [int(a) for a in anchors]\n",
        "            anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
        "            anchors = [anchors[i] for i in mask]  # 取前三个？？\n",
        "\n",
        "            detection = DetectionLayer(anchors)\n",
        "            module.add_module(\"Detection_{}\".format(index), detection)  \n",
        "            \n",
        "        # 回路结束时，做一些统计（bookkeeping.）\n",
        "        module_list.append(module)\n",
        "        prev_filters = filters\n",
        "        output_filters.append(filters)\n",
        "        \n",
        "    return (net_info, module_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-X6Zb85urR3",
        "colab_type": "text"
      },
      "source": [
        "### 1.3定义网络\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>\n",
        "用 nn.Module 在 PyTorch 中构建自定义架构：  \n",
        "    \n",
        "*   定义nn.Module子类Darknet，用 members、blocks、net_info 和 module_list 进行初始化  \n",
        "\n",
        "*   重写forward方法来实现网络的前向传递nn.Module ：1）计算输出；2）以一种可以更容易处理的方式转换输出检测特征图，例如：将它们转换为可以连接多个尺度的检测图（ self.blocks 的第一个元素是 net 块，不属于前向传播，所以迭代的对象是 self.block[1:]）\n",
        "\n",
        "*   与create_modules函数一样，module_list中包含网络的模块。模块顺序与配置文件中的顺序相同。因此，可以输入通过每个模块就可以简单地得到输出\n",
        "*   路由层需要连接两个特征图谱， torch.cat第二个参数为1（沿着深度连接特征图谱） \n",
        "    \n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxd7AJ1NHmVn",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>加载权重</font>   \n",
        "<font face=楷体 color=skyblue>权重是如何存储：</font>  \n",
        "\n",
        "<font face=楷体>\n",
        "权重只属于<font color=skyblue>批量归一化层（batch norm layer）和卷积层</font>  两种类型的层，储存顺序和配置文件中定义层级的顺序完全相同  \n",
        "    \n",
        "下图展示了权重如何储存：\n",
        "</font>\n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/wts-1.png)\n",
        "\n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "<font face=楷体>\n",
        "\\# 卷积和上采样层\n",
        "if module_type == \"convolutional\" or module_type == \"upsample\":  \n",
        "    x = self.module_list\\[i](x)  \n",
        "    outputs[i] = x   \n",
        "line52: anchors = self.module_list[i][0].anchors\n",
        "line59: x = x.data  \n",
        " *  <font color=skyblue>Variable是tensor的外包装，data属性存储着tensor数据，grad属性存储关于该变量的导数，creator是代表该变量的创造者[$^{【2】}$](https://zhuanlan.zhihu.com/p/34298983)  </font>  \n",
        "\n",
        "line73: outputs[i] = x\n",
        "line74: batch_normalize = int(self.blocks[i + 1][\"batch_normalize\"])  \n",
        "line102:  bn_biases = bn_biases.view_as(bn.bias.data)\n",
        "                \n",
        "</font> \n",
        "<font face=楷体 color=green size=4>绿色链接</font>  \n",
        "【1】[Tensor and tensor.data](https://discuss.pytorch.org/t/tensor-and-tensor-data/18427)  \n",
        "【2】[autograd 及Variable](https://zhuanlan.zhihu.com/p/34298983)  \n",
        "【3】[What about .data?](https://pytorch.org/blog/pytorch-0_4_0-migration-guide/#what-about-data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzhDjzWcZrzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Darknet(nn.Module):\n",
        "    def __init__(self, cfgfile):\n",
        "        super(Darknet, self).__init__()\n",
        "        self.blocks = parse_cfg(cfgfile)\n",
        "        self.net_info, self.module_list = create_modules(self.blocks)\n",
        "        \n",
        "    # 前向传播\n",
        "    def forward(self, x, CUDA):\n",
        "        detections = []\n",
        "        modules = self.blocks[1:]\n",
        "        outputs = {}  # We cache the outputs for the route layer    \n",
        "        \n",
        "        # write表示是否遇到第一个检测\n",
        "        # write=0，收集器未初始化\n",
        "        # write=1，收集器已初始化，只需要将检测图与收集器级联起来即可\n",
        "        write = 0\n",
        "        for i in range(len(modules)):\n",
        "            module_type = (modules[i][\"type\"])    \n",
        "            \n",
        "            # 卷积和上采样层\n",
        "            if module_type == \"convolutional\" or module_type == \"upsample\":\n",
        "                x = self.module_list[i](x)\n",
        "                outputs[i] = x     \n",
        "                \n",
        "            # 路由层\n",
        "            elif module_type == \"route\":\n",
        "                layers = modules[i][\"layers\"]\n",
        "                layers = [int(a) for a in layers]\n",
        "\n",
        "                if (layers[0]) > 0:\n",
        "                    layers[0] = layers[0] - i\n",
        "\n",
        "                if len(layers) == 1:\n",
        "                    x = outputs[i + (layers[0])]\n",
        "\n",
        "                else:\n",
        "                    if (layers[1]) > 0:\n",
        "                        layers[1] = layers[1] - i\n",
        "\n",
        "                    map1 = outputs[i + layers[0]]\n",
        "                    map2 = outputs[i + layers[1]]\n",
        "\n",
        "                    x = torch.cat((map1, map2), 1)\n",
        "                \n",
        "            elif module_type == \"shortcut\":\n",
        "                from_ = int(modules[i][\"from\"])\n",
        "                x = outputs[i - 1] + outputs[i + from_]  # 直接相加，不会改变维度\n",
        "            \n",
        "            # YOLO层\n",
        "            elif module_type == 'yolo':        \n",
        "                anchors = self.module_list[i][0].anchors\n",
        "                #Get the input dimensions\n",
        "                inp_dim = int (self.net_info[\"height\"])\n",
        "\n",
        "                #Get the number of classes\n",
        "                num_classes = int (module[\"classes\"])\n",
        "\n",
        "                #Transform \n",
        "                # Variable是tensor的外包装，data属性存储着tensor数据，grad属性存储关于该变量的导数，creator是代表该变量的创造者\n",
        "                x = x.data  # x是一个Variable， x.data 则是一个Tensor\n",
        "                x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n",
        "                if not write:              #if no collector has been intialised. \n",
        "                    detections = x\n",
        "                    write = 1\n",
        "\n",
        "                else:\n",
        "                    # 变换后x的维度是(batch_size, grid_size*grid_size*num_anchors, 5+类别数量)\n",
        "                    # 在维度1上合并，即：按anchor数量的维度拼接\n",
        "                    # 对应教程part3中的Bounding Box attributes图的行进行连接\n",
        "                    # 共有3个yolo层，对于每个yolo层的输出先用predict_transform()转换成每行为一个anchor对应的预测值的形式(忽略batch_size维度，x剩下的可看成二维tensor)\n",
        "                    # 3个yolo层的预测值按照每个方框对应的行的维度进行连接，得到了图片所有anchor预测值，以便后面的NMS等操作可以一次完成\n",
        "                    detections = torch.cat((detections, x), 1)\n",
        "\n",
        "            outputs[i] = x  # 储存每一层特征图谱，以便route层和shortcut层调用\n",
        "\n",
        "        return detections\n",
        "    \n",
        "    # 加载权重            \n",
        "    def load_weights(self, weightfile):\n",
        "        # Open the weights file\n",
        "        fp = open(weightfile, \"rb\")\n",
        "\n",
        "        # 第一个 160 比特的权重文件保存了 5 个 int32 值，它们构成了文件的标头\n",
        "        # The first 4 values are header information\n",
        "        # 1. Major version number\n",
        "        # 2. Minor Version Number\n",
        "        # 3. Subversion number\n",
        "        # 4. IMages seen\n",
        "        header = np.fromfile(fp, dtype=np.int32, count=5)\n",
        "        self.header = torch.from_numpy(header)\n",
        "        self.seen = self.header[3]        \n",
        "        \n",
        "        # The rest of the values are the weights\n",
        "        # Let's load them up\n",
        "        weights = np.fromfile(fp, dtype=np.float32)\n",
        "        \n",
        "        # 循环地加载权重文件到网络的模块上\n",
        "        ptr = 0\n",
        "        for i in range(len(self.module_list)):\n",
        "            module_type = self.blocks[i + 1][\"type\"]\n",
        "\n",
        "            if module_type == \"convolutional\":        \n",
        "                \n",
        "                model = self.module_list[i]\n",
        "                try:\n",
        "                    batch_normalize = int(self.blocks[i + 1][\"batch_normalize\"])  # blocks包括Net，module_list只包含网络层\n",
        "                except:\n",
        "                    batch_normalize = 0\n",
        "\n",
        "                conv = model[0]\n",
        "                \n",
        "                #如果 batch_normalize 检查结果是 True，则我们按以下方式加载权重\n",
        "                if (batch_normalize):\n",
        "                    bn = model[1]\n",
        "\n",
        "                    # Get the number of weights of Batch Norm Layer\n",
        "                    num_bn_biases = bn.bias.numel()\n",
        "\n",
        "                    # Load the weights\n",
        "                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n",
        "                    ptr += num_bn_biases\n",
        "\n",
        "                    # Cast the loaded weights into dims of model weights.\n",
        "                    bn_biases = bn_biases.view_as(bn.bias.data)\n",
        "                    bn_weights = bn_weights.view_as(bn.weight.data)\n",
        "                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
        "                    bn_running_var = bn_running_var.view_as(bn.running_var)\n",
        "\n",
        "                    # Copy the data to model\n",
        "                    bn.bias.data.copy_(bn_biases)\n",
        "                    bn.weight.data.copy_(bn_weights)\n",
        "                    bn.running_mean.copy_(bn_running_mean)\n",
        "                    bn.running_var.copy_(bn_running_var)     \n",
        "                    \n",
        "                #如果 batch_normalize 的检查结果不是 True，只需要加载卷积层的偏置项。\n",
        "                else:\n",
        "                    # Number of biases\n",
        "                    num_biases = conv.bias.numel()\n",
        "\n",
        "                    # Load the weights\n",
        "                    conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases])\n",
        "                    ptr = ptr + num_biases\n",
        "\n",
        "                    # reshape the loaded weights according to the dims of the model weights\n",
        "                    conv_biases = conv_biases.view_as(conv.bias.data)\n",
        "\n",
        "                    # Finally copy the data\n",
        "                    conv.bias.data.copy_(conv_biases)\n",
        "                    \n",
        "                # Let us load the weights for the Convolutional layers\n",
        "                num_weights = conv.weight.numel()\n",
        "\n",
        "                # Do the same as above for weights\n",
        "                conv_weights = torch.from_numpy(weights[ptr:ptr + num_weights])\n",
        "                ptr = ptr + num_weights\n",
        "\n",
        "                conv_weights = conv_weights.view_as(conv.weight.data)\n",
        "                conv.weight.data.copy_(conv_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOYbAE6MWOy9",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>**为什么要一个空的层？**</font>  \n",
        "<font face=楷体>\n",
        "*   如果像其它层一样，创建路由层需要构建一个 nn.Module 对象并初始化，然后在 forward 函数中拼接特征图，但拼接操作的代码相当简短（ torch.cat），像其它层一样设计route层将导致不必要的抽象，增加代码。可以用一个空的虚拟层代替路由层，然后 forward 函数中直接执行拼接操作  \n",
        "*   shortcut层是一个简单的add操作，也用一个空的虚拟层代替\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8x1JkOOUBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmptyLayer(nn.Module):\n",
        "     def __init__(self):\n",
        "            super(EmptyLayer, self).__init__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpgGOgn2hspz",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=red size=4> 定义DetectionLayer 保存用于检测边界框的锚点？</font>  \n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接：**</font>  \n",
        "【1】[nn.Module](https://blog.csdn.net/u012609509/article/details/81203436)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArUR8AMhaiZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DetectionLayer(nn.Module):\n",
        "    def __init__(self, anchors):\n",
        "        super(DetectionLayer, self).__init__()\n",
        "        self.anchors = anchors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9mhiasvw3Qx",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>\n",
        "将OpenCV读取图片的数据形式转换成Pytorch格式：  \n",
        "$\\color{pink}{RGB\\Longrightarrow BGR}\\ \\ \\ \\color{skyblue}{\\LARGE \\&}\\ \\color{pink}{\\mathrm 【height \\times width \\times channel】\\Longrightarrow 【channel \\times height \\times width】}$\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks30oz6jLdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_input():\n",
        "    img = cv2.imread(\"dog-cycle-car.png\")\n",
        "    img = cv2.resize(img, (416, 416))  # 调整图片尺寸\n",
        "    img_ = img[:, :, ::-1].transpose((2, 0, 1))\n",
        "    img_ = img_[np.newaxis, :, :, :] / 255.0  # Add a channel at 0 (for batch) | Normalise\n",
        "    img_ = torch.from_numpy(img_).float()  # Convert to float\n",
        "    img_ = Variable(img_)   # Convert to Variable\n",
        "    return img_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywbs55hJkfqm",
        "colab_type": "text"
      },
      "source": [
        "# util.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv5gWoIhygEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITl_JgY6ktoL",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "YOLO 的输出是一个卷积特征图，包含沿特征图深度的边界框属性，单元格预测的边界框彼此堆叠，如果需要查看第(5,6)单元格的第二个边框，  \n",
        "<font color=red size=4>需要通过 map[5,6, (5+C): 2*(5+C)] ??????????????????????</font>  \n",
        "将其编入索引。这种格式对于输出处理过程（例如通过目标置信度进行阈值处理、添加对中心的网格偏移、应用锚点等）很不方便。\n",
        "\n",
        "另一个问题是由于检测是在三个尺度上进行的，预测图的维度将是不同的。虽然三个特征图的维度不同，但对它们执行的输出处理过程是相似的。最好能在单个张量上执行这些运算而不是三个单独张量\n",
        "\n",
        "为了解决这些问题，引入函数 <font color=skyblue size=4>predict_transform.</font></font>\n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2018/04/bbox_-2.png#pic_center)\n",
        "\n",
        "\n",
        "<font face=楷体 color=skyblue size=4>**predict_transform 有 5 个参数：**</font>  \n",
        "\n",
        "<font face=楷体 color=pink>prediction（输出）、inp_dim（输入图像的维度）、anchors、num_classes、CUDA flag（可选）</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "prediction\n",
        "~~~\n",
        "line5 : stride = inp_dim // prediction.size(2) 输入图像维度不是多维的吗？\n",
        "line12: prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)\n",
        "line14: anchors = [(a[0] / stride, a[1] / stride) for a in anchors]\n",
        "line32: x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0) \n",
        "line34: prediction[:, :, :2] += x_y_offset\n",
        "line42： anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)\n",
        "line43: prediction[:, :, 2:4] = torch.exp(prediction[:, :, 2:4]) * anchors  \n",
        "line48: prediction[:, :, :4] *= stride\n",
        "\n",
        "~~~\n",
        "<font face=楷体>\n",
        "在特征图上进行多尺度预测, 在gridc其中x,y,w,h是在网络输入图片坐标系下的值,s是方框含有目标的置信度得分，s_cls1,s_cls_2等是方框所含目标对应每类的概率。输入的feature map(prediction变量) 维度为(batch_size, num_anchors*bbox_attrs, grid_size, grid_size)，类似于一个batch彩色图片$B\\times C\\times H\\times W$存储方式。  \n",
        "并且将结果的维度变换成(batch_size, grid_size*grid_size*num_anchors, 5+类别数量)的tensor，同时得到每个方框在网络输入图片(416x416)坐标系下的(x,y,w,h)以及方框含有目标的得分以及每个类的得分。\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrk0_w3Tklp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_transform(prediction, inp_dim, anchors, num_classes, CUDA=True):\n",
        "    \n",
        "    # 将上图代码化\n",
        "    batch_size = prediction.size(0)  # 参数0代表第一个维度，例如：prediction是二维的时候size(0)等于其行数\n",
        "    stride = inp_dim // prediction.size(2) \n",
        "    grid_size = inp_dim // stride\n",
        "    bbox_attrs = 5 + num_classes\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    prediction = prediction.view(batch_size, bbox_attrs * num_anchors, grid_size * grid_size)\n",
        "    prediction = prediction.transpose(1, 2).contiguous()\n",
        "    prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)  # 将所有anchor按行排列\n",
        "    \n",
        "    # anchors变换到相应feature map中的尺寸\n",
        "    anchors = [(a[0] / stride, a[1] / stride) for a in anchors]\n",
        "    \n",
        "    # Sigmoid the  centre_X, centre_Y. and object confidencce\n",
        "    prediction[:, :, 0] = torch.sigmoid(prediction[:, :, 0])\n",
        "    prediction[:, :, 1] = torch.sigmoid(prediction[:, :, 1])\n",
        "    prediction[:, :, 4] = torch.sigmoid(prediction[:, :, 4])\n",
        "    \n",
        "    # Add the center offsets\n",
        "    grid_len = np.arange(grid_size)\n",
        "    a, b = np.meshgrid(grid_len, grid_len)  # a,b均为grid_len*grid_len矩阵，互为转置关系\n",
        "\n",
        "    x_offset = torch.FloatTensor(a).view(-1, 1)\n",
        "    y_offset = torch.FloatTensor(b).view(-1, 1)\n",
        "\n",
        "    if CUDA:\n",
        "        x_offset = x_offset.cuda()\n",
        "        y_offset = y_offset.cuda()\n",
        "\n",
        "    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0) \n",
        "    \n",
        "    # bx=sigmoid(tx)+cx,by=sigmoid(ty)+cy\n",
        "    prediction[:, :, :2] += x_y_offset    \n",
        "    \n",
        "    # log space transform height and the width\n",
        "    anchors = torch.FloatTensor(anchors)\n",
        "\n",
        "    if CUDA:\n",
        "        anchors = anchors.cuda()\n",
        "        \n",
        "    anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)  # 将三个anchor复制到每个格子\n",
        "    # bw=p_w×exp(t_w)，bh=p_h×exp(t_h)\n",
        "    prediction[:, :, 2:4] = torch.exp(prediction[:, :, 2:4]) * anchors   \n",
        "    \n",
        "    # Softmax the class scores\n",
        "    prediction[:, :, 5: 5 + num_classes] = torch.sigmoid((prediction[:, :, 5: 5 + num_classes]))   # 计算anchor中每个类别的得分\n",
        "    \n",
        "    prediction[:, :, :4] *= stride  # 将相对于feature map的anchorbox尺寸映射回输入网络图片(416x416)尺度\n",
        "    \n",
        "    return prediction    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u5_qUscsN-5",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>输出满足 objectness 分数阈值和非极大值抑制（NMS），以得到后文所提到的「真实（true）」检测结果  \n",
        "创建一个名为 write_results 的函数  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>\n",
        "~~~\n",
        "line5: conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)\n",
        "line6: prediction = prediction * conf_mask   \n",
        "line32: max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)\n",
        "line34: max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)\n",
        "line35: max_conf = max_conf.float().unsqueeze(1)\n",
        "line37: seq = (image_pred[:, :5], max_conf, max_conf_score)   \n",
        "line38: image_pred = torch.cat(seq, 1)\n",
        "line44: image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)  # ????????????\n",
        "line47: img_classes = unique(image_pred_[:, -1])  \n",
        "line78: ious=bbox_iou(image_pred_class[i].unsqueeze(0),image_pred_class[i+1:])???????????????????????????????????????????????????????????? \n",
        "line93: iou_mask = (ious < nms_conf).float().unsqueeze(1)？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0iB2MnDr5-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_results(prediction, confidence, num_classes, nms=True, nms_conf=0.4):\n",
        "\n",
        "    # 预测张量包含有关 B x 10647 边界框的信息\n",
        "    # 对于有低于一个阈值的 objectness 分数的每个边界框，将其每个属性的值（表示该边界框的一整行）都设为零\n",
        "    # confidence: 输入预测shape=(1,10647, 85)——>conf_mask: shape=(1,10647) -----> 增加一维度之后 (1, 10647, 1)\n",
        "    conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)  \n",
        "    # 例如：torch.Size([3, 4, 5])____[:, :, 4]____>torch.Size([3, 4])____unsqueeze(2)___>torch.Size([3, 4, 1])\n",
        "    prediction = prediction * conf_mask   \n",
        "    \n",
        "    # 现在的边界框属性是由中心坐标以及边界框的高度和宽度决定\n",
        "    # 使用每个框的两个对角坐标能更轻松地计算两个框的 IoU\n",
        "    # 将框的 (中心 x, 中心 y, 宽, 高) 属性转换成 (左上角 x, 左上角 y, 右下角 x, 右下角 y)\n",
        "    box_a = prediction.new(prediction.shape)  # 构建一个具有相同类型的新张量作中间变量\n",
        "    \n",
        "    box_a[:, :, 0] = (prediction[:, :, 0] - prediction[:, :, 2] / 2)\n",
        "    box_a[:, :, 1] = (prediction[:, :, 1] - prediction[:, :, 3] / 2)\n",
        "    box_a[:, :, 2] = (prediction[:, :, 0] + prediction[:, :, 2] / 2)\n",
        "    box_a[:, :, 3] = (prediction[:, :, 1] + prediction[:, :, 3] / 2)\n",
        "    prediction[:, :, :4] = box_a[:, :, :4]\n",
        "    \n",
        "    # 每张图像中的「真实」检测结果的数量可能存在差异\n",
        "    # 比如，一个大小为 3 的 batch 中有 1、2、3 这 3 张图像，它们各自有 5、2、4 个「真实」检测结果\n",
        "    # 因此，一次只能完成一张图像的置信度阈值设置和 NMS，不能将所涉及的操作向量化，且必须在预测的第一个维度（包含一个 batch 中图像的索引）上循环\n",
        "    batch_size = prediction.size(0)\n",
        "    write = False\n",
        "    for ind in range(batch_size):\n",
        "        # select the image from the batch\n",
        "        image_pred = prediction[ind]\n",
        "        # confidence threshholding\n",
        "        # NMS    \n",
        "\n",
        "        # Get the class having maximum score, and the index of that class\n",
        "        # Get rid of num_classes softmax scores\n",
        "        # Add the class index and the class score of class having maximum score\n",
        "        # max_conf最大得分，max_conf_score索引\n",
        "        max_conf, max_conf_score = torch.max(image_pred[:, 5:5 + num_classes], 1)  # axis=1纵向比较，返回行索引\n",
        "        max_conf = max_conf.float().unsqueeze(1)\n",
        "        max_conf_score = max_conf_score.float().unsqueeze(1)\n",
        "        seq = (image_pred[:, :5], max_conf, max_conf_score)\n",
        "        # 将每个框的(x1,y1,x2,y2,s)与最高的类的分数s_cls(max_conf)和对应类的索引index_cls(max_conf_score)在列维度上合并(10647, 5+1+1=7) \n",
        "        image_pred = torch.cat(seq, 1)    \n",
        "        \n",
        "        # Get rid of the zero entries\n",
        "        non_zero_ind = (torch.nonzero(image_pred[:, 4]))  # 返回索引（2维tensor）\n",
        "\n",
        "        try:\n",
        "            image_pred_ = image_pred[non_zero_ind.squeeze(), :].view(-1, 7)  # 保留image_pred中非0目标得分行的所有元素，且image_pred第二维度不变\n",
        "        except:\n",
        "            continue  # 当没有检测到时目标时，直接进入下一次循环  \n",
        "            \n",
        "        # Get the various classes detected in the image\n",
        "        img_classes = unique(image_pred_[:, -1])  # 最后一列保存的是每个框里物体的类别   \n",
        "        \n",
        "        # WE will do NMS classwise\n",
        "        for cls in img_classes:\n",
        "        \n",
        "            # get the detections with one particular class\n",
        "            cls_mask = image_pred_ * (image_pred_[:, -1] == cls).float().unsqueeze(1)\n",
        "            class_mask_ind = torch.nonzero(cls_mask[:, -2]).squeeze()  # cls_mask[:,-2]是物体类别分数\n",
        "\n",
        "            image_pred_class = image_pred_[class_mask_ind].view(-1, 7)  # 保留image_pred中包含cls类别的所有结果，且image_pred第二维度不变\n",
        "            #下一步的nms做准备\n",
        "\n",
        "            # sort the detections such that the entry with the maximum objectness\n",
        "            # confidence is at the top\n",
        "            # torch.sort返回降序数组和索引两个Tensor\n",
        "            conf_sort_index = torch.sort(image_pred_class[:, 4], descending=True)[1]  # [1]表示返回索引\n",
        "            image_pred_class = image_pred_class[conf_sort_index]  # 排序后的索引对应出的bbox的坐标与分数\n",
        "            idx = image_pred_class.size(0)  \n",
        "            \n",
        "            # 执行 NMS\n",
        "                # For each detection\n",
        "            for i in range(idx):\n",
        "                # Get the IOUs of all boxes that come after the one we are looking at\n",
        "                # in the loop\n",
        "                try:\n",
        "                    # image_pred_class为（x，7）二维Tensor，image_pred_class[i]是一个长度为7的Tensor，unsqueeze(0)——>(1,7)变成二维\n",
        "                    ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i + 1:])  # 计算第i个方框和i+1到最终的所有方框的IOU\n",
        "                except ValueError:\n",
        "                    break\n",
        "                    '''\n",
        "                    在for i in range(idx):这个循环中，因为有一些框(在image_pred_class对应一行)会被去掉，image_pred_class行数会减少，\n",
        "                    这样在后面的循环中，idx序号会超出image_pred_class的行数的范围，出现ValueError错误。\n",
        "                    所以当抛出这个错误时，则跳出这个循环，因为此时已经没有更多可以去掉的方框了。\n",
        "                    '''\n",
        "                except IndexError:\n",
        "                    break\n",
        "\n",
        "                # Zero out all the detections that have IoU > treshhold\n",
        "                # 计算出需要保留的item（保留ious < nms_conf的框）\n",
        "                #ious < nms_conf得到的是torch.uint8类型，转换为float\n",
        "                #要与image_pred_class[i+1:]相乘，故将长度为7的tensor添加一个维度变成7x1\n",
        "                iou_mask = (ious < nms_conf).float().unsqueeze(1)\n",
        "                image_pred_class[i + 1:] *= iou_mask  # IOU大于阈值的框的预测值全部变成0.得出需要保留的框\n",
        "\n",
        "                # Remove the non-zero entries\n",
        "                non_zero_ind = torch.nonzero(image_pred_class[:, 4]).squeeze()  # 返回得分为非0的方框的索引\n",
        "                image_pred_class = image_pred_class[non_zero_ind].view(-1, 7)  # 得到得分非0框的预测值(x1, y1, x2, y2, s,  s_class,index_cls)\n",
        "                #当前类执行完nms后，下一次循环将对剩下的方框中得分第i+1高的方框进行NMS操作，直到最后一个方框循环完成为止、\n",
        "                    \n",
        "            # 将所得到的检测结果加入到输出张量中\n",
        "            # 创建一个image_pred_class类型相同的tensor，其行数等于cls这个类别NMS剩下的框的个数，即image_pred_class的行数，列数为1\n",
        "            batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)  #用类别代号填充\n",
        "            seq = batch_ind, image_pred_class\n",
        "            # 用write标签来表示张量是否初始化\n",
        "            # 在类别上迭代的循环结束时，将所得到的检测结果合并成输出\n",
        "            if not write:\n",
        "                output = torch.cat(seq, 1)\n",
        "                write = True\n",
        "            else:\n",
        "                out = torch.cat(seq, 1)\n",
        "                output = torch.cat((output, out))     \n",
        "                \n",
        "    try:\n",
        "        return output\n",
        "    except:\n",
        "        return 0               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJOaAfrtujlm",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>同一类别可能会有多个「真实」检测结果，用 unique 函数来去除重复的元素，获取任意给定图像中存在的类别</font>  \n",
        "\n",
        "疑问"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi5iCRlduhDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unique(tensor):\n",
        "    tensor_np = tensor.cpu().numpy()\n",
        "    unique_np = np.unique(tensor_np)  # np.unique去除数组中重复数字，并进行排序\n",
        "    unique_tensor = torch.from_numpy(unique_np)\n",
        "\n",
        "    tensor_res = tensor.new(unique_tensor.shape)\n",
        "    tensor_res.copy_(unique_tensor)\n",
        "    return tensor_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntmMbWb4QD3s",
        "colab_type": "text"
      },
      "source": [
        "**计算IOU**\n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "\n",
        "line19: inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape).cuda()) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape).cuda())\n",
        "b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1) #加1？？？？？、"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqt-jypvP3AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bbox_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Returns the IoU of two bounding boxes\n",
        "\n",
        "    \"\"\"\n",
        "    # Get the coordinates of bounding boxes\n",
        "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
        "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
        "\n",
        "    # get the corrdinates of the intersection rectangle\n",
        "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
        "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
        "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
        "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
        "\n",
        "    # Intersection area\n",
        "    if torch.cuda.is_available():\n",
        "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape).cuda()) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape).cuda())\n",
        "    else:\n",
        "        inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1, torch.zeros(inter_rect_x2.shape)) * torch.max(\n",
        "            inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape))\n",
        "\n",
        "    # Union Area\n",
        "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
        "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
        "\n",
        "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T-Dj2A3YoMw",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>将每个类的索引映射到它的名称字符串，并以字典的形式返回</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问</font>  \n",
        "返回字典？？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBDvlQStYiV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_classes(namesfile):\n",
        "    fp = open(namesfile, \"r\")\n",
        "    names = fp.read().split(\"\\n\")[:-1]\n",
        "    return names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_kvd3JCbwoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_input():\n",
        "    img = cv2.imread(\"img/dog-cycle-car.png\")\n",
        "    img = cv2.resize(img, (416, 416))\n",
        "    img_ = img[:, :, ::-1].transpose((2, 0, 1))\n",
        "    img_ = img_[np.newaxis, :, :, :] / 255.0\n",
        "    img_ = torch.from_numpy(img_).float()\n",
        "    img_ = Variable(img_)\n",
        "    return img_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMyv_0JKc7RU",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>OpenCV以numpy数组的形式加载图像，BGR作为颜色通道的顺序。PyTorch的图像输入格式为：<font color=pink>**【批量x通道x高x宽】通道顺序为RGB**</font>。  \n",
        "因此，用函数prep_image将numpy数组转换为PyTorch的输入格式</font>  \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问</font>  \n",
        "~~~\n",
        "line8: img = cv2.resize(img, (inp_dim, inp_dim))？？？？？？？？？？？？？？？？？？？？？？？？？\n",
        "line9: img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr2WGCivdyCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prep_image(img, inp_dim):\n",
        "    \"\"\"\n",
        "    Prepare image for inputting to the neural network. \n",
        "    \n",
        "    Returns a Variable \n",
        "    \"\"\"\n",
        "\n",
        "    img = (letterbox_image(img, (inp_dim, inp_dim)))\n",
        "    img = img[:,:,::-1].transpose((2,0,1)).copy()\n",
        "    img = torch.from_numpy(img).float().div(255.0).unsqueeze(0) # 1x3x416x416\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjO1R_Tvd2tN",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>函数letterbox_image调整图像的大小，保持长宽比一致，并用颜色填充未填充的区域(128,128,128)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y51mHzwac64O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def letterbox_image(img, inp_dim):\n",
        "    '''resize image with unchanged aspect ratio using padding'''\n",
        "    img_w, img_h = img.shape[1], img.shape[0]\n",
        "    w, h = inp_dim  # 目标尺寸\n",
        "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
        "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
        "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)  # 假设：inp_dim：416x416----> 768 x 576的图片缩放成416x312\n",
        "    # 创建画布\n",
        "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
        "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
        "    \n",
        "    return canvas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9LL9UqISMwe",
        "colab_type": "text"
      },
      "source": [
        "# detector.py  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zNC0-wyRB54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 \n",
        "#from util import *\n",
        "import argparse\n",
        "import os \n",
        "import os.path as osp\n",
        "#from darknet import Darknet\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEMMAuQ4SzWm",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>**检测文件需要传递命令行参数，用python的ArgParse模块来实现**</font>  \n",
        "<font face=楷体>\n",
        "如：python detect.py --images dog-cycle-car.png --det det\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NZpZolRSUXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def arg_parse():\n",
        "    \"\"\"\n",
        "    Parse arguements to the detect module\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description='YOLO v3 Detection Module')\n",
        "    \n",
        "    parser.add_argument(\"--images\", dest = 'images', help = \n",
        "                        \"Image / Directory containing images to perform detection upon\",\n",
        "                        default = \"imgs\", type = str)\n",
        "    parser.add_argument(\"--det\", dest = 'det', help = \n",
        "                        \"Image / Directory to store detections to\",\n",
        "                        default = \"det\", type = str)\n",
        "    parser.add_argument(\"--bs\", dest = \"bs\", help = \"Batch size\", default = 1)\n",
        "    parser.add_argument(\"--confidence\", dest = \"confidence\", help = \"Object Confidence to filter predictions\", default = 0.5)\n",
        "    parser.add_argument(\"--nms_thresh\", dest = \"nms_thresh\", help = \"NMS Threshhold\", default = 0.4)\n",
        "    parser.add_argument(\"--cfg\", dest = 'cfgfile', help = \n",
        "                        \"Config file\",\n",
        "                        default = \"cfg/yolov3.cfg\", type = str)\n",
        "    parser.add_argument(\"--weights\", dest = 'weightsfile', help = \n",
        "                        \"weightsfile\",\n",
        "                        default = \"yolov3.weights\", type = str)\n",
        "    parser.add_argument(\"--reso\", dest = 'reso', help = \n",
        "                        \"Input resolution of the network. Increase to increase accuracy. Decrease to increase speed\",\n",
        "                        default = \"416\", type = str)\n",
        "    \n",
        "    return parser.parse_args()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYG2CumsSUU6",
        "colab_type": "code",
        "outputId": "083695f4-0b43-4cc8-b479-adcc4903aeb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "args = arg_parse()\n",
        "images = args.images\n",
        "batch_size = int(args.bs)\n",
        "confidence = float(args.confidence)\n",
        "nms_thesh = float(args.nms_thresh)\n",
        "start = 0\n",
        "CUDA = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--images IMAGES] [--det DET] [--bs BS]\n",
            "                             [--confidence CONFIDENCE]\n",
            "                             [--nms_thresh NMS_THRESH] [--cfg CFGFILE]\n",
            "                             [--weights WEIGHTSFILE] [--reso RESO]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-1a290c87-d307-452f-ac75-5c0d3fb8750d.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSrwPpT-YAUx",
        "colab_type": "text"
      },
      "source": [
        "**加载the class file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKKwxW4WX01X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 80    #For COCO\n",
        "classes = load_classes(\"data/coco.names\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CPsrYTkY6pL",
        "colab_type": "text"
      },
      "source": [
        "**初始化网络并加载权重**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg97uOOaSUSU",
        "colab_type": "code",
        "outputId": "8e8a6d1f-ac0f-4b65-dbeb-902298254c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "#Set up the neural network\n",
        "print(\"Loading network.....\")\n",
        "model = Darknet(args.cfgfile)\n",
        "model.load_weights(args.weightsfile)\n",
        "print(\"Network successfully loaded\")\n",
        "\n",
        "model.net_info[\"height\"] = args.reso\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0 \n",
        "assert inp_dim > 32\n",
        "\n",
        "#If there's a GPU availible, put the model on GPU\n",
        "if CUDA:\n",
        "    model.cuda()\n",
        "\n",
        "#Set the model in evaluation mode\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network.....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-3382d68fd88c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading network.....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightsfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Network successfully loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X07VlBwZI4X",
        "colab_type": "text"
      },
      "source": [
        "**读取输入图像**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-E5JhMQSUPo",
        "colab_type": "code",
        "outputId": "dc130dbb-20c5-45ed-f332-1d5df10cda36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "read_dir = time.time()\n",
        "#Detection phase\n",
        "try:\n",
        "    imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
        "except NotADirectoryError:\n",
        "    imlist = []\n",
        "    imlist.append(osp.join(osp.realpath('.'), images))\n",
        "except FileNotFoundError:\n",
        "    print (\"No file or directory with the name {}\".format(images))\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-0db93eeaf3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Detection phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mNotADirectoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FirEvFSxb6LR",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>如果保存检测的目录(由det标志定义)，不存在则创建它</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud4WkPC1SUMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(args.det):\n",
        "    os.makedirs(args.det)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sEmSpYdcQHV",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>用OpenCV加载图像</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pyKkfzHSUJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_batch = time.time()\n",
        "loaded_ims = [cv2.imread(x) for x in imlist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol6dqwdJcmux",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>除转换后的图像，还保留了原始图像列表和im_dim_list，后者包含原始图像的维度</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "line7：im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DPa7l-qSUGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch Variables for images\n",
        "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))  # prep_image函数需要两个参数\n",
        "\n",
        "#List containing dimensions of original images\n",
        "#opencv读入的图片矩阵对应的是 HxWxC，im_dim_list：【W x H】\n",
        "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "\n",
        "if CUDA:\n",
        "    im_dim_list = im_dim_list.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3lSNMLexMy",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>创建批次（batches）</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "line6：:num_batches = len(imlist) // batch_size + leftover            \n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                       len(im_batches))]))  for i in range(num_batches)]   \n",
        "                       \n",
        "                       \n",
        "Variable(batch)将图片生成一个可导tensor，现在已经不再支持这种写法，Autograd automatically supports Tensors with requires_grad set to True。  \n",
        "prediction是一个batch所有图片通过yolov3模型得到的预测值，维度为1x10647x85，三个scale的图片每个scale的特征图大小为13x13,26x26,52x52,一个元素看作一个格子，每个格子有3个anchor，将一个anchor保存为一行，  \n",
        "所以prediction一共有(13x13+26x26+52x52)x3=10647行，一个anchor预测(x,y,w,h,s,s_cls1,s_cls2...s_cls_80)，一共有85个元素。所以prediction的维度为Bx10647x85，加为这里batch_size为1，所以prediction的维度为1x10647x85\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8etRYGmewB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "leftover = 0\n",
        "if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "\n",
        "if batch_size != 1:\n",
        "    num_batches = len(imlist) // batch_size + leftover   \n",
        "    # 最后一个batch如果用(i + 1)*batch_size索引可能会超过图片数量len(im_batches)，所以取两者最小\n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                       len(im_batches))]))  for i in range(num_batches)]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ0U_svSnKkv",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=yellow size=4>疑问</font>  \n",
        "line9: prediction = model(Variable(batch, volatile = True), CUDA)  \n",
        "line49: objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL0u1zAoi3Tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write = 0\n",
        "start_det_loop = time.time()\n",
        "for i, batch in enumerate(im_batches):\n",
        "    #load the image \n",
        "    start = time.time()\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "    with torch.no_grad():\n",
        "        # Variable(batch)将图片生成一个可导tensor，现在已经不再支持这种写法\n",
        "        # prediction是一个batch所有图片通过yolov3模型得到的预测值，维度为1x10647x85\n",
        "        # 三个scale的图片每个scale的特征图大小为13x13,26x26,52x52,一个元素看作一个格子，每个格子有3个anchor，将一个anchor保存为一行\n",
        "        # prediction共有(13x13+26x26+52x52)x3=10647行，一个anchor预测(x,y,w,h,s,s_cls1,s_cls2...s_cls_80)，一共有85个元素\n",
        "        # prediction的维度为Bx10647x85，这里batch_size为1，所以prediction的维度为1x10647x85\n",
        "        prediction = model(Variable(batch, volatile = True), CUDA)\n",
        "\n",
        "    # 经过NMS筛选，每个框属性为(ind,x1,y1,x2,y2,s,s_cls,index_cls) ind:batch序号，x1,y1左上角坐标，x2,y2右下角坐标\n",
        "    # s框是否有目标的得分，s_cls框中所含目标最可能类别的概率得分，index_cls类别代号，prediction维度3x8，则表示有3个框\n",
        "    prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "     # 如果write_results()返回一个batch的结果是int(0)，表没检测到目标，用continue跳过本次循环\n",
        "    if type(prediction) == int:\n",
        "\n",
        "        # 在imlist中遍历一个batch所有的图片对应的元素(存储位置和名字)，同时返回图片在该batch中的序号im_num\n",
        "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "            # 计算图片在imlist中所对应的序号,即在所有图片中的序号\n",
        "            im_id = i*batch_size + im_num\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        continue\n",
        "\n",
        "    # prediction[:,0]取出每个框在所在图片的序号（第i个batch中的图片序号）\n",
        "    # 加上i*batch_size，batch中的图片序号——>图片在imlist中的序号\n",
        "    prediction[:,0] += i * batch_size    #transform the atribute from index in batch to index in imlist \n",
        "\n",
        "    # 因为空的变量不能与tensor连接，用write标记是否是第一次得到输出结果\n",
        "    if not write:                      # If we have't initialised output\n",
        "        output = prediction  \n",
        "        write = 1\n",
        "    else:\n",
        "        # output将每个batch的输出结果在0维进行连接\n",
        "        output = torch.cat((output,prediction))\n",
        "\n",
        "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "        im_id = i * batch_size + im_num\n",
        "        # objs列表包含本批次图片中所有框检测到的目标的类别名称\n",
        "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "    if CUDA:\n",
        "        torch.cuda.synchronize()  # 保证gpu和cpu同步，否则 GPU 工作还未完成， CUDA 核就将控制返回给 CPU（异步调用）       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxNUy-G4jaiF",
        "colab_type": "text"
      },
      "source": [
        "**在图像上绘制边框**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crKUzXlZjZs7",
        "colab_type": "code",
        "outputId": "070e9744-cbd1-427a-fc1c-5a27d12554a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "    output\n",
        "except NameError:\n",
        "    print (\"No detections were made\")\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No detections were made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P9j9C2cj6_1",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>在绘制边界框之前，输出张量中包含的预测符合网络的输入大小，而不是图像的原始大小。因此，在绘制边界框之前，要将每个边界框的角属性转换为图像的原始维度  \n",
        "在绘制边界框之前，输出张量中包含的预测是对填充图像的预测，而不是对原始图像的预测。仅仅将它们重新缩放到输入图像的维数在这里是行不通的。首先，我们需要转换要测量的框的坐标相对于包含原始图像的填充图像上区域的边界。\n",
        "</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "lime15：output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExUgc2Gnj4er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# im_dim_list为4维tensor，一行的元素为(W,H,W,H)，与后面计算x1,y1,x2,y2各自对应的缩放系数时相对应\n",
        "# .index_select()即在im_dim_list中查找output中每行所对应框所在图片在所有图片中的序号所对应im_dim_list中的那行\n",
        "# im_dim_list的行数应该与output的行数相同\n",
        "im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())  # torch.index_select(data, dim, indices)\n",
        "\n",
        "# 将框的坐标转换为相对于填充后的图片中包含原始图片区域的计算方式。\n",
        "# min(416/im_dim_list, 1): 416除以im_dim_list中的每个元素，从得到的tensor的第1维(每行)找到最小元素，并返回（ torch.min 返回tuple， [0]：value；[1]：索引）\n",
        "# 这里没有设置keepdim=True，返回的的最小元素的tensor维度比原来减一\n",
        "# view(-1, 1)变成了【n x 1】维tensor，scaling_factor的每个元素就对应一张图片缩放成416的时候所采用的缩放系数（默认416）  \n",
        "scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)  \n",
        "\n",
        "# 将相对于输入网络图片(416x416)的方框属性变换成原图按照纵横比不变进行缩放后的区域的坐标。\n",
        "# scaling_factor*img_w和scaling_factor*img_h是图片按照纵横比不变进行缩放后的图片，即原图是768x576按照纵横比长边不变缩放到了416*372。\n",
        "# 经坐标换算,得到的坐标还是在输入网络的图片(416x416)坐标系下的绝对坐标，但是此时已经是相对于416*372这个区域的坐标了，而不再相对于(0,0)原点。\n",
        "output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2  # x1=x1−(416−scaling_factor*img_w)/2,x2=x2-(416−scaling_factor*img_w)/2\n",
        "output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2  # y1=y1-(416−scaling_factor*img_h)/2,y2=y2-(416−scaling_factor*img_h)/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu4IMf9okfDl",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "现在，坐标符合填充区域上图像的尺寸。然而，在函数letterbox_image中，通过缩放因子调整了图像的两个维度的大小(两个维度都用一个公共因子来划分，以保持长宽比)，现在要撤消这个，重新缩放，以获得原始图像上的边框的坐标\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTzTjKDkeHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 直接除以缩放系数，将框坐标(x1,y1,x2,y2)映射到原始图片上\n",
        "output[:,1:5] /= scaling_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR7SG247keR7",
        "colab_type": "text"
      },
      "source": [
        "Let us now clip any bounding boxes that may have boundaries outside the image to the edges of our image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZcvEtAhkdi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 如果映射回原始图片中的坐标超过了原始图片的区域，x1,x2小于0.0，令x1,x2为0.0，x1,x2大于原始图片宽度，令x1,x2大小为图片的宽度，y坐标同理\n",
        "# clamp()函数就是将第一个输入对数的值限定在后面两个数字的区间\n",
        "for i in range(output.shape[0]):\n",
        "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
        "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyrG0_tlP63",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>用不同的颜色画框</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArA6ATSlUp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_load = time.time()\n",
        "colors = pkl.load(open(\"pallete\", \"rb\"))  # pallete：100种颜色"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8N5Z_EHlifE",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "开始画框\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2_GrGllNoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "draw = time.time()\n",
        "\n",
        "# x为映射到原始图片中一个框的属性(ind,x1,y1,x2,y2,s,s_cls,index_cls)\n",
        "# results列表保存了所有测试图片，一个元素对应一张图片\n",
        "def write(x, results, color):\n",
        "    c1 = tuple(x[1:3].int())  # c1为方框左上角坐标x1,y1\n",
        "    c2 = tuple(x[3:5].int())  # c2为方框右下角坐标x2,y2\n",
        "    img = results[int(x[0])]  # 在results中找到框所对应的图片\n",
        "    cls = int(x[-1])\n",
        "    label = \"{0}\".format(classes[cls])\n",
        "    cv2.rectangle(img, c1, c2,color, 1)\n",
        "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4  # 得到目标名字的框，在右下角2x,y方向上分别加了3、4个像素\n",
        "    cv2.rectangle(img, c1, c2,color, -1)  # 在图片上画一个实心框\n",
        "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1)  # 在实心框显示标签，(c1[0], c1[1] + t_size[1] + 4)为字符串的左下角坐标\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17VPeFy7mBJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 开始绘制所有框包括目标名字\n",
        "# x是output中的一行，维度为1x8\n",
        "# loaded_ims列表保存了所有图片内容数组,一个元素对应一张图片\n",
        "# 原地修改loaded_ims 中图像\n",
        "list(map(lambda x: write(x, loaded_ims), output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_M64LCdmJh4",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>通过在图像名称前面加上前缀“det_”保存每个图像。我们创建一个地址列表，并将检测图像保存到其中</font>  \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>  \n",
        "\n",
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(args.det,x.split(\"/\")[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bHr484mCYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将带框的测试图片重命名\n",
        "# det_names 是series对象，类似于列表，pd.Series(imlist)返回一个series对象\n",
        "# 对于imlist这个列表(保存的是所有测试图片的绝对路径+名字，一个元素对应一张图片路径加名字)，生成的series对象包含两列，一列是每个imlist元素的索引，一列是 imlist 元素。\n",
        "# apply()函数将这个series对象传递给apply()里面的函数，以遍历的方式进行。apply()返回结果是经过 apply()里面的函数返回每张测试图片将要保存的文件路径，这里依然是一个series对象\n",
        "# x是Series()返回的对象中的一个元素，即一张图片的绝对路径加名字，args.det是将要保存图片的文件夹(默认det)，返回”det/det_图片名”,x.split(\"/\")[-1]中的 ”/” 是linux下文件路径分隔符\n",
        "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(args.det,x.split(\"/\")[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IhKhxz5mRwa",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "最后，用det_names将检测到的图像写入地址\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qRen6JRmNE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 保存标注框和目标类别的图片\n",
        "# det_names对应所有测试图片的保存路径，loaded_ims对应所有标注了框和目标名字的图片数组\n",
        "list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i_ifQCgmdZO",
        "colab_type": "text"
      },
      "source": [
        "**打印Time Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG4-OMO3mcyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"SUMMARY\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "print()\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhJpd_NHrl3a",
        "colab_type": "text"
      },
      "source": [
        "# 测试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "141yClAmRMlU",
        "colab_type": "text"
      },
      "source": [
        "<div id=\"测试一\">测试一</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHqJZq-L3Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir cfg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAOk32apZse",
        "colab_type": "code",
        "outputId": "32b6c604-7f42-459f-8a37-acae9e5004d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cd cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "blocks = parse_cfg(\"yolov3.cfg\")\n",
        "print(create_modules(blocks))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-02 02:47:05--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg.2’\n",
            "\n",
            "\ryolov3.cfg.2          0%[                    ]       0  --.-KB/s               \ryolov3.cfg.2        100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-02 02:47:05 (124 MB/s) - ‘yolov3.cfg.2’ saved [8342/8342]\n",
            "\n",
            "({'type': 'net', 'batch': '64', 'subdivisions': '16', 'width': '608', 'height': '608', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, ModuleList(\n",
            "  (0): Sequential(\n",
            "    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (2): Sequential(\n",
            "    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (3): Sequential(\n",
            "    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (4): Sequential(\n",
            "    (shortcut_4): EmptyLayer()\n",
            "  )\n",
            "  (5): Sequential(\n",
            "    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (6): Sequential(\n",
            "    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (7): Sequential(\n",
            "    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (8): Sequential(\n",
            "    (shortcut_8): EmptyLayer()\n",
            "  )\n",
            "  (9): Sequential(\n",
            "    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (10): Sequential(\n",
            "    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (11): Sequential(\n",
            "    (shortcut_11): EmptyLayer()\n",
            "  )\n",
            "  (12): Sequential(\n",
            "    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (13): Sequential(\n",
            "    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (14): Sequential(\n",
            "    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (15): Sequential(\n",
            "    (shortcut_15): EmptyLayer()\n",
            "  )\n",
            "  (16): Sequential(\n",
            "    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (17): Sequential(\n",
            "    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (18): Sequential(\n",
            "    (shortcut_18): EmptyLayer()\n",
            "  )\n",
            "  (19): Sequential(\n",
            "    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (20): Sequential(\n",
            "    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (21): Sequential(\n",
            "    (shortcut_21): EmptyLayer()\n",
            "  )\n",
            "  (22): Sequential(\n",
            "    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (23): Sequential(\n",
            "    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (24): Sequential(\n",
            "    (shortcut_24): EmptyLayer()\n",
            "  )\n",
            "  (25): Sequential(\n",
            "    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (26): Sequential(\n",
            "    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (27): Sequential(\n",
            "    (shortcut_27): EmptyLayer()\n",
            "  )\n",
            "  (28): Sequential(\n",
            "    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (29): Sequential(\n",
            "    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (30): Sequential(\n",
            "    (shortcut_30): EmptyLayer()\n",
            "  )\n",
            "  (31): Sequential(\n",
            "    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (32): Sequential(\n",
            "    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (33): Sequential(\n",
            "    (shortcut_33): EmptyLayer()\n",
            "  )\n",
            "  (34): Sequential(\n",
            "    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (35): Sequential(\n",
            "    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (36): Sequential(\n",
            "    (shortcut_36): EmptyLayer()\n",
            "  )\n",
            "  (37): Sequential(\n",
            "    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (38): Sequential(\n",
            "    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (39): Sequential(\n",
            "    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (40): Sequential(\n",
            "    (shortcut_40): EmptyLayer()\n",
            "  )\n",
            "  (41): Sequential(\n",
            "    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (42): Sequential(\n",
            "    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (43): Sequential(\n",
            "    (shortcut_43): EmptyLayer()\n",
            "  )\n",
            "  (44): Sequential(\n",
            "    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (45): Sequential(\n",
            "    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (46): Sequential(\n",
            "    (shortcut_46): EmptyLayer()\n",
            "  )\n",
            "  (47): Sequential(\n",
            "    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (48): Sequential(\n",
            "    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (49): Sequential(\n",
            "    (shortcut_49): EmptyLayer()\n",
            "  )\n",
            "  (50): Sequential(\n",
            "    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (51): Sequential(\n",
            "    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (52): Sequential(\n",
            "    (shortcut_52): EmptyLayer()\n",
            "  )\n",
            "  (53): Sequential(\n",
            "    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (54): Sequential(\n",
            "    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (55): Sequential(\n",
            "    (shortcut_55): EmptyLayer()\n",
            "  )\n",
            "  (56): Sequential(\n",
            "    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (57): Sequential(\n",
            "    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (58): Sequential(\n",
            "    (shortcut_58): EmptyLayer()\n",
            "  )\n",
            "  (59): Sequential(\n",
            "    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (60): Sequential(\n",
            "    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (61): Sequential(\n",
            "    (shortcut_61): EmptyLayer()\n",
            "  )\n",
            "  (62): Sequential(\n",
            "    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (63): Sequential(\n",
            "    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (64): Sequential(\n",
            "    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (65): Sequential(\n",
            "    (shortcut_65): EmptyLayer()\n",
            "  )\n",
            "  (66): Sequential(\n",
            "    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (67): Sequential(\n",
            "    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (68): Sequential(\n",
            "    (shortcut_68): EmptyLayer()\n",
            "  )\n",
            "  (69): Sequential(\n",
            "    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (70): Sequential(\n",
            "    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (71): Sequential(\n",
            "    (shortcut_71): EmptyLayer()\n",
            "  )\n",
            "  (72): Sequential(\n",
            "    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (73): Sequential(\n",
            "    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (74): Sequential(\n",
            "    (shortcut_74): EmptyLayer()\n",
            "  )\n",
            "  (75): Sequential(\n",
            "    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (76): Sequential(\n",
            "    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (77): Sequential(\n",
            "    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (78): Sequential(\n",
            "    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (79): Sequential(\n",
            "    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (80): Sequential(\n",
            "    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (81): Sequential(\n",
            "    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (82): Sequential(\n",
            "    (Detection_82): DetectionLayer()\n",
            "  )\n",
            "  (83): Sequential(\n",
            "    (route_83): EmptyLayer()\n",
            "  )\n",
            "  (84): Sequential(\n",
            "    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (85): Sequential(\n",
            "    (upsample_85): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (86): Sequential(\n",
            "    (route_86): EmptyLayer()\n",
            "  )\n",
            "  (87): Sequential(\n",
            "    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (88): Sequential(\n",
            "    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (89): Sequential(\n",
            "    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (90): Sequential(\n",
            "    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (91): Sequential(\n",
            "    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (92): Sequential(\n",
            "    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (93): Sequential(\n",
            "    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (94): Sequential(\n",
            "    (Detection_94): DetectionLayer()\n",
            "  )\n",
            "  (95): Sequential(\n",
            "    (route_95): EmptyLayer()\n",
            "  )\n",
            "  (96): Sequential(\n",
            "    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (97): Sequential(\n",
            "    (upsample_97): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (98): Sequential(\n",
            "    (route_98): EmptyLayer()\n",
            "  )\n",
            "  (99): Sequential(\n",
            "    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (100): Sequential(\n",
            "    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (101): Sequential(\n",
            "    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (102): Sequential(\n",
            "    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (103): Sequential(\n",
            "    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (104): Sequential(\n",
            "    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
            "  )\n",
            "  (105): Sequential(\n",
            "    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (106): Sequential(\n",
            "    (Detection_106): DetectionLayer()\n",
            "  )\n",
            "))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxUQC1SQmqwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv yolov3.cfg ./cfg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-uY09vjRf4e",
        "colab_type": "text"
      },
      "source": [
        "测试一"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgZiTiYiQ86V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!!cd ../\n",
        "#!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "model = Darknet(\"cfg/yolov3.cfg\")\n",
        "model.load_weights(\"yolov3.weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz9MddweJS55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data\n",
        "!cd data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ajaoj3olnVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Darknet(\"yolov3.cfg\")\n",
        "inp = get_test_input()\n",
        "pred = model(inp, torch.cuda.is_available())\n",
        "print (pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfkv-cBRQ-xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3zZciE2pgEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTiq-J8pluS7",
        "colab_type": "code",
        "outputId": "2f1adcbd-611a-4260-b4de-76a04cb7f704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "!wget wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-02 05:26:52--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2019-09-02 05:26:52--  https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png [following]\n",
            "--2019-09-02 05:26:53--  https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347445 (339K) [image/png]\n",
            "Saving to: ‘dog-cycle-car.png’\n",
            "\n",
            "dog-cycle-car.png   100%[===================>] 339.30K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-09-02 05:26:53 (8.24 MB/s) - ‘dog-cycle-car.png’ saved [347445/347445]\n",
            "\n",
            "FINISHED --2019-09-02 05:26:53--\n",
            "Total wall clock time: 0.6s\n",
            "Downloaded: 1 files, 339K in 0.04s (8.24 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-QvWpiLcLL1",
        "colab_type": "code",
        "outputId": "d7efaa06-44c9-43fe-d92d-736d5c99408d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "img = cv2.imread(\"dog-cycle-car.png\")\n",
        "img = cv2.resize(img, (4, 4))  # 调整图片尺寸\n",
        "print(img.shape)\n",
        "print(\"--------------------------------------------------\")\n",
        "img_ = img[:, :, ::-1]#.transpose((2, 0, 1))\n",
        "print(img_.shape)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(img)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(img_)\n",
        "print(\"--------------------------------------------------\")\n",
        "print(img_.transpose((2, 0, 1)))\n",
        "print(\"--------------------------------------------------\")\n",
        "#img_ = img_[np.newaxis, :, :, :] / 255.0  # Add a channel at 0 (for batch) | Normalise\n",
        "#img_ = torch.from_numpy(img_).float()  # Convert to floa\n",
        "#img_ = Variable(img_)   # Convert to Variable"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 4, 3)\n",
            "--------------------------------------------------\n",
            "(4, 4, 3)\n",
            "--------------------------------------------------\n",
            "[[[174 193 190]\n",
            "  [ 66 150 118]\n",
            "  [169 163 167]\n",
            "  [ 48 101  79]]\n",
            "\n",
            " [[168 180 178]\n",
            "  [171 184 184]\n",
            "  [156 162 159]\n",
            "  [200 182 182]]\n",
            "\n",
            " [[ 40 105 114]\n",
            "  [136 138 144]\n",
            "  [ 73 127 129]\n",
            "  [ 42 126 135]]\n",
            "\n",
            " [[175 164 157]\n",
            "  [156 152 151]\n",
            "  [182 169 167]\n",
            "  [142 153 156]]]\n",
            "--------------------------------------------------\n",
            "[[[190 193 174]\n",
            "  [118 150  66]\n",
            "  [167 163 169]\n",
            "  [ 79 101  48]]\n",
            "\n",
            " [[178 180 168]\n",
            "  [184 184 171]\n",
            "  [159 162 156]\n",
            "  [182 182 200]]\n",
            "\n",
            " [[114 105  40]\n",
            "  [144 138 136]\n",
            "  [129 127  73]\n",
            "  [135 126  42]]\n",
            "\n",
            " [[157 164 175]\n",
            "  [151 152 156]\n",
            "  [167 169 182]\n",
            "  [156 153 142]]]\n",
            "--------------------------------------------------\n",
            "[[[190 118 167  79]\n",
            "  [178 184 159 182]\n",
            "  [114 144 129 135]\n",
            "  [157 151 167 156]]\n",
            "\n",
            " [[193 150 163 101]\n",
            "  [180 184 162 182]\n",
            "  [105 138 127 126]\n",
            "  [164 152 169 153]]\n",
            "\n",
            " [[174  66 169  48]\n",
            "  [168 171 156 200]\n",
            "  [ 40 136  73  42]\n",
            "  [175 156 182 142]]]\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTKzHyGBe6d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S1yXdMimrG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Darknet(\"yolov3.cfg\")\n",
        "model.load_weights(\"yolov3.weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Sst-uirOVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv coco.names ./data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PUFUBDf_lXj",
        "colab_type": "text"
      },
      "source": [
        "测试二"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS5G5mEnppv3",
        "colab_type": "code",
        "outputId": "9d0ac8c8-1c08-4ef6-83b0-68f99c707c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!mkdir data\n",
        "!cd data\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-31 02:59:19--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "\rcoco.names            0%[                    ]       0  --.-KB/s               \rcoco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-31 02:59:19 (148 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BKjf-V_cGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TnxMDMYNPWJ",
        "colab_type": "code",
        "outputId": "d3565f97-9d2a-4240-903b-4f3a72790353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Set up the neural network\n",
        "print(\"Loading network.....\")\n",
        "model = Darknet(\"yolov3.cfg\")\n",
        "model.load_weights(\"yolov3.weights\")\n",
        "#model = Darknet(args.cfgfile)\n",
        "#model.load_weights(args.weightsfile)\n",
        "print(\"Network successfully loaded\")\n",
        "\n",
        "#model.net_info[\"height\"] = args.reso\n",
        "#inp_dim = int(model.net_info[\"height\"])\n",
        "model.net_info[\"height\"] = 416\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0 \n",
        "assert inp_dim > 32\n",
        "\n",
        "CUDA = 1\n",
        "\n",
        "#If there's a GPU availible, put the model on GPU\n",
        "if CUDA:\n",
        "    model.cuda()\n",
        "\n",
        "#Set the model in evaluation mode\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network.....\n",
            "Network successfully loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Darknet(\n",
              "  (module_list): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_0): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_1): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_2): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_3): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (shortcut_4): EmptyLayer()\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_5): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_6): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_7): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (shortcut_8): EmptyLayer()\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_9): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_10): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (shortcut_11): EmptyLayer()\n",
              "    )\n",
              "    (12): Sequential(\n",
              "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_12): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_13): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (14): Sequential(\n",
              "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_14): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (15): Sequential(\n",
              "      (shortcut_15): EmptyLayer()\n",
              "    )\n",
              "    (16): Sequential(\n",
              "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_16): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (17): Sequential(\n",
              "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_17): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (18): Sequential(\n",
              "      (shortcut_18): EmptyLayer()\n",
              "    )\n",
              "    (19): Sequential(\n",
              "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_19): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (20): Sequential(\n",
              "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_20): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (21): Sequential(\n",
              "      (shortcut_21): EmptyLayer()\n",
              "    )\n",
              "    (22): Sequential(\n",
              "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_22): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (23): Sequential(\n",
              "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_23): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (24): Sequential(\n",
              "      (shortcut_24): EmptyLayer()\n",
              "    )\n",
              "    (25): Sequential(\n",
              "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_25): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (26): Sequential(\n",
              "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_26): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (27): Sequential(\n",
              "      (shortcut_27): EmptyLayer()\n",
              "    )\n",
              "    (28): Sequential(\n",
              "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_28): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (29): Sequential(\n",
              "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_29): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (30): Sequential(\n",
              "      (shortcut_30): EmptyLayer()\n",
              "    )\n",
              "    (31): Sequential(\n",
              "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_31): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (32): Sequential(\n",
              "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_32): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (33): Sequential(\n",
              "      (shortcut_33): EmptyLayer()\n",
              "    )\n",
              "    (34): Sequential(\n",
              "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_34): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (35): Sequential(\n",
              "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_35): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (36): Sequential(\n",
              "      (shortcut_36): EmptyLayer()\n",
              "    )\n",
              "    (37): Sequential(\n",
              "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_37): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (38): Sequential(\n",
              "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_38): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (39): Sequential(\n",
              "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_39): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (40): Sequential(\n",
              "      (shortcut_40): EmptyLayer()\n",
              "    )\n",
              "    (41): Sequential(\n",
              "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_41): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (42): Sequential(\n",
              "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_42): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (43): Sequential(\n",
              "      (shortcut_43): EmptyLayer()\n",
              "    )\n",
              "    (44): Sequential(\n",
              "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_44): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (45): Sequential(\n",
              "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_45): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (46): Sequential(\n",
              "      (shortcut_46): EmptyLayer()\n",
              "    )\n",
              "    (47): Sequential(\n",
              "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_47): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (48): Sequential(\n",
              "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_48): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (49): Sequential(\n",
              "      (shortcut_49): EmptyLayer()\n",
              "    )\n",
              "    (50): Sequential(\n",
              "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_50): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (51): Sequential(\n",
              "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_51): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (52): Sequential(\n",
              "      (shortcut_52): EmptyLayer()\n",
              "    )\n",
              "    (53): Sequential(\n",
              "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_53): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (54): Sequential(\n",
              "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_54): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (55): Sequential(\n",
              "      (shortcut_55): EmptyLayer()\n",
              "    )\n",
              "    (56): Sequential(\n",
              "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_56): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (57): Sequential(\n",
              "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_57): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (58): Sequential(\n",
              "      (shortcut_58): EmptyLayer()\n",
              "    )\n",
              "    (59): Sequential(\n",
              "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_59): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (60): Sequential(\n",
              "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_60): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (61): Sequential(\n",
              "      (shortcut_61): EmptyLayer()\n",
              "    )\n",
              "    (62): Sequential(\n",
              "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_62): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (63): Sequential(\n",
              "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_63): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (64): Sequential(\n",
              "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_64): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (65): Sequential(\n",
              "      (shortcut_65): EmptyLayer()\n",
              "    )\n",
              "    (66): Sequential(\n",
              "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_66): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (67): Sequential(\n",
              "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_67): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (68): Sequential(\n",
              "      (shortcut_68): EmptyLayer()\n",
              "    )\n",
              "    (69): Sequential(\n",
              "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_69): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (70): Sequential(\n",
              "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_70): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (71): Sequential(\n",
              "      (shortcut_71): EmptyLayer()\n",
              "    )\n",
              "    (72): Sequential(\n",
              "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_72): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (73): Sequential(\n",
              "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_73): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (74): Sequential(\n",
              "      (shortcut_74): EmptyLayer()\n",
              "    )\n",
              "    (75): Sequential(\n",
              "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_75): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (76): Sequential(\n",
              "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_76): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (77): Sequential(\n",
              "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_77): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (78): Sequential(\n",
              "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_78): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (79): Sequential(\n",
              "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_79): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (80): Sequential(\n",
              "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_80): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (81): Sequential(\n",
              "      (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (82): Sequential(\n",
              "      (Detection_82): DetectionLayer()\n",
              "    )\n",
              "    (83): Sequential(\n",
              "      (route_83): EmptyLayer()\n",
              "    )\n",
              "    (84): Sequential(\n",
              "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_84): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (85): Sequential(\n",
              "      (upsample_85): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    )\n",
              "    (86): Sequential(\n",
              "      (route_86): EmptyLayer()\n",
              "    )\n",
              "    (87): Sequential(\n",
              "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_87): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (88): Sequential(\n",
              "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_88): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (89): Sequential(\n",
              "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_89): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (90): Sequential(\n",
              "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_90): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (91): Sequential(\n",
              "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_91): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (92): Sequential(\n",
              "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_92): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (93): Sequential(\n",
              "      (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (94): Sequential(\n",
              "      (Detection_94): DetectionLayer()\n",
              "    )\n",
              "    (95): Sequential(\n",
              "      (route_95): EmptyLayer()\n",
              "    )\n",
              "    (96): Sequential(\n",
              "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_96): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (97): Sequential(\n",
              "      (upsample_97): Upsample(scale_factor=2.0, mode=nearest)\n",
              "    )\n",
              "    (98): Sequential(\n",
              "      (route_98): EmptyLayer()\n",
              "    )\n",
              "    (99): Sequential(\n",
              "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_99): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (100): Sequential(\n",
              "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_100): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (101): Sequential(\n",
              "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_101): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (102): Sequential(\n",
              "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_102): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (103): Sequential(\n",
              "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_103): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (104): Sequential(\n",
              "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (leaky_104): LeakyReLU(negative_slope=0.1, inplace)\n",
              "    )\n",
              "    (105): Sequential(\n",
              "      (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (106): Sequential(\n",
              "      (Detection_106): DetectionLayer()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUVsp47sNaKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images\n",
        "!cp dog-cycle-car.png ./images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uELppiXQdZqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "read_dir = time.time()\n",
        "#Detection phase\n",
        "try:\n",
        "    imlist = [osp.join(osp.realpath('.'), \"images\", img) for img in os.listdir(\"images\")]\n",
        "except NotADirectoryError:\n",
        "    imlist = []\n",
        "    imlist.append(osp.join(osp.realpath('.'), images))\n",
        "except FileNotFoundError:\n",
        "    print (\"No file or directory with the name {}\".format(images))\n",
        "    exit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-YHQWKdzD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs(\"det\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LmQdHsOeGlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size  = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VIWOyy3cX98",
        "colab_type": "code",
        "outputId": "a31139f9-efca-4e21-d643-99dbaeb16187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "a = Variable(batch, volatile = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH9CNEIXdMy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write = 0\n",
        "start_det_loop = time.time()\n",
        "for i, batch in enumerate(im_batches):\n",
        "    #load the image \n",
        "    start = time.time()\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "\n",
        "    prediction = model(a, CUDA)\n",
        "\n",
        "    prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    if type(prediction) == int:\n",
        "\n",
        "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "            im_id = i*batch_size + im_num\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        continue\n",
        "\n",
        "    prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
        "\n",
        "    if not write:                      #If we have't initialised output\n",
        "        output = prediction  \n",
        "        write = 1\n",
        "    else:\n",
        "        output = torch.cat((output,prediction))\n",
        "\n",
        "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "        im_id = i*batch_size + im_num\n",
        "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "    if CUDA:\n",
        "        torch.cuda.synchronize()     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IRZKm2CgMGI",
        "colab_type": "code",
        "outputId": "1ccdd976-d99f-400d-aec0-083e72485117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "!python detector.py --images dog-cycle-car.png --det det"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network.....\n",
            "Network successfully loaded\n",
            "dog-cycle-car.png    predicted in  0.185 seconds\n",
            "Objects Detected:    bicycle truck dog\n",
            "----------------------------------------------------------\n",
            "SUMMARY\n",
            "----------------------------------------------------------\n",
            "Task                     : Time Taken (in seconds)\n",
            "\n",
            "Reading addresses        : 0.000\n",
            "Loading batch            : 0.054\n",
            "Detection (1 images)     : 0.198\n",
            "Output Processing        : 0.000\n",
            "Drawing Boxes            : 0.027\n",
            "Average time_per_img     : 0.279\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmlCP4mU311g",
        "colab_type": "text"
      },
      "source": [
        "$$\\begin{matrix}\n",
        "&t_x = (x - x_a) /w_a,&t_y = (y - y_a) / h_a\\\\[1ex]&t_w = log(w/ w_a),&t_h = log(h/h_a)\\\\[1ex]t_x^* &= (x^* - x_a) / w_a,\\  t_y^* = (y^* - y_a) /h_a\\\\[1ex]t_w^* &= log(w^* - w),\\ \\  h_h^* = log(h^*/h_a)\n",
        "\\end{matrix}$$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Yv4N97hn2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}