{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch教程.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/master/PyTorch%E6%95%99%E7%A8%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWmhnjgpOx2I",
        "colab_type": "text"
      },
      "source": [
        "# Tensor基本操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjR1BmmWO_Id",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UId1VNTAxauk",
        "colab_type": "code",
        "outputId": "80205a06-935f-4c32-9fe6-9e95f022ea21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.Tensor(5, 3)  # 构造一个未初始化的5*3的矩阵\n",
        "print(x)\n",
        "x = torch.rand(5, 3)  # 构造一个随机初始化的矩阵\n",
        "print(x)\n",
        "x.size() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.7755e-36, 0.0000e+00, 3.7835e-44],\n",
            "        [0.0000e+00,        nan, 1.6255e-43],\n",
            "        [1.3733e-14, 6.4069e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [3.8016e-39, 4.3724e-05, 0.0000e+00]])\n",
            "tensor([[0.9202, 0.4282, 0.0826],\n",
            "        [0.3717, 0.1017, 0.7316],\n",
            "        [0.7124, 0.3054, 0.2333],\n",
            "        [0.7186, 0.9089, 0.0880],\n",
            "        [0.0184, 0.2866, 0.6191]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVBb1UPcxfYi",
        "colab_type": "code",
        "outputId": "36ccfef0-1ba8-411c-9234-3b29c3f6ac3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.Size 事实上是一个tuple, 所以其支持相关的操作*\n",
        "y = torch.rand(5, 3)\n",
        "x + y # 语法一\n",
        "torch.add(x, y) # 语法二"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9815, 1.2067, 1.3755],\n",
              "        [0.6702, 0.5304, 0.9676],\n",
              "        [0.7938, 0.7058, 0.8588],\n",
              "        [1.5058, 0.9331, 1.7468],\n",
              "        [1.4405, 0.6854, 0.6840]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBemHXdTyZgi",
        "colab_type": "code",
        "outputId": "8df2bae8-0226-43df-96f5-172114ab569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# 另外输出tensor也有两种写法\n",
        "result = torch.Tensor(5, 3)\n",
        "torch.add(x, y, out=result) \n",
        "y.add_(x) # 特别注明：任何可以改变tensor内容的操作都会在方法名后加一个下划线'_'，例如：x.copy_(y), x.t_(), 这俩都会改变x的值"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9815, 1.2067, 1.3755],\n",
              "        [0.6702, 0.5304, 0.9676],\n",
              "        [0.7938, 0.7058, 0.8588],\n",
              "        [1.5058, 0.9331, 1.7468],\n",
              "        [1.4405, 0.6854, 0.6840]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXUw5uOHysOR",
        "colab_type": "code",
        "outputId": "ace4ddd3-151e-4211-a52f-01e89ee7c155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 此处演示tensor和numpy数据结构的相互转换\n",
        "a = torch.ones(5)\n",
        "b = a.numpy()\n",
        "# 此处演示当修改numpy数组之后,与之相关联的tensor也会相应的被修改\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtBIC8RZ0EOJ",
        "colab_type": "code",
        "outputId": "bbf25441-faed-4d05-bcd1-97f17f60a391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 将numpy的Array转换为torch的Tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6xXGLum0JjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 另外除了CharTensor之外，所有的tensor都可以在CPU运算和GPU预算之间相互转换\n",
        "# 使用CUDA函数来将Tensor移动到GPU上\n",
        "# 当CUDA可用时会进行GPU的运算\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp1gdTns2fhY",
        "colab_type": "text"
      },
      "source": [
        "autograd.Variable 这是这个包中最核心的类。 它包装了一个Tensor，并且几乎支持所有的定义在其上的操作。一旦完成了你的运算，你可以调用 .backward()来自动计算出所有的梯度。\n",
        "可以通过属性 .data 来访问原始的tensor，而关于这一Variable的梯度则集中于 .grad 属性中。\n",
        "![替代文字](https://pic4.zhimg.com/80/v2-08e0530dfd6879ff2bee56cfc5cc5073_hd.jpg)\n",
        "\n",
        "在自动求导中非常重要的类 Function\n",
        "Variable 和 Function 二者相互联系并且构建了一个描述整个运算过程的无环图。每个Variable拥有一个 .creator 属性，其引用了一个创建Variable的 Function。(除了用户创建的Variable其 creator 部分是 None)。\n",
        "\n",
        "如果你想要进行求导计算，你可以在Variable上调用.backward()。 如果Variable是一个标量（例如它包含一个单元素数据），你无需对backward()指定任何参数，然而如果它有更多的元素，你需要指定一个和tensor的形状想匹配的grad_output参数\n",
        "\n",
        "更多关于Variable 和 Function的文档:https://link.zhihu.com/?target=http%3A//pytorch.org/docs/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkkies3H0VsZ",
        "colab_type": "code",
        "outputId": "1dfd667a-3d65-4f58-c801-1182674ebe8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "x = Variable(torch.ones(2, 2), requires_grad = True)\n",
        "y = x + 2\n",
        "#y.creator  # 错误\n",
        "y.grad  \n",
        "# y 是作为一个操作的结果创建的因此y有一个creator ?????????????????\n",
        "z = y * y * 3\n",
        "out = z.mean() \n",
        "# 现在我们来使用反向传播\n",
        "out.backward()\n",
        "\n",
        "# out.backward()和操作out.backward(torch.Tensor([1.0]))是等价的\n",
        "# 在此处输出 d(out)/dx\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.5000, 4.5000],\n",
              "        [4.5000, 4.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZeYJc268o4",
        "colab_type": "code",
        "outputId": "10dfa26f-e9ba-48b0-9fc4-35030d3ec309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3)\n",
        "x = Variable(x, requires_grad = True)  # 用上一个随机初始化的tensor初始化变量x?????????????????????????\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])  \n",
        "y.backward(gradients)\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TTxatfK9LcL",
        "colab_type": "text"
      },
      "source": [
        "# Part-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-6g4vaqBWo4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg5GgexZ9FUA",
        "colab_type": "code",
        "outputId": "0b934b91-94a7-479f-a6e3-7b7a158b6404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch \n",
        "\n",
        "a = torch.randn((3,3), requires_grad = True)\n",
        "\n",
        "w1 = torch.randn((3,3), requires_grad = True)\n",
        "w2 = torch.randn((3,3), requires_grad = True)\n",
        "w3 = torch.randn((3,3), requires_grad = True)\n",
        "w4 = torch.randn((3,3), requires_grad = True)\n",
        "\n",
        "b = w1*a \n",
        "c = w2*a\n",
        "\n",
        "d = w3*b + w4*c \n",
        "\n",
        "L = 10 - d\n",
        "\n",
        "print(\"The grad fn for a is\", a.grad_fn)\n",
        "print(\"The grad fn for d is\", d.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The grad fn for a is None\n",
            "The grad fn for d is <AddBackward0 object at 0x7fce077bc6a0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6OwT47XBg-v",
        "colab_type": "text"
      },
      "source": [
        "<font face=STCAIYUN color=red size=4>注意：</font>当必须冻结某些图层并在训练时阻止他们更新参数时，可以简单地将requires_grad设置为False，这些Tensors不会参与计算图。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKDwg-fkCZWW",
        "colab_type": "text"
      },
      "source": [
        "当执行inference code时，并不计算梯度，因此不需要存储这些值。事实上，在推理过程中不需要创建任何图形，因为它将导致无用的内存消耗  \n",
        "PyTorch提供了环境管理器：torch.no_grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJavr9vK9FRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad:\n",
        "\tinference code goes here "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th-F_M_sDlt9",
        "colab_type": "text"
      },
      "source": [
        "# Part-2  \n",
        "<font face=STCAIYUN color=skyblue size=4>**主要内容**</font>\n",
        "\n",
        "<font face=STCAIYUN color=skyblue size=4>**1. </font>  <font face=楷体>  如何使用nn.Module类构建神经网络  \n",
        "<font face=STCAIYUN color=skyblue size=4>**2.</font>   如何使用Dataset和Dataloader类使用数据扩充来构建自定义数据输入管道。  \n",
        "<font face=STCAIYUN color=skyblue size=4>**3.  </font> 如何使用不同的学习率计划配置您的学习率  \n",
        "<font face=STCAIYUN color=skyblue size=4>**4. </font> 训练Resnet基础图像分类器来对来自CIFAR-10数据集的图像进行分类。</font>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1msmpQyuDtCR",
        "colab_type": "text"
      },
      "source": [
        "## 构造简单的神经网络  \n",
        "![网络图](https://blog.paperspace.com/content/images/2019/06/network.png   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmg7qTOmFjiB",
        "colab_type": "text"
      },
      "source": [
        "### 预热\n",
        "<font face=楷体 color=skyblue  size=4>torch.nn  模块</font><font face=楷体 >是PyTorch设计神经网络的基石，通过实例化torch.nn.Module对象来实现诸如完全连接层、卷积层、池化层、激活函数及整个神经网络的层</font>  \n",
        "<font face=楷体 color=skyblue  size=4>nn.Module类需要重写（override）两个方法：</font>\n",
        "\n",
        "\n",
        "*   <font face=楷体>__init__方法：创建nn.Module实例时自动调用该方法，在该方法下定义网络层的各种参数，例如：filters，卷积内核尺寸，dropout层的dropout probability等\n",
        "*  forward方法：定义输出的计算方式。不需要显式调用，通过调用nn.Module实例（input作参数）就可以自动调用并运行该方法</font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjbcUOtv9FOy",
        "colab_type": "code",
        "outputId": "bb1e6dac-e08c-4b20-cbd4-89b2e7f81cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import torchvision\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "class MyLayer(nn.Module):\n",
        "    def __init__(self, param):\n",
        "        super().__init__()\n",
        "        self.param = param \n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x * self.param\n",
        "\n",
        "myLayerObject = MyLayer(5)\n",
        "output = myLayerObject(torch.Tensor([5, 4, 3]) )    # 非显式调用forward方法 \n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([25., 20., 15.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qbid2JwqPT4",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>nn.Sequential类：</font><font face=楷体>可以按特定顺序传递对象列表，并按顺序返回nn.Module对象</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaagmCn49FMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinedNetwork = nn.Sequential(MyLayer(5), MyLayer(10))\n",
        "\n",
        "output = combinedNetwork([3,4])\n",
        "\n",
        "#equivalent to..\n",
        "# out = MyLayer(5)([3,4])\n",
        "# out = MyLayer(10)(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_gD27dGq3eB",
        "colab_type": "text"
      },
      "source": [
        "### 开始构建网络    \n",
        "<font face=楷体 color=skyblue  size=4>搭建残差模块（ResNet Block）</font>\n",
        "![替代文字](https://blog.paperspace.com/content/images/2019/06/resblk.png)\n",
        "<font face=楷体 color=yellow  size=4>疑问：</font>  \n",
        "~~~\n",
        "line23: self.shortcut = nn.Sequential() \n",
        "line28: kernel_size=(1, 1)  #1x1的卷积核？？\n",
        "line34: out = nn.ReLU()(self.bn1(self.conv1(x))) # 直接输入参数？？\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF-qTTBP9FJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        # Conv Layer 1\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels, out_channels=out_channels,\n",
        "            kernel_size=(3, 3), stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        # Conv Layer 2\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=out_channels, out_channels=out_channels,\n",
        "            kernel_size=(3, 3), stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    \n",
        "        # Shortcut connection to downsample residual\n",
        "        # In case the output dimensions of the residual block is not the same \n",
        "        # as it's input, have a convolutional layer downsample the layer \n",
        "        # being bought forward by approporate striding and filters\n",
        "        self.shortcut = nn.Sequential()  # 对应上图左边情况，直接连接\n",
        "        if stride != 1 or in_channels != out_channels:  # 对应上图右边stride不等于1或input和output不一样时，需要对x降采样后连接\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels, out_channels=out_channels,\n",
        "                    kernel_size=(1, 1), stride=stride, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = nn.ReLU()(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olj2tczOv4qR",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>搭建残差网络（ResNet）</font>  \n",
        "<font face=楷体 color=yellow  size=4>疑问</font>  \n",
        "~~~\n",
        "line35: out = out.view(out.size(0), -1)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_9C4cFW9FF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        \n",
        "        # Initial input conv\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=(3, 3),\n",
        "            stride=1, padding=1, bias=False\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        # Create blocks\n",
        "        self.block1 = self._create_block(64, 64, stride=1)\n",
        "        self.block2 = self._create_block(64, 128, stride=2)\n",
        "        self.block3 = self._create_block(128, 256, stride=2)\n",
        "        self.block4 = self._create_block(256, 512, stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "    \n",
        "    # A block is just two residual blocks for ResNet18\n",
        "    def _create_block(self, in_channels, out_channels, stride):\n",
        "        return nn.Sequential(\n",
        "            ResidualBlock(in_channels, out_channels, stride),\n",
        "            ResidualBlock(out_channels, out_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\t# Output of one layer becomes input to the next\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.block4(out)\n",
        "        out = nn.AvgPool2d(4)(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH2wrgnRv-6o",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>输入格式：</font><font face=楷体 >图像的输入格式是[B C H W]  \n",
        "B批量大小、C通道、H高度、W宽度</font>  \n",
        "<font face=楷体 color=skyblue  size=4>加载数据：</font><font face=楷体 >这里用到torch.utils.data.Dataset和torch.utils.data.Dataloader  \n",
        "    将CIFAR-10数据集下载到当前目录"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1TsNo_TukFK",
        "colab_type": "code",
        "outputId": "391ff2b2-2f61-4a35-e7b5-da1686e77729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "!wget http://pjreddie.com/media/files/cifar.tgz\n",
        "!tar xzf cifar.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2019-08-12 05:40:16--  https://pjreddie.com/media/files/cifar.tgz\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168584360 (161M) [application/octet-stream]\n",
            "Saving to: ‘cifar.tgz.1’\n",
            "\n",
            "cifar.tgz.1         100%[===================>] 160.77M  64.7MB/s    in 2.5s    \n",
            "\n",
            "2019-08-12 05:40:19 (64.7 MB/s) - ‘cifar.tgz.1’ saved [168584360/168584360]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaZnxqM-1zFK",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>读取CIFAR数据集中存在的类的标签</font>  \n",
        "<font face=楷体 color=yellow  size=4>疑问</font>  \n",
        "~~~\n",
        "line5: label_mapping = dict(zip(labels, list(range(len(labels)))))\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvjHQUUukC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"cifar/train/\"\n",
        "\n",
        "with open(\"cifar/labels.txt\") as label_file:\n",
        "    labels = label_file.read().split()\n",
        "    label_mapping = dict(zip(labels, list(range(len(labels)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7OmnIqZ2n-Q",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>用PIL读取图像：</font>\n",
        "\n",
        "\n",
        "*   <font face=楷体>随机水平翻转图片的概率为0.5\n",
        "*   使用CIFAR数据集的均值和标准差来标准化图像\n",
        "*   图片格式变换：$W\\times H\\times C\\Longrightarrow C\\times H\\times W$</font>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UysrgabukAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(image):\n",
        "    image = np.array(image)\n",
        "    \n",
        "    if random.random() > 0.5:\n",
        "        image = image[::-1,:,:]\n",
        "    \n",
        "    cifar_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1,1,-1)\n",
        "    cifar_std  = np.array([0.2023, 0.1994, 0.2010]).reshape(1,1,-1)\n",
        "    image = (image - cifar_mean) / cifar_std\n",
        "    \n",
        "    image = image.transpose(2,1,0)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkrqtu9j4Tdy",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>加载数据：</font>  \n",
        "<font face=楷体>torch.utils.data.dataset：是一个加载数据并返回生成器的类，允许将数据增强融合到input Pipeline中</font>    \n",
        "<font face=楷体 color=skyblue>dataset为数据创建对象，需要重载三个方法：  </font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>\n",
        "    <font face=楷体 color=skyblue>__init __方法：</font> \n",
        "    定义与数据集相关的内容：数据位置，各种数据扩充等\n",
        "*  <font face=楷体 color=skyblue> __len __方法：</font>\n",
        "    返回数据的长度\n",
        "*   <font face=楷体 color=skyblue>__getitem __方法：</font>\n",
        "    将索引作为对象的参数，通过给定索引获取数据和标签（对象[索引]）\n",
        "</font>    \n",
        "\n",
        "<font face=楷体 color=yellow  size=4>疑问：</font>    \n",
        "  __getitem __方法  \n",
        "  transforms 数据扩充\n",
        "  ~~~\n",
        "  line32：image = image.astype(np.float32)\n",
        "  ~~~\n",
        "  <font face=楷体 color=green  size=4>**绿色链接：** </font>  \n",
        "   <font face=楷体>\n",
        "  [【1】PyTorch源码解读之torchvision.transforms](https://blog.csdn.net/u014380165/article/details/79167753)\n",
        "     </font>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebfdwmiuj9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cifar10Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, data_size = 0, transforms = None):\n",
        "        files = os.listdir(data_dir)\n",
        "        files = [os.path.join(data_dir,x) for x in files]\n",
        "        \n",
        "        \n",
        "        if data_size < 0 or data_size > len(files):\n",
        "            assert(\"Data size should be between 0 to number of files in the dataset\")\n",
        "        \n",
        "        if data_size == 0:\n",
        "            data_size = len(files)\n",
        "        \n",
        "        self.data_size = data_size\n",
        "        self.files = random.sample(files, self.data_size)  # 打乱顺序\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_address = self.files[idx]\n",
        "        image = Image.open(image_address)\n",
        "        image = preprocess(image)\n",
        "        label_name = image_address[:-4].split(\"_\")[-1]\n",
        "        label = label_mapping[label_name]\n",
        "        \n",
        "        image = image.astype(np.float32)\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgMOCRTtaJ2M",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>torch.utils.data.Dataloader：</font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>批处理数据\n",
        "*   混排（Shuffling）数据\n",
        "*   多线程一次加载多个数据\n",
        "*   预读，即当GPU处理当前批数据时，Dataloader可以同时将下一批数据加载到内存中。这意味着GPU不必等待，加快训练速度</font>\n",
        "\n",
        "\n",
        "<font face=楷体 color=green  size=4>**绿色链接：**</font>    \n",
        "\n",
        "[【1】PyTorch源码解读之torch.utils.data.DataLoader](https://blog.csdn.net/u014380165/article/details/79058479)  、\n",
        "\n",
        "[【2】SOURCE CODE FOR TORCH.UTILS.DATA.DATALOADER](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8gkivYCuj7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = Cifar10Dataset(data_dir = \"cifar/train/\", transforms=None)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)  # num_workers：线程数"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uujxT58yuj4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data in trainloader:   # or trainset\n",
        "\timg, label = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-vZWVdWEM9R",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=yellow>\n",
        "DataLoader第一个参数（Dataset）和其本身都是可迭代对象 \n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv95B2owuj1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     #Check whether a GPU is present.\n",
        "\n",
        "clf = ResNet()\n",
        "clf.to(device)   #Put the network on GPU if present\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(clf.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "717phvy5ujzE",
        "colab_type": "code",
        "outputId": "d566cb0d-84cf-4efc-b336-9d75e54a7a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(10):\n",
        "    losses = []\n",
        "    scheduler.step()\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()                 # Zero the gradients\n",
        "\n",
        "        outputs = clf(inputs)                 # Forward pass\n",
        "        loss = criterion(outputs, targets)    # Compute the Loss\n",
        "        loss.backward()                       # Compute the Gradients\n",
        "\n",
        "        optimizer.step()                      # Updated the weights\n",
        "        losses.append(loss.item())\n",
        "        end = time.time()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Batch Index : %d Loss : %.3f Time : %.3f seconds ' % (batch_idx, np.mean(losses), end - start))\n",
        "            \n",
        "            start = time.time()\n",
        "    # Evaluate\n",
        "    clf.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            outputs = clf(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
        "        print('--------------------------------------------------------------')\n",
        "    clf.train()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Index : 0 Loss : 2.325 Time : 0.400 seconds \n",
            "Batch Index : 100 Loss : 1.992 Time : 16.010 seconds \n",
            "Batch Index : 200 Loss : 1.850 Time : 16.440 seconds \n",
            "Batch Index : 300 Loss : 1.757 Time : 16.861 seconds \n",
            "Epoch : 0 Test Acc : 43.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 1.497 Time : 0.321 seconds \n",
            "Batch Index : 100 Loss : 1.345 Time : 17.924 seconds \n",
            "Batch Index : 200 Loss : 1.300 Time : 17.434 seconds \n",
            "Batch Index : 300 Loss : 1.250 Time : 17.201 seconds \n",
            "Epoch : 1 Test Acc : 52.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.927 Time : 0.317 seconds \n",
            "Batch Index : 100 Loss : 1.021 Time : 17.442 seconds \n",
            "Batch Index : 200 Loss : 1.001 Time : 17.560 seconds \n",
            "Batch Index : 300 Loss : 0.981 Time : 17.530 seconds \n",
            "Epoch : 2 Test Acc : 63.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.858 Time : 0.312 seconds \n",
            "Batch Index : 100 Loss : 0.850 Time : 17.382 seconds \n",
            "Batch Index : 200 Loss : 0.845 Time : 17.340 seconds \n",
            "Batch Index : 300 Loss : 0.839 Time : 17.372 seconds \n",
            "Epoch : 3 Test Acc : 60.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.722 Time : 0.313 seconds \n",
            "Batch Index : 100 Loss : 0.757 Time : 17.457 seconds \n",
            "Batch Index : 200 Loss : 0.757 Time : 17.440 seconds \n",
            "Batch Index : 300 Loss : 0.757 Time : 17.478 seconds \n",
            "Epoch : 4 Test Acc : 62.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.727 Time : 0.314 seconds \n",
            "Batch Index : 100 Loss : 0.685 Time : 17.504 seconds \n",
            "Batch Index : 200 Loss : 0.701 Time : 17.410 seconds \n",
            "Batch Index : 300 Loss : 0.696 Time : 17.371 seconds \n",
            "Epoch : 5 Test Acc : 70.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.631 Time : 0.320 seconds \n",
            "Batch Index : 100 Loss : 0.647 Time : 17.365 seconds \n",
            "Batch Index : 200 Loss : 0.645 Time : 17.308 seconds \n",
            "Batch Index : 300 Loss : 0.647 Time : 17.318 seconds \n",
            "Epoch : 6 Test Acc : 65.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.538 Time : 0.324 seconds \n",
            "Batch Index : 100 Loss : 0.578 Time : 17.388 seconds \n",
            "Batch Index : 200 Loss : 0.589 Time : 17.383 seconds \n",
            "Batch Index : 300 Loss : 0.594 Time : 17.370 seconds \n",
            "Epoch : 7 Test Acc : 75.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.609 Time : 0.315 seconds \n",
            "Batch Index : 100 Loss : 0.551 Time : 17.375 seconds \n",
            "Batch Index : 200 Loss : 0.562 Time : 17.418 seconds \n",
            "Batch Index : 300 Loss : 0.564 Time : 17.435 seconds \n",
            "Epoch : 8 Test Acc : 70.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.448 Time : 0.316 seconds \n",
            "Batch Index : 100 Loss : 0.508 Time : 17.456 seconds \n",
            "Batch Index : 200 Loss : 0.531 Time : 17.378 seconds \n",
            "Batch Index : 300 Loss : 0.527 Time : 17.361 seconds \n",
            "Epoch : 9 Test Acc : 70.000\n",
            "--------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1fKalLKujwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62-y7VwZ9E34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJEsD8xP8-Pf",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# 搭建神经网络\n",
        "用 torch.nn 包搭建神经网络  \n",
        "\n",
        "nn建立在autograd的基础上来进行模型的定义和微分  \n",
        "**一个典型的神经网络的训练过程：**\n",
        "\n",
        "1、定义一个有着可学习的参数（或者权重）的神经网络  \n",
        "2、对着一个输入的数据集进行迭代:  \n",
        "3、用神经网络对输入进行处理  \n",
        "4、计算代价值 (对输出值的修正到底有多少)  \n",
        "5、将梯度传播回神经网络的参数中  \n",
        "6、更新网络中的权重  \n",
        "$\\qquad$通常使用简单的更新规则: weight = weight + learning_rate * gradient  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWlOM8vHesGM",
        "colab_type": "text"
      },
      "source": [
        "##定义一个神经网络\n",
        "定义一个<font color=geen>**forward函数**</font>，backward会自动地生成， 可以在forward函数中使用所有的Tensor中的操作，模型中可学习的参数会由<font color=geen>**net.parameters()**</font>返回。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9niX6Fg8G8O",
        "colab_type": "code",
        "outputId": "74c6dccb-acce-4632-db8a-07f908d51281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)  # If the size is a square you can only specify a single number\n",
        "        x = x.view(-1, self.num_flat_features(x))  # ？？？？？？？？？？？？？？？？？\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:] # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "net = Net()\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mxXftBneZbM",
        "colab_type": "text"
      },
      "source": [
        "## 输入\n",
        "**注意：** torch.nn包只接受小批量样本，而非单个样本。     \n",
        "例如：nn.Conv2d能够接受四维的$TensornSamples \\times nChannels \\times Height \\times Width$批量样本，\n",
        "如果非要用单个样本，使用input.unsqueeze(0)来加一个假维度就可以了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWa0e8119QGg",
        "colab_type": "code",
        "outputId": "9f98e66a-9a32-4c3e-d641-74fc196e031b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size()) # conv1's .weight\n",
        "\n",
        "input = Variable(torch.randn(1, 1, 32, 32))\n",
        "out = net(input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsfG_ZpFfKEc",
        "colab_type": "text"
      },
      "source": [
        "## 反向传播"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfWibyTE-PLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad() # 对所有的参数的梯度缓冲区进行归零\n",
        "out.backward(torch.randn(1, 10)) # 使用随机的梯度进行反向传播"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt2nK9ylc_Ic",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3QpTC9XfUjZ",
        "colab_type": "text"
      },
      "source": [
        "##计算loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKmnx-NXfT3Y",
        "colab_type": "code",
        "outputId": "bd950846-eca9-4c84-d82b-a26840310791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "output = net(input)\n",
        "target = Variable(torch.range(1, 10))  # a dummy target, for example\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(output, target)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:443: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(38.5381, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0TPXLgRrdfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss.grad_fn) # creator貌似被grad_fn代替了\n",
        "print(loss.grad_fn.previous_functions[0][0]) # Linear\n",
        "print(loss.grad_fn.previous_functions[0][0].previous_functions[0][0]) # ReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOAPopdDKPtK",
        "colab_type": "text"
      },
      "source": [
        "调用loss.backward()，看看 conv1's在进行反馈之后的偏置梯度如何"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W22B8W0rE5x1",
        "colab_type": "code",
        "outputId": "19923a7c-be9f-4548-afa3-a5135f895e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# 调用loss.backward(), 看看 conv1's在进行反馈之后的偏置梯度如何\n",
        "net.zero_grad() # 归零操作\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "loss.backward()\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0193, -0.0114,  0.0311,  0.0051, -0.0441, -0.0320])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8pYaRWLBkO",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## 更新权重\n",
        "\n",
        "最简单的就是**随机梯度下降法(SGD)：**\n",
        "  ~~~\n",
        "weight = weight - learning_rate * gradient\n",
        "  ~~~\n",
        "**简单的python实现：**\n",
        "  ~~~\n",
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)\n",
        "~~~\n",
        "还有许多不同种类的方法：**SGD, Nesterov-SGD, Adam, RMSProp, etc**，这些方法都可以用**torch.optim包**来实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8thatqJiNxQB",
        "colab_type": "text"
      },
      "source": [
        "1、创建 optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll0qrHJrE6F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "# 创建 optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgdMhhxpOA_z",
        "colab_type": "text"
      },
      "source": [
        "2、使用 optimizer 实现梯度下降"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IsE13MpreNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.zero_grad()  # 缓存区梯度归零\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()  # 开始更新"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aj8xak5E7oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NDVYUoGE73B",
        "colab_type": "code",
        "outputId": "9ac68ee8-047f-4817-da9c-b2f721398a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAsxHDkTWZlo",
        "colab_type": "code",
        "outputId": "c12de9a0-10d3-4e90-fcea-340999b529a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "\n",
        "# show some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s'%classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bird   dog  deer   dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCPwL3cPDw2OLwL/QPTw8PLYI/j96MM58Czj+WwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xts_GClE8FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"docstring for Net\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,6,5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(6,16,5)\n",
        "        self.fc1 = nn.Linear(16*5*5,120)\n",
        "        self.fc2 = nn.Linear(120,84)        \n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1,16*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gu9QooXE8Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#声明使用交叉熵函数作为代价函数\n",
        "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
        "#声明使用学习率0.001的SGD优化器\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0\n",
        "    for i,data in enumerate(trainloader,0):\n",
        "        inputs,labels = data\n",
        "        inputs,labels = Variable(inputs).cuda(),Variable(labels).cuda()\n",
        "        #获得数据并将其放在GPU上\n",
        "        optimizer.zero_grad()\n",
        "        #初始化梯度\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        #前馈\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #反馈计算梯度并更新权值\n",
        "\n",
        "        running_loss += loss.data[0]\n",
        "        if i % 200 == 0:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0\n",
        "            #打印平均代价函数值\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayEP51z2E8vP",
        "colab_type": "code",
        "outputId": "42e85fea-3770-4976-99f8-8930f25fb4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "corret,total = 0,0\n",
        "for images,labels in testloader:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    outputs = net(Variable(images))\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    corret += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * corret / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 10 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vi1N3ewXFCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P592TDzLXFRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg2uTAC7XFfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CyfQBbOXFsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqpMivTAXF47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH_iEmUv-vVe",
        "colab_type": "code",
        "outputId": "3abd89ec-40fa-49fd-b768-29a6af569b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x = torch.tensor([[1.,2.,3.],[4.,5.,6.]],requires_grad=True)\n",
        "y = x+1\n",
        "print(y)\n",
        "z = 2*y*y\n",
        "print(z)\n",
        "J = torch.mean(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 3., 4.],\n",
            "        [5., 6., 7.]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 8., 18., 32.],\n",
            "        [50., 72., 98.]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWzVAmTrFRp",
        "colab_type": "code",
        "outputId": "c0798b7e-cce7-46de-cd35-706456c12e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "z.backward(torch.tensor([[1.,1.,1.],[1.,1.,1.]]))\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8., 12., 16.],\n",
              "        [20., 24., 28.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOYQcyJSztyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_LFpW52rpTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "J.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4jhtAa_r3fo",
        "colab_type": "code",
        "outputId": "8671c4f0-6593-42f8-c337-969495cc5835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8., 12., 16.],\n",
              "        [20., 24., 28.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heydkof3r-_C",
        "colab_type": "code",
        "outputId": "7e7fae98-b6b1-4824-a77f-fcc184399159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = torch.ones(2,4,requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixbpeQVfvAsw",
        "colab_type": "code",
        "outputId": "5ef6d082-45d8-4a79-d0d9-5c74ab1c5392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywut47stvE-3",
        "colab_type": "code",
        "outputId": "fa885921-98fc-4538-9a02-0d1fbbd13d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hb0_o-EvHAn",
        "colab_type": "code",
        "outputId": "bb27cd07-527c-4c97-87e2-e07da09758dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x.requires_grad_(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTrZgJIYvI63",
        "colab_type": "code",
        "outputId": "3442b784-9237-4cb4-f386-001c45f7c678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.requires_grad,y.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAKr86xgvYmL",
        "colab_type": "code",
        "outputId": "447cbb39-6b4c-4195-82f9-e71a56871431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "x = torch.rand(5)\n",
        "print(x)\n",
        "x = Variable(x,requires_grad = True)\n",
        "y = x * 2\n",
        "print(y)\n",
        "grads = torch.FloatTensor([1,1,1,1,1])\n",
        "y.backward(grads)#如果y是scalar的话，那么直接y.backward()，然后通过x.grad方式，就可以得到var的梯度\n",
        "x.grad           #如果y不是scalar，那么只能通过传参的方式给x指定梯度"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3219, 0.7271, 0.3582, 0.1854, 0.4333])\n",
            "tensor([0.6437, 1.4541, 0.7165, 0.3709, 0.8666], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eo4D-aa5Zps",
        "colab_type": "code",
        "outputId": "5f0e6a39-b03b-4f55-9c1c-656969513398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(2,1,7,3)\n",
        "conv = torch.nn.Conv2d(1,8,(2,3))\n",
        "res = conv(x)\n",
        "\n",
        "print(res.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q6bZfRu-JV1",
        "colab_type": "code",
        "outputId": "92a80e9b-684e-4d23-f7b3-0c958a0da06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.6527, -1.2410, -1.1945],\n",
              "          [-0.0185, -2.1766,  0.6402],\n",
              "          [-0.7816, -1.0634, -0.2349],\n",
              "          [ 0.2766,  0.1649, -0.1483],\n",
              "          [-1.8347, -1.0713, -0.4455],\n",
              "          [ 0.8888,  1.0780, -0.9985],\n",
              "          [ 0.2306, -1.0541,  0.2395]]],\n",
              "\n",
              "\n",
              "        [[[-0.0297, -0.6147,  0.8194],\n",
              "          [-0.0355,  0.5811, -1.1233],\n",
              "          [-0.2102,  0.5853, -0.1647],\n",
              "          [ 1.0932, -0.9402, -1.8629],\n",
              "          [-0.6348,  1.0294, -0.7822],\n",
              "          [-0.2458, -0.6021, -0.5502],\n",
              "          [ 0.6221,  1.1570, -0.1598]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0n4zp2-KAh",
        "colab_type": "code",
        "outputId": "04f4de25-1b19-4790-fea6-33110ffc85a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = torch.Tensor([-1])\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNTzfubWBgMc",
        "colab_type": "code",
        "outputId": "cd4f2e52-7152-48f0-9081-aa339ef09a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.FloatTensor(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mipyIMbOWNsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}