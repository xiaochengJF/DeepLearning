{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch教程.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "qWmhnjgpOx2I",
        "3TTxatfK9LcL",
        "th-F_M_sDlt9",
        "2-iJJYkJDebi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/master/PyTorch%E6%95%99%E7%A8%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWmhnjgpOx2I",
        "colab_type": "text"
      },
      "source": [
        "# Tensor基本操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjR1BmmWO_Id",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UId1VNTAxauk",
        "colab_type": "code",
        "outputId": "80205a06-935f-4c32-9fe6-9e95f022ea21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.Tensor(5, 3)  # 构造一个未初始化的5*3的矩阵\n",
        "print(x)\n",
        "x = torch.rand(5, 3)  # 构造一个随机初始化的矩阵\n",
        "print(x)\n",
        "x.size() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.7755e-36, 0.0000e+00, 3.7835e-44],\n",
            "        [0.0000e+00,        nan, 1.6255e-43],\n",
            "        [1.3733e-14, 6.4069e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [3.8016e-39, 4.3724e-05, 0.0000e+00]])\n",
            "tensor([[0.9202, 0.4282, 0.0826],\n",
            "        [0.3717, 0.1017, 0.7316],\n",
            "        [0.7124, 0.3054, 0.2333],\n",
            "        [0.7186, 0.9089, 0.0880],\n",
            "        [0.0184, 0.2866, 0.6191]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVBb1UPcxfYi",
        "colab_type": "code",
        "outputId": "36ccfef0-1ba8-411c-9234-3b29c3f6ac3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# torch.Size 事实上是一个tuple, 所以其支持相关的操作*\n",
        "y = torch.rand(5, 3)\n",
        "x + y # 语法一\n",
        "torch.add(x, y) # 语法二"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9815, 1.2067, 1.3755],\n",
              "        [0.6702, 0.5304, 0.9676],\n",
              "        [0.7938, 0.7058, 0.8588],\n",
              "        [1.5058, 0.9331, 1.7468],\n",
              "        [1.4405, 0.6854, 0.6840]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBemHXdTyZgi",
        "colab_type": "code",
        "outputId": "8df2bae8-0226-43df-96f5-172114ab569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# 另外输出tensor也有两种写法\n",
        "result = torch.Tensor(5, 3)\n",
        "torch.add(x, y, out=result) \n",
        "y.add_(x) # 特别注明：任何可以改变tensor内容的操作都会在方法名后加一个下划线'_'，例如：x.copy_(y), x.t_(), 这俩都会改变x的值"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9815, 1.2067, 1.3755],\n",
              "        [0.6702, 0.5304, 0.9676],\n",
              "        [0.7938, 0.7058, 0.8588],\n",
              "        [1.5058, 0.9331, 1.7468],\n",
              "        [1.4405, 0.6854, 0.6840]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXUw5uOHysOR",
        "colab_type": "code",
        "outputId": "ace4ddd3-151e-4211-a52f-01e89ee7c155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 此处演示tensor和numpy数据结构的相互转换\n",
        "a = torch.ones(5)\n",
        "b = a.numpy()\n",
        "# 此处演示当修改numpy数组之后,与之相关联的tensor也会相应的被修改\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtBIC8RZ0EOJ",
        "colab_type": "code",
        "outputId": "bbf25441-faed-4d05-bcd1-97f17f60a391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 将numpy的Array转换为torch的Tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6xXGLum0JjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 另外除了CharTensor之外，所有的tensor都可以在CPU运算和GPU预算之间相互转换\n",
        "# 使用CUDA函数来将Tensor移动到GPU上\n",
        "# 当CUDA可用时会进行GPU的运算\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    x + y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp1gdTns2fhY",
        "colab_type": "text"
      },
      "source": [
        "autograd.Variable 这是这个包中最核心的类。 它包装了一个Tensor，并且几乎支持所有的定义在其上的操作。一旦完成了你的运算，你可以调用 .backward()来自动计算出所有的梯度。\n",
        "可以通过属性 .data 来访问原始的tensor，而关于这一Variable的梯度则集中于 .grad 属性中。\n",
        "![替代文字](https://pic4.zhimg.com/80/v2-08e0530dfd6879ff2bee56cfc5cc5073_hd.jpg)\n",
        "\n",
        "在自动求导中非常重要的类 Function\n",
        "Variable 和 Function 二者相互联系并且构建了一个描述整个运算过程的无环图。每个Variable拥有一个 .creator 属性，其引用了一个创建Variable的 Function。(除了用户创建的Variable其 creator 部分是 None)。\n",
        "\n",
        "如果你想要进行求导计算，你可以在Variable上调用.backward()。 如果Variable是一个标量（例如它包含一个单元素数据），你无需对backward()指定任何参数，然而如果它有更多的元素，你需要指定一个和tensor的形状想匹配的grad_output参数\n",
        "\n",
        "更多关于Variable 和 Function的文档:https://link.zhihu.com/?target=http%3A//pytorch.org/docs/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkkies3H0VsZ",
        "colab_type": "code",
        "outputId": "1dfd667a-3d65-4f58-c801-1182674ebe8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "x = Variable(torch.ones(2, 2), requires_grad = True)\n",
        "y = x + 2\n",
        "#y.creator  # 错误\n",
        "y.grad  \n",
        "# y 是作为一个操作的结果创建的因此y有一个creator ?????????????????\n",
        "z = y * y * 3\n",
        "out = z.mean() \n",
        "# 现在我们来使用反向传播\n",
        "out.backward()\n",
        "\n",
        "# out.backward()和操作out.backward(torch.Tensor([1.0]))是等价的\n",
        "# 在此处输出 d(out)/dx\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.5000, 4.5000],\n",
              "        [4.5000, 4.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZeYJc268o4",
        "colab_type": "code",
        "outputId": "10dfa26f-e9ba-48b0-9fc4-35030d3ec309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3)\n",
        "x = Variable(x, requires_grad = True)  # 用上一个随机初始化的tensor初始化变量x?????????????????????????\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])  \n",
        "y.backward(gradients)\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TTxatfK9LcL",
        "colab_type": "text"
      },
      "source": [
        "# Part-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-6g4vaqBWo4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg5GgexZ9FUA",
        "colab_type": "code",
        "outputId": "0b934b91-94a7-479f-a6e3-7b7a158b6404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch \n",
        "\n",
        "a = torch.randn((3,3), requires_grad = True)\n",
        "\n",
        "w1 = torch.randn((3,3), requires_grad = True)\n",
        "w2 = torch.randn((3,3), requires_grad = True)\n",
        "w3 = torch.randn((3,3), requires_grad = True)\n",
        "w4 = torch.randn((3,3), requires_grad = True)\n",
        "\n",
        "b = w1*a \n",
        "c = w2*a\n",
        "\n",
        "d = w3*b + w4*c \n",
        "\n",
        "L = 10 - d\n",
        "\n",
        "print(\"The grad fn for a is\", a.grad_fn)\n",
        "print(\"The grad fn for d is\", d.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The grad fn for a is None\n",
            "The grad fn for d is <AddBackward0 object at 0x7fce077bc6a0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6OwT47XBg-v",
        "colab_type": "text"
      },
      "source": [
        "<font face=STCAIYUN color=red size=4>注意：</font>当必须冻结某些图层并在训练时阻止他们更新参数时，可以简单地将requires_grad设置为False，这些Tensors不会参与计算图。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKDwg-fkCZWW",
        "colab_type": "text"
      },
      "source": [
        "当执行inference code时，并不计算梯度，因此不需要存储这些值。事实上，在推理过程中不需要创建任何图形，因为它将导致无用的内存消耗  \n",
        "PyTorch提供了环境管理器：torch.no_grad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJavr9vK9FRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad:\n",
        "\tinference code goes here "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th-F_M_sDlt9",
        "colab_type": "text"
      },
      "source": [
        "# Part-2  构建一个神经网络\n",
        "<font face=STCAIYUN color=skyblue size=4>**主要内容**</font>\n",
        "\n",
        "<font face=STCAIYUN color=skyblue size=4>**1. </font>  <font face=楷体>  如何使用nn.Module类构建神经网络  \n",
        "<font face=STCAIYUN color=skyblue size=4>**2.</font>   如何使用Dataset和Dataloader类使用数据扩充来构建自定义数据输入管道。  \n",
        "<font face=STCAIYUN color=skyblue size=4>**3.  </font> 如何使用不同的学习率计划配置您的学习率  \n",
        "<font face=STCAIYUN color=skyblue size=4>**4. </font> 训练Resnet基础图像分类器来对来自CIFAR-10数据集的图像进行分类。</font>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1msmpQyuDtCR",
        "colab_type": "text"
      },
      "source": [
        "## 构造简单的神经网络  \n",
        "![网络图](https://blog.paperspace.com/content/images/2019/06/network.png   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmg7qTOmFjiB",
        "colab_type": "text"
      },
      "source": [
        "### 预热\n",
        "<font face=楷体 color=skyblue  size=4>torch.nn  模块</font><font face=楷体 >是PyTorch设计神经网络的基石，通过实例化torch.nn.Module对象来实现诸如完全连接层、卷积层、池化层、激活函数及整个神经网络的层</font>  \n",
        "<font face=楷体 color=skyblue  size=4>nn.Module类需要重写（override）两个方法：</font>\n",
        "\n",
        "\n",
        "*   <font face=楷体>__init__方法：创建nn.Module实例时自动调用该方法，在该方法下定义网络层的各种参数，例如：filters，卷积内核尺寸，dropout层的dropout probability等\n",
        "*  forward方法：定义输出的计算方式。不需要显式调用，通过调用nn.Module实例（input作参数）就可以自动调用并运行该方法</font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjbcUOtv9FOy",
        "colab_type": "code",
        "outputId": "bb1e6dac-e08c-4b20-cbd4-89b2e7f81cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import torchvision\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "class MyLayer(nn.Module):\n",
        "    def __init__(self, param):\n",
        "        super().__init__()\n",
        "        self.param = param \n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x * self.param\n",
        "\n",
        "myLayerObject = MyLayer(5)\n",
        "output = myLayerObject(torch.Tensor([5, 4, 3]) )    # 非显式调用forward方法 \n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([25., 20., 15.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qbid2JwqPT4",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>nn.Sequential类：</font><font face=楷体>可以按特定顺序传递对象列表，并按顺序返回nn.Module对象</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaagmCn49FMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinedNetwork = nn.Sequential(MyLayer(5), MyLayer(10))\n",
        "\n",
        "output = combinedNetwork([3,4])\n",
        "\n",
        "#equivalent to..\n",
        "# out = MyLayer(5)([3,4])\n",
        "# out = MyLayer(10)(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_gD27dGq3eB",
        "colab_type": "text"
      },
      "source": [
        "### 开始构建网络    \n",
        "<font face=楷体 color=skyblue  size=4>搭建残差模块（ResNet Block）</font>\n",
        "![替代文字](https://blog.paperspace.com/content/images/2019/06/resblk.png)\n",
        "<font face=楷体 color=yellow  size=4>疑问：</font>  \n",
        "~~~\n",
        "line23: self.shortcut = nn.Sequential() \n",
        "line28: kernel_size=(1, 1)  #1x1的卷积核？？\n",
        "line34: out = nn.ReLU()(self.bn1(self.conv1(x))) # 直接输入参数？？\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF-qTTBP9FJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        # Conv Layer 1\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels, out_channels=out_channels,\n",
        "            kernel_size=(3, 3), stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        # Conv Layer 2\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=out_channels, out_channels=out_channels,\n",
        "            kernel_size=(3, 3), stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    \n",
        "        # Shortcut connection to downsample residual\n",
        "        # In case the output dimensions of the residual block is not the same \n",
        "        # as it's input, have a convolutional layer downsample the layer \n",
        "        # being bought forward by approporate striding and filters\n",
        "        self.shortcut = nn.Sequential()  # 对应上图左边情况，直接连接\n",
        "        if stride != 1 or in_channels != out_channels:  # 对应上图右边stride不等于1或input和output不一样时，需要对x降采样后连接\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_channels=in_channels, out_channels=out_channels,\n",
        "                    kernel_size=(1, 1), stride=stride, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = nn.ReLU()(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olj2tczOv4qR",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>搭建残差网络（ResNet）</font>  \n",
        "<font face=楷体 color=yellow  size=4>疑问</font>  \n",
        "~~~\n",
        "line35: out = out.view(out.size(0), -1)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_9C4cFW9FF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        \n",
        "        # Initial input conv\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3, out_channels=64, kernel_size=(3, 3),\n",
        "            stride=1, padding=1, bias=False\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        # Create blocks\n",
        "        self.block1 = self._create_block(64, 64, stride=1)\n",
        "        self.block2 = self._create_block(64, 128, stride=2)\n",
        "        self.block3 = self._create_block(128, 256, stride=2)\n",
        "        self.block4 = self._create_block(256, 512, stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "    \n",
        "    # A block is just two residual blocks for ResNet18\n",
        "    def _create_block(self, in_channels, out_channels, stride):\n",
        "        return nn.Sequential(\n",
        "            ResidualBlock(in_channels, out_channels, stride),\n",
        "            ResidualBlock(out_channels, out_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\t# Output of one layer becomes input to the next\n",
        "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.block4(out)\n",
        "        out = nn.AvgPool2d(4)(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH2wrgnRv-6o",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>输入格式：</font><font face=楷体 >图像的输入格式是[B C H W]  \n",
        "B批量大小、C通道、H高度、W宽度</font>  \n",
        "<font face=楷体 color=skyblue  size=4>加载数据：</font><font face=楷体 >这里用到torch.utils.data.Dataset和torch.utils.data.Dataloader  \n",
        "    将CIFAR-10数据集下载到当前目录"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1TsNo_TukFK",
        "colab_type": "code",
        "outputId": "391ff2b2-2f61-4a35-e7b5-da1686e77729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "!wget http://pjreddie.com/media/files/cifar.tgz\n",
        "!tar xzf cifar.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2019-08-12 05:40:16--  https://pjreddie.com/media/files/cifar.tgz\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168584360 (161M) [application/octet-stream]\n",
            "Saving to: ‘cifar.tgz.1’\n",
            "\n",
            "cifar.tgz.1         100%[===================>] 160.77M  64.7MB/s    in 2.5s    \n",
            "\n",
            "2019-08-12 05:40:19 (64.7 MB/s) - ‘cifar.tgz.1’ saved [168584360/168584360]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaZnxqM-1zFK",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>读取CIFAR数据集中存在的类的标签</font>  \n",
        "<font face=楷体 color=yellow  size=4>疑问</font>  \n",
        "~~~\n",
        "line5: label_mapping = dict(zip(labels, list(range(len(labels)))))\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvjHQUUukC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"cifar/train/\"\n",
        "\n",
        "with open(\"cifar/labels.txt\") as label_file:\n",
        "    labels = label_file.read().split()\n",
        "    label_mapping = dict(zip(labels, list(range(len(labels)))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7OmnIqZ2n-Q",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>用PIL读取图像：</font>\n",
        "\n",
        "\n",
        "*   <font face=楷体>随机水平翻转图片的概率为0.5\n",
        "*   使用CIFAR数据集的均值和标准差来标准化图像\n",
        "*   图片格式变换：$W\\times H\\times C\\Longrightarrow C\\times H\\times W$</font>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UysrgabukAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(image):\n",
        "    image = np.array(image)\n",
        "    \n",
        "    if random.random() > 0.5:\n",
        "        image = image[::-1,:,:]\n",
        "    \n",
        "    cifar_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1,1,-1)\n",
        "    cifar_std  = np.array([0.2023, 0.1994, 0.2010]).reshape(1,1,-1)\n",
        "    image = (image - cifar_mean) / cifar_std\n",
        "    \n",
        "    image = image.transpose(2,1,0)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkrqtu9j4Tdy",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>加载数据：</font>  \n",
        "<font face=楷体>torch.utils.data.dataset：是一个加载数据并返回生成器的类，允许将数据增强融合到input Pipeline中</font>    \n",
        "<font face=楷体 color=skyblue>dataset为数据创建对象，需要重载三个方法：  </font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>\n",
        "    <font face=楷体 color=skyblue>__init __方法：</font> \n",
        "    定义与数据集相关的内容：数据位置，各种数据扩充等\n",
        "*  <font face=楷体 color=skyblue> __len __方法：</font>\n",
        "    返回数据的长度\n",
        "*   <font face=楷体 color=skyblue>__getitem __方法：</font>\n",
        "    将索引作为对象的参数，通过给定索引获取数据和标签（对象[索引]）\n",
        "</font>    \n",
        "\n",
        "<font face=楷体 color=yellow  size=4>疑问：</font>    \n",
        "  __getitem __方法  \n",
        "  transforms 数据扩充\n",
        "  ~~~\n",
        "  line32：image = image.astype(np.float32)\n",
        "  ~~~\n",
        "  <font face=楷体 color=green  size=4>**绿色链接：** </font>  \n",
        "   <font face=楷体>\n",
        "  [【1】PyTorch源码解读之torchvision.transforms](https://blog.csdn.net/u014380165/article/details/79167753)\n",
        "     </font>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebfdwmiuj9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Cifar10Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, data_size = 0, transforms = None):\n",
        "        files = os.listdir(data_dir)\n",
        "        files = [os.path.join(data_dir,x) for x in files]\n",
        "        \n",
        "        \n",
        "        if data_size < 0 or data_size > len(files):\n",
        "            assert(\"Data size should be between 0 to number of files in the dataset\")\n",
        "        \n",
        "        if data_size == 0:\n",
        "            data_size = len(files)\n",
        "        \n",
        "        self.data_size = data_size\n",
        "        self.files = random.sample(files, self.data_size)  # 打乱顺序\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_address = self.files[idx]\n",
        "        image = Image.open(image_address)\n",
        "        image = preprocess(image)\n",
        "        label_name = image_address[:-4].split(\"_\")[-1]\n",
        "        label = label_mapping[label_name]\n",
        "        \n",
        "        image = image.astype(np.float32)\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgMOCRTtaJ2M",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>torch.utils.data.Dataloader：</font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>批处理数据\n",
        "*   混排（Shuffling）数据\n",
        "*   多线程一次加载多个数据\n",
        "*   预读，即当GPU处理当前批数据时，Dataloader可以同时将下一批数据加载到内存中。这意味着GPU不必等待，加快训练速度</font>\n",
        "\n",
        "\n",
        "<font face=楷体 color=green  size=4>**绿色链接：**</font>    \n",
        "\n",
        "[【1】PyTorch源码解读之torch.utils.data.DataLoader](https://blog.csdn.net/u014380165/article/details/79058479)  、\n",
        "\n",
        "[【2】SOURCE CODE FOR TORCH.UTILS.DATA.DATALOADER](https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8gkivYCuj7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = Cifar10Dataset(data_dir = \"cifar/train/\", transforms=None)\n",
        "# 第一个参数：可迭代Dataset对象；num_workers：线程数\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2) \n",
        "\n",
        "testset = Cifar10Dataset(data_dir = \"cifar/test/\", transforms=None)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uujxT58yuj4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for data in trainloader:   # or trainset 注意区别\n",
        "\timg, label = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-vZWVdWEM9R",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=yellow size=4>\n",
        "DataLoader和Dataset都是返回可迭代对象 \n",
        "</font>\n",
        "\n",
        "*  <font face=楷体> __ getitem__方法trainset返回一个numpy数组($C\\times H\\times W$)，Dataloader将图像批量化为Tensor($B\\times C\\times H\\times W$) \n",
        "*   __ getitem__方法输出一个numpy数组，但Dataloader类会自动将其转换为Tensor\n",
        "*   __ getitem__方法返回一个非数字类型的对象，Dataloader该类也将其转换为大小的列表/元组B（在我们的例子中为128）。假设   __getitem__  还返回一个字符串，即标签字符串。如果我们在实例化dataloader时设置batch = 128，那么每次迭代Dataloader都会给我们一个128字符串的元组。\n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd7SZFk1l82E",
        "colab_type": "text"
      },
      "source": [
        "### 训练和评估  \n",
        "<font face=楷体 color=skyblue size=4>\n",
        "torch.optim模块训练/优化\n",
        "</font>          \n",
        "\n",
        "\n",
        "*   <font face=楷体>不同的优化算法（如：optim.SGD，optim.Adam） \n",
        "*   设置学习率（有optim.lr_scheduler）\n",
        "*   可为不同的参数设置不同的学习率\n",
        "    </font>    \n",
        "    \n",
        "<font face=楷体 color=yellow size=4>疑问：</font>    \n",
        "clf.parameters()\n",
        "\n",
        "<font face=楷体 color=green size=4>**绿色链接：**</font>    \n",
        "<font face=楷体>\n",
        "[【1】pytorch使用torch.dtype、torch.device和torch.layout管理数据类型属性](https://ptorch.com/news/187.html)  \n",
        "[【2】torch.cuda](https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-cuda/)  \n",
        "[【3】torch.optim](https://ptorch.com/docs/1/optim)\n",
        " </font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv95B2owuj1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")     # Check whether a GPU is present.\n",
        "\n",
        "clf = ResNet()\n",
        "clf.to(device)   # Put the network on GPU if present\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # 创建对象\n",
        "optimizer = optim.SGD(clf.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)  # clf.parameters()：神经网络的权重\n",
        "# 衰减因子gamma=0.1；当150 =< epoch < 200 ；lr = gamma * lr\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS1IwZcU3UKr",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>迭代：</font>  \n",
        "\n",
        "\n",
        "*   <font face=楷体>先调用scheduler.step()，以确保optimizer使用正确的学习率\n",
        "*    input 和 target $\\Longrightarrow$ GPU 0\n",
        "*   optimizer.zero_grad()：将梯度设置为零，因为Tensor会保留之前的梯度，防止其累积\n",
        "*   torch.no_grad环境管理器：不会为测试部分创建图表</font>    \n",
        "\n",
        "<font face=楷体 color=yellow size=4>疑问：</font>    \n",
        "1、line24: clf.eval()  \n",
        "<font face=楷体>\n",
        "PyTorch中的模型有两个状态eval()和train()，eval()状态下，框架会自动把BN和DropOut固定住，直接用训练好的值  \n",
        "\n",
        "*   训练时是用批处理（min-batch），但测试时往往针对单张图片，即不存在min-batch，由于网络训练完毕后参数都是固定的，每个批次的均值和方差都不变，因此直接结算所有batch的均值和方差，所以Batch Normalization训练和测试时的操作是不同的\n",
        "*   \n",
        "训练时每个隐层的神经元先乘概率P，然后在进行激活；测试时所有的神经元先进行激活，然后每个隐层神经元的输出乘P</font>  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "717phvy5ujzE",
        "colab_type": "code",
        "outputId": "d566cb0d-84cf-4efc-b336-9d75e54a7a09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(10):\n",
        "    losses = []\n",
        "    scheduler.step()\n",
        "    # Train\n",
        "    start = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()                 # Zero the gradients\n",
        "\n",
        "        outputs = clf(inputs)                 # Forward pass\n",
        "        loss = criterion(outputs, targets)    # Compute the Loss\n",
        "        loss.backward()                       # Compute the Gradients\n",
        "\n",
        "        optimizer.step()                      # Updated the weights\n",
        "        losses.append(loss.item())\n",
        "        end = time.time()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Batch Index : %d Loss : %.3f Time : %.3f seconds ' % (batch_idx, np.mean(losses), end - start))\n",
        "            \n",
        "            start = time.time()\n",
        "    # Evaluate\n",
        "    clf.eval()  # 将模型设置成evaluation模式，仅当模型中有Dropout和BatchNorm有影响\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            outputs = clf(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
        "        print('--------------------------------------------------------------')\n",
        "    clf.train()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Index : 0 Loss : 2.325 Time : 0.400 seconds \n",
            "Batch Index : 100 Loss : 1.992 Time : 16.010 seconds \n",
            "Batch Index : 200 Loss : 1.850 Time : 16.440 seconds \n",
            "Batch Index : 300 Loss : 1.757 Time : 16.861 seconds \n",
            "Epoch : 0 Test Acc : 43.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 1.497 Time : 0.321 seconds \n",
            "Batch Index : 100 Loss : 1.345 Time : 17.924 seconds \n",
            "Batch Index : 200 Loss : 1.300 Time : 17.434 seconds \n",
            "Batch Index : 300 Loss : 1.250 Time : 17.201 seconds \n",
            "Epoch : 1 Test Acc : 52.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.927 Time : 0.317 seconds \n",
            "Batch Index : 100 Loss : 1.021 Time : 17.442 seconds \n",
            "Batch Index : 200 Loss : 1.001 Time : 17.560 seconds \n",
            "Batch Index : 300 Loss : 0.981 Time : 17.530 seconds \n",
            "Epoch : 2 Test Acc : 63.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.858 Time : 0.312 seconds \n",
            "Batch Index : 100 Loss : 0.850 Time : 17.382 seconds \n",
            "Batch Index : 200 Loss : 0.845 Time : 17.340 seconds \n",
            "Batch Index : 300 Loss : 0.839 Time : 17.372 seconds \n",
            "Epoch : 3 Test Acc : 60.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.722 Time : 0.313 seconds \n",
            "Batch Index : 100 Loss : 0.757 Time : 17.457 seconds \n",
            "Batch Index : 200 Loss : 0.757 Time : 17.440 seconds \n",
            "Batch Index : 300 Loss : 0.757 Time : 17.478 seconds \n",
            "Epoch : 4 Test Acc : 62.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.727 Time : 0.314 seconds \n",
            "Batch Index : 100 Loss : 0.685 Time : 17.504 seconds \n",
            "Batch Index : 200 Loss : 0.701 Time : 17.410 seconds \n",
            "Batch Index : 300 Loss : 0.696 Time : 17.371 seconds \n",
            "Epoch : 5 Test Acc : 70.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.631 Time : 0.320 seconds \n",
            "Batch Index : 100 Loss : 0.647 Time : 17.365 seconds \n",
            "Batch Index : 200 Loss : 0.645 Time : 17.308 seconds \n",
            "Batch Index : 300 Loss : 0.647 Time : 17.318 seconds \n",
            "Epoch : 6 Test Acc : 65.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.538 Time : 0.324 seconds \n",
            "Batch Index : 100 Loss : 0.578 Time : 17.388 seconds \n",
            "Batch Index : 200 Loss : 0.589 Time : 17.383 seconds \n",
            "Batch Index : 300 Loss : 0.594 Time : 17.370 seconds \n",
            "Epoch : 7 Test Acc : 75.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.609 Time : 0.315 seconds \n",
            "Batch Index : 100 Loss : 0.551 Time : 17.375 seconds \n",
            "Batch Index : 200 Loss : 0.562 Time : 17.418 seconds \n",
            "Batch Index : 300 Loss : 0.564 Time : 17.435 seconds \n",
            "Epoch : 8 Test Acc : 70.000\n",
            "--------------------------------------------------------------\n",
            "Batch Index : 0 Loss : 0.448 Time : 0.316 seconds \n",
            "Batch Index : 100 Loss : 0.508 Time : 17.456 seconds \n",
            "Batch Index : 200 Loss : 0.531 Time : 17.378 seconds \n",
            "Batch Index : 300 Loss : 0.527 Time : 17.361 seconds \n",
            "Epoch : 9 Test Acc : 70.000\n",
            "--------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-iJJYkJDebi",
        "colab_type": "text"
      },
      "source": [
        "# part-3 深入研究PyTorch  \n",
        "<font face=STCAIYUN color=skyblue size=4>**主要内容**</font>\n",
        "\n",
        "<font face=STCAIYUN color=skyblue size=4>**1. </font>  <font face=楷体>  nn.Module，nn.Functional，nn.Parameter等PyTorch类之间的差别及如何应用  \n",
        "<font face=STCAIYUN color=skyblue size=4>**2.</font>   学习如何使用Dataset及如何自定义训练，如：在不同网络层设置不同的学习率  \n",
        "<font face=STCAIYUN color=skyblue size=4>3.  </font> 初始化权重\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzAQUxOiGkrY",
        "colab_type": "text"
      },
      "source": [
        "## nn.Module <font face=STCAIYUN color=yellow  size=5>vs</font> nn.Functional</font>   \n",
        "<font face=楷体><font face=楷体 color=skyblue >torch.nn.Module</font>   是PyTorch的基石\n",
        "    \n",
        "使用方式：先定义一个nn.Module对象，然后调用它的forward方法来运行它，是以一种面向对象的方式。\n",
        "    \n",
        "<font face=楷体 color=skyblue >nn.functional</font>提供一些函数形式的层/激活函数，可以直接调用。如：调整图像的tensor shape可以调用torch.nn.functional.interpolate\n",
        "</font>     \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNBHU7gvNAgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ff387502-f111-4db3-f10c-934af6656ae2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "inp = torch.randn(1,3,64,64)     # random input image\n",
        "\n",
        "# Same thing using two approaches\n",
        "\n",
        "# torch.nn\n",
        "avg_pool = nn.AvgPool2d(4)     # create an object\n",
        "nn_out = avg_pool(inp)         # invoke the forward method\n",
        "\n",
        "# torch.nn.Functional\n",
        "f_out = F.avg_pool2d(inp, 4)\n",
        "\n",
        "print (torch.equal(nn_out, f_out))        # check whether the same result is produced"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvj6j5gFNMsC",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue  size=4>\n",
        "了解状态\n",
        "</font>  \n",
        "<font face=楷体>\n",
        "    任何层都可以看作是一个函数（如：卷积运算只是一堆乘法和加法运算），但绝不仅仅是一个函数，train()状态时，它还要保存权重（eval()状态时不需要），这些权重在随着训练不断变化 ；实现一个执行卷积运算的函数，还需要定义一个数据结构来保持层的权重与函数本身分开，将此外部数据结构作为函数的输入（或者定义一个类来保存数据结构，并将卷积操作作为成员函数）。所以，<font face=楷体 color=skyblue >需要保存、更新权重或定义层其他行为状态更倾向于使用nn.Module对象</font>  ，如：dropout / Batch Norm层（训练和测试时表现不同）\n",
        "    \n",
        "<font face=楷体 color=skyblue >如果不需要任何状态或权重，可以使用nn.functional</font>  ，如：resizing（nn.functional.interpolate），average pooling（nn.functional.AvgPool2d）\n",
        " </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I7cZ4DxJCmT",
        "colab_type": "text"
      },
      "source": [
        "## nn.Parameter  \n",
        "<font face=楷体>\n",
        "每个nn.Module都有一个parameters()函数，返回训练参数 ，这些参数都是隐式定义的，<font color=yellow>如： </font>\n",
        "\n",
        "将权重和偏差定义为nn.Conv2d层的参数（parameters），\n",
        "nn.Conv2d对象作为net对象的成员，将nn.Conv2d的parameters<font color=yellow>隐式地</font>添加到net的parameters\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To4nGYsBDc-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "8d574252-14ca-43a6-a058-5888a29c691b"
      },
      "source": [
        "class net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net()\n",
        "\n",
        "#prints the weights and bias of Linear Layer\n",
        "print(list(myNet.parameters()))     "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.0926,  0.2187, -0.2662,  0.0521, -0.0017, -0.3112, -0.0364,  0.1104,\n",
            "         -0.3047, -0.0755],\n",
            "        [-0.1563, -0.0881, -0.2432, -0.0159, -0.2308,  0.0856,  0.1889, -0.2231,\n",
            "         -0.2278,  0.0325],\n",
            "        [-0.2875, -0.1271,  0.2549,  0.1854, -0.0532,  0.1335, -0.1458,  0.2900,\n",
            "          0.2415, -0.2507],\n",
            "        [ 0.0496,  0.0826, -0.1131,  0.0208,  0.1302,  0.2035, -0.3146,  0.2113,\n",
            "          0.1580, -0.0839],\n",
            "        [ 0.0133, -0.1628,  0.2050,  0.0549, -0.2991,  0.0993,  0.1947,  0.0085,\n",
            "         -0.1174,  0.1326]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.2769, -0.0205,  0.2578,  0.2376, -0.1807], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf0gUnfOK2Uw",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "nn.Module类所有训练权重都是作为nn.Parameter对象实现的  \n",
        "    \n",
        "如果尝试为nn.Module对象分配一个张量，除非将其定义为nn.Parameter对象，否则它不会显示在对象中  ，这样做是为了便于可能需要缓存不可微分张量的情况，例如，RNN缓存先前的输出。\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm7TaPGMDc74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "dfad5113-5ad1-44d6-ec7e-a30592f80f7e"
      },
      "source": [
        "class net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5)\n",
        "        self.tens = torch.ones(3,4)                       # This won't show up in a parameter list \n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "    \n",
        "myNet = net1()\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 3.1077e-01,  2.9064e-01, -3.1203e-01,  2.6764e-01, -2.4576e-01,\n",
            "         -2.3809e-01,  1.1285e-01,  5.0202e-02,  1.2070e-01,  2.4290e-01],\n",
            "        [ 5.7830e-02, -1.2940e-04, -3.5586e-03,  3.3382e-02,  3.0426e-02,\n",
            "          8.3874e-02, -1.6578e-01,  9.2118e-02,  9.9363e-02, -2.2698e-01],\n",
            "        [-8.6960e-02,  2.5439e-01,  2.1148e-01,  4.9662e-02,  2.7508e-01,\n",
            "         -8.5165e-02,  1.3041e-01, -1.7114e-02,  1.1198e-01, -1.8522e-01],\n",
            "        [ 1.1522e-01,  2.6888e-01, -2.3142e-01, -3.4737e-02, -6.7823e-02,\n",
            "          2.0897e-01, -1.6254e-01, -2.7248e-01,  5.9397e-02, -1.0993e-01],\n",
            "        [-1.1501e-01, -1.7813e-01, -2.1228e-01, -2.1794e-01, -1.5854e-01,\n",
            "         -9.2147e-02, -2.5643e-01,  2.5347e-01, -8.1554e-02,  2.6417e-01]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.2237,  0.0358, -0.2227,  0.1571,  0.1680], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5PNwByG3aNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0dd8f424-02ec-488a-f163-b079292497a2"
      },
      "source": [
        "class net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5) \n",
        "        self.tens = nn.Parameter(torch.ones(3,4))         # This will show up in a parameter list \n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net2()\n",
        "print(list(myNet.parameters()))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.1500, -0.2401, -0.2126, -0.2890, -0.2318,  0.2337, -0.2820, -0.1947,\n",
            "         -0.2645,  0.1324],\n",
            "        [-0.0896,  0.0453,  0.1682,  0.2182,  0.1532,  0.0474, -0.2855, -0.2457,\n",
            "          0.0488,  0.2059],\n",
            "        [-0.2856,  0.2502, -0.2356,  0.0276,  0.1286, -0.0241, -0.1821, -0.0616,\n",
            "          0.0142,  0.0273],\n",
            "        [-0.3050, -0.2686, -0.0116,  0.1047, -0.0329, -0.0454, -0.1809,  0.1941,\n",
            "         -0.2898, -0.1292],\n",
            "        [ 0.2849, -0.0019, -0.2207, -0.2798, -0.3115, -0.2471,  0.0943, -0.0516,\n",
            "          0.2965, -0.2453]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1801,  0.0246,  0.2966,  0.0904,  0.2116], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrzx7Hcg3cdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "e43e3cca-846d-48b0-e5db-fee6910972f3"
      },
      "source": [
        "class net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Linear(10,5) \n",
        "        self.net  = net2()                                # Parameters of net2 will show up in list of parameters of net3\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "myNet = net3()\n",
        "print(list(myNet.parameters()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2875,  0.0333, -0.0960, -0.1356, -0.0302, -0.0400, -0.2221, -0.1920,\n",
            "         -0.0871,  0.2897],\n",
            "        [-0.2136,  0.1195, -0.0166,  0.0887, -0.0934,  0.0212, -0.1770, -0.0740,\n",
            "          0.0815,  0.2865],\n",
            "        [-0.3121, -0.2448, -0.2292,  0.0115,  0.1970,  0.2191,  0.0099,  0.1680,\n",
            "         -0.3015, -0.2308],\n",
            "        [-0.1488,  0.1683,  0.2023,  0.2309,  0.1990,  0.2117, -0.2737, -0.2217,\n",
            "          0.0763, -0.1254],\n",
            "        [ 0.0589, -0.1519, -0.2553,  0.0890, -0.1559,  0.2358,  0.1993,  0.2307,\n",
            "         -0.1046,  0.1838]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0491, -0.2433, -0.1561,  0.2427, -0.3029], requires_grad=True), Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0754, -0.2132, -0.2313,  0.2725,  0.0102,  0.1251,  0.0971,  0.0160,\n",
            "          0.0131, -0.2261],\n",
            "        [-0.2561, -0.0064, -0.1440,  0.0350, -0.2579, -0.0732,  0.2141,  0.2359,\n",
            "         -0.0430,  0.1097],\n",
            "        [-0.2027, -0.2136, -0.0523,  0.1477,  0.0907,  0.1586, -0.2683, -0.2319,\n",
            "         -0.0938,  0.2080],\n",
            "        [ 0.2003,  0.0507,  0.2553,  0.1196, -0.0524,  0.1769, -0.0425,  0.0460,\n",
            "          0.0524, -0.1663],\n",
            "        [ 0.3109, -0.1323,  0.2500, -0.2678,  0.1575, -0.2873,  0.0144, -0.1457,\n",
            "          0.2628,  0.0502]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1865,  0.1140, -0.1190, -0.2162, -0.3066], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3HHO0AT3JSp",
        "colab_type": "text"
      },
      "source": [
        "## nn.ModuleList和nn.ParameterList（）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkcD_aJqDc3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "931e0247-cc74-43ab-d29d-40aa88cb8496"
      },
      "source": [
        "layer_list = [nn.Conv2d(5,5,3), nn.BatchNorm2d(5), nn.Linear(5,2)]\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = layer_list\n",
        "    \n",
        "    def forward(x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "net = myNet()\n",
        "\n",
        "print(list(net.parameters()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY4AF_ZY5PLa",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体>\n",
        "正如我们所看到的，与注册单个模块不同，分配Python列表并登记列表中模块的参数。  \n",
        "    \n",
        "为了解决这个问题，我们将列表与nn.ModuleList类封装。然后将其指定为网络类的成员\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtMQ9IqDDc06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97593ceb-e93a-4ee8-d71d-8269da63a8ec"
      },
      "source": [
        "layer_list = [nn.Conv2d(5,5,3), nn.BatchNorm2d(5), nn.Linear(5,2)]\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layer_list)\n",
        "        \n",
        "    def forward(x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "net = myNet()\n",
        "\n",
        "print(list(net.parameters()))  # Parameters of modules in layer_list show up."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[[[ 0.0113,  0.1198,  0.0024],\n",
            "          [ 0.0572,  0.1451, -0.0942],\n",
            "          [-0.0553,  0.1140,  0.1462]],\n",
            "\n",
            "         [[ 0.0610,  0.0324,  0.0173],\n",
            "          [-0.0259, -0.0282, -0.0647],\n",
            "          [ 0.1265,  0.0826,  0.0194]],\n",
            "\n",
            "         [[ 0.0604, -0.0954, -0.0928],\n",
            "          [-0.0149, -0.1048,  0.0245],\n",
            "          [-0.0317,  0.0888, -0.0733]],\n",
            "\n",
            "         [[ 0.0068, -0.0902, -0.1327],\n",
            "          [ 0.0928, -0.0102, -0.1209],\n",
            "          [ 0.1397, -0.0674, -0.0500]],\n",
            "\n",
            "         [[ 0.0261,  0.1271,  0.0450],\n",
            "          [-0.0407, -0.1073, -0.1266],\n",
            "          [ 0.0316, -0.0594, -0.0595]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1372, -0.1372, -0.0668],\n",
            "          [ 0.0413, -0.0246, -0.0841],\n",
            "          [ 0.0691, -0.0539, -0.1472]],\n",
            "\n",
            "         [[-0.1173,  0.1250,  0.0362],\n",
            "          [-0.1179, -0.0109,  0.0123],\n",
            "          [-0.0810, -0.1143,  0.1064]],\n",
            "\n",
            "         [[ 0.0309,  0.1110,  0.1147],\n",
            "          [ 0.0796, -0.0666,  0.1168],\n",
            "          [-0.0121,  0.0219, -0.0840]],\n",
            "\n",
            "         [[ 0.0098, -0.0836, -0.0766],\n",
            "          [-0.0800,  0.1309, -0.1457],\n",
            "          [ 0.0132, -0.1367,  0.0234]],\n",
            "\n",
            "         [[-0.0723,  0.1265, -0.0277],\n",
            "          [-0.0734, -0.1445,  0.0909],\n",
            "          [-0.0062,  0.0893, -0.0205]]],\n",
            "\n",
            "\n",
            "        [[[-0.0630,  0.0691,  0.0049],\n",
            "          [-0.0622, -0.0495,  0.0065],\n",
            "          [-0.0414, -0.1006,  0.1439]],\n",
            "\n",
            "         [[-0.1348, -0.1129,  0.0545],\n",
            "          [-0.0899, -0.0477, -0.0956],\n",
            "          [ 0.0546, -0.0781, -0.1060]],\n",
            "\n",
            "         [[ 0.0309, -0.1223, -0.0810],\n",
            "          [-0.0612, -0.0864,  0.0300],\n",
            "          [ 0.1406, -0.0989, -0.0263]],\n",
            "\n",
            "         [[ 0.1183,  0.1111, -0.0957],\n",
            "          [ 0.0101,  0.1156, -0.0309],\n",
            "          [ 0.1411,  0.0314, -0.0230]],\n",
            "\n",
            "         [[-0.0845,  0.0844, -0.1043],\n",
            "          [-0.0036, -0.0709,  0.0447],\n",
            "          [ 0.0224,  0.0639, -0.1442]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0177, -0.1322,  0.0637],\n",
            "          [-0.0160,  0.1005,  0.0963],\n",
            "          [ 0.0287,  0.1373, -0.0559]],\n",
            "\n",
            "         [[ 0.0607,  0.1137, -0.1044],\n",
            "          [ 0.0887, -0.0018, -0.1226],\n",
            "          [ 0.0923, -0.0778, -0.0794]],\n",
            "\n",
            "         [[ 0.0268,  0.0717, -0.1109],\n",
            "          [ 0.0695,  0.0751,  0.0136],\n",
            "          [-0.0026,  0.0278, -0.0898]],\n",
            "\n",
            "         [[ 0.1201, -0.0942, -0.0234],\n",
            "          [-0.0909,  0.0633, -0.0442],\n",
            "          [-0.0266, -0.0197,  0.0801]],\n",
            "\n",
            "         [[ 0.0272,  0.0163,  0.1164],\n",
            "          [-0.0368, -0.0243, -0.0986],\n",
            "          [-0.0054, -0.1263, -0.0993]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0515, -0.0753,  0.0962],\n",
            "          [-0.1435, -0.0981, -0.0780],\n",
            "          [ 0.0791,  0.0559,  0.0530]],\n",
            "\n",
            "         [[-0.0509, -0.0902, -0.0015],\n",
            "          [ 0.0135,  0.0218,  0.0118],\n",
            "          [-0.0221,  0.0148,  0.0891]],\n",
            "\n",
            "         [[ 0.0295, -0.1378, -0.1436],\n",
            "          [ 0.1213,  0.0219, -0.0411],\n",
            "          [ 0.0825, -0.1229, -0.0357]],\n",
            "\n",
            "         [[-0.0718, -0.1449, -0.0220],\n",
            "          [ 0.0993, -0.0347, -0.0945],\n",
            "          [-0.0670,  0.0961, -0.1435]],\n",
            "\n",
            "         [[ 0.0468, -0.1453,  0.0832],\n",
            "          [-0.0841,  0.0699, -0.0444],\n",
            "          [-0.0249, -0.0335, -0.1023]]]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0856, -0.1449,  0.0608,  0.0752,  0.0700], requires_grad=True), Parameter containing:\n",
            "tensor([0.0354, 0.1126, 0.2441, 0.3270, 0.5581], requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.2553,  0.1247, -0.0574, -0.3664, -0.3168],\n",
            "        [ 0.4063,  0.1691, -0.4437,  0.0899,  0.1705]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4033,  0.2050], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnltjumt6-LY",
        "colab_type": "text"
      },
      "source": [
        "## 初始化权重\n",
        "<font face=楷体><font face=楷体 color=skyblue  size=4>\n",
        "初始化重量可以影响训练结果，而且对于不同类型的层，可能需要不同的权重初始化方案，通过modules和apply函数来实现：</font>\n",
        "\n",
        "\n",
        "*   modules是nn.Module类的成员函数，它返回一个包含函数的所有成员nn.Module成员对象的迭代器nn.Module\n",
        "*   可以在每个nn.Module上调用apply函数来设置初始化\n",
        "</font>\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gM-wt2BDcyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "dd4ff7a0-8afc-4432-b469-7dc12138895c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(10,10,3)\n",
        "        self.bn = nn.BatchNorm2d(10)\n",
        "        \n",
        "    def weights_init(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.normal_(module.weight, mean = 0, std = 1)\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "\n",
        "Net = myNet()\n",
        "Net.weights_init()\n",
        "\n",
        "for module in Net.modules():\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "        weights = module.weight\n",
        "        weights = weights.reshape(-1).detach().cpu().numpy()\n",
        "        print(module.bias)                                       # Bias to zero\n",
        "        plt.hist(weights)\n",
        "        plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zhlW-0QNjXW",
        "colab_type": "text"
      },
      "source": [
        "## modules() <font face=STCAIYUN color=yellow  size=5>vs</font> children()  \n",
        "和modules非常类似的函数是children，差异很小但很重要：\n",
        "\n",
        "\n",
        "*   nn.Module对象可以包含其他nn.Module对象作为其数据成员\n",
        "*   children()只返回一个调用了children的nn.Module对象的数据成员列表\n",
        "\n",
        "另一方面，nn.Modules在每个nn.Module对象内递归，创建一个nn.Module沿途的每个对象的列表，直到没有nn.module对象为止。注意，modules()还返回nn.Module它作为列表的一部分被调用的内容。   \n",
        "\n",
        "因此，当我们初始化权重时，我们可能想要使用modules()函数，因为我们无法进入nn.Sequential对象并初始化其成员的权重。  \n",
        "\n",
        "![替代文字](https://blog.paperspace.com/content/images/2019/05/children_vs_modules_pytorch-2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH9bfN_DDcwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e62e3971-c8b1-492a-84da-32fdee114745"
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convBN =  nn.Sequential(nn.Conv2d(10,10,3), nn.BatchNorm2d(10))\n",
        "        self.linear =  nn.Linear(10,2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        pass\n",
        "    \n",
        "Net = myNet()\n",
        "\n",
        "print(\"Printing children\\n------------------------------\")\n",
        "print(list(Net.children()))\n",
        "print(\"\\n\\nPrinting Modules\\n------------------------------\")\n",
        "print(list(Net.modules()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing children\n",
            "------------------------------\n",
            "[Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "), Linear(in_features=10, out_features=2, bias=True)]\n",
            "\n",
            "\n",
            "Printing Modules\n",
            "------------------------------\n",
            "[myNet(\n",
            "  (convBN): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
            "), Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "), Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)), BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Linear(in_features=10, out_features=2, bias=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFfuUdo-QYee",
        "colab_type": "text"
      },
      "source": [
        "## 打印有关网络的信息\n",
        "\n",
        "PyTorch提供了一种非常简洁的方法，可以使用它的named_*功能打印有关网络的大量信息，有以下四个方法：\n",
        "\n",
        "\n",
        "*   named_parameters ：返回一个迭代器，给出一个包含参数名称的元组（如果卷积层被指定为self.conv1，那么它的参数将是conv1.weight和conv1.bias）以及由nn.Parameter下的__ repr__函数返回的值\n",
        "\n",
        "*   named_modules ： 与上面相同，但迭代器返回模块（类似modules()的返回）\n",
        "*   与上面相同，但迭代器返回模块（类似children()的返回）\n",
        "\n",
        "\n",
        "*   named_buffers ： 返回缓冲区张量，例如Bn层的移动平均值\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jb_i666Dcts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "7ac3daa7-3d1c-491e-89de-8ae064d741fb"
      },
      "source": [
        "for x in Net.named_modules():\n",
        "    print(x[0], x[1], \"\\n-------------------------------\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " myNet(\n",
            "  (convBN): Sequential(\n",
            "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
            ") \n",
            "-------------------------------\n",
            "convBN Sequential(\n",
            "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ") \n",
            "-------------------------------\n",
            "convBN.0 Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)) \n",
            "-------------------------------\n",
            "convBN.1 BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
            "-------------------------------\n",
            "linear Linear(in_features=10, out_features=2, bias=True) \n",
            "-------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgrC-dU3S6vn",
        "colab_type": "text"
      },
      "source": [
        "## 设置不同层学习率  \n",
        "介绍如何针对不同的参数组设置不同的超参数，无论是不同层学习率，或者偏差和权重的学习率。 \n",
        "\n",
        "前面实现了CIFAR分类器，将网络所有参数作为一个整体传递给了优化器对象"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuAQW289Dcq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(10,5)\n",
        "        self.fc2 = nn.Linear(5,2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.fc1(x))\n",
        "\n",
        "Net = myNet()\n",
        "optimiser = torch.optim.SGD(Net.parameters(), lr = 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bCGXTpNVH_Z",
        "colab_type": "text"
      },
      "source": [
        "然而，torch.optim类允许以字典形式的参来设置不同学习率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37cDe3f9Dcnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimiser = torch.optim.SGD([{\"params\": Net.fc1.parameters(), 'lr' : 0.001, \"momentum\" : 0.99},\n",
        "                             {\"params\": Net.fc2.parameters()}], lr = 0.01, momentum = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkgtvdQ0JaVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_bias = []\n",
        "params_wts = []\n",
        "\n",
        "# seperate the bias and weights parameters\n",
        "for name, parameter in Net.named_parameters():\n",
        "    if \"bias\" in name:\n",
        "        params_bias.append(parameter)\n",
        "    elif \"weight\" in name:\n",
        "        params_wts.append(parameter)\n",
        "\n",
        "# Set the optimiser to have different hyperparameters for bias and weights\n",
        "optimiser = torch.optim.SGD([{\"params\": params_bias, 'lr' : 0.001, \"momentum\" : 0.99},\n",
        "                             {\"params\": params_wts}], lr = 0.01, momentum = 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHw4PcliGx0s",
        "colab_type": "text"
      },
      "source": [
        "### 学习率安排  \n",
        "\n",
        "torch.optim.lr_scheduler模块提供对学习速率的安排"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1fKalLKujwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimiser, milestones = [10,20], gamma = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNF1nFObHggL",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue size=4>\n",
        "    训练进行到milestones列表中包含的epoch范围时（$10\\leq epoch<20$），$Learning\\_rate*=gamma$  \n",
        "    </font>\n",
        "\n",
        "<font face=楷体 color=yellow size=4>注意：</font>\n",
        "    <font face=楷体  >\n",
        "\n",
        "*   训练循环一般由两个嵌套循环组成，确保scheduler.step在\"epoch\"循环开始时调用，而不要在\"batch\"循环中调用  \n",
        "*   scheduler.step不能替代optim.step，每次反向传播时都要调用optim.step(在“batch”循环中)\n",
        "</font>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC0IOsWALphJ",
        "colab_type": "text"
      },
      "source": [
        "## 保存模型  \n",
        "<font face=楷体 color=skyblue size=4>PyTorch保存模型有两种选择： </font> \n",
        "<font face=楷体>\n",
        "\n",
        "*   torch.save：保存整个模型用torch.save(the_model, PATH)，相当于nn.Module的Pickle，保存后可用torch.load从内存中加载模型\n",
        "*   state_dict：如果只保存模型中的参数用torch.save(model.state_dict(), PATH)，加载模型时需要自己导入模型的结构信息\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62-y7VwZ9E34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "b06a4fe7-89f3-4275-fdac-11a8064d8f97"
      },
      "source": [
        "torch.save(Net, \"net.pth\")\n",
        "Net = torch.load(\"net.pth\")\n",
        "print(Net)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "myNet(\n",
            "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
            "  (fc2): Linear(in_features=5, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type myNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNjXVJ5ZLotL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1e85e901-6c0b-4940-eeda-ebb474c70980"
      },
      "source": [
        "for key in Net.state_dict():\n",
        "    print(key, Net.state_dict()[key])\n",
        "    \n",
        "torch.save(Net.state_dict(), \"net_state_dict.pth\")\n",
        "Net.load_state_dict(torch.load(\"net_state_dict.pth\"))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.weight tensor([[-0.0142, -0.1490,  0.2568, -0.2621, -0.0803,  0.0824,  0.1999,  0.2888,\n",
            "          0.0114, -0.0053],\n",
            "        [-0.0471,  0.1405, -0.1094, -0.0921,  0.2265,  0.0744,  0.1465, -0.1262,\n",
            "         -0.1090, -0.2974],\n",
            "        [ 0.0035, -0.0351, -0.1386, -0.2429, -0.1477, -0.1273, -0.0503,  0.0053,\n",
            "          0.2148,  0.2893],\n",
            "        [-0.0885,  0.2263,  0.2858, -0.0348,  0.2520, -0.2159, -0.0207,  0.2793,\n",
            "         -0.2704, -0.1167],\n",
            "        [ 0.1640, -0.0631, -0.3121,  0.1830,  0.2677,  0.2574, -0.2797, -0.0270,\n",
            "          0.1276, -0.0990]])\n",
            "fc1.bias tensor([-0.2203, -0.2941,  0.2389,  0.1853, -0.2126])\n",
            "fc2.weight tensor([[-0.2143,  0.0816, -0.1487, -0.4326, -0.3264],\n",
            "        [-0.1830,  0.2608, -0.1976, -0.1337,  0.3195]])\n",
            "fc2.bias tensor([0.3887, 0.4306])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSxvTv667kkb",
        "colab_type": "text"
      },
      "source": [
        "#Part- 4 内存管理和多GPU  \n",
        "<font face=STCAIYUN color=skyblue size=4>**主要内容**</font>\n",
        "\n",
        "<font face=STCAIYUN color=skyblue size=4>1. </font>  <font face=楷体>  多GPU训练网络、数据并行、模型并行     \n",
        "<font face=STCAIYUN color=skyblue size=4>2.</font>   如何在创建新对象时自动选择GPU  \n",
        "<font face=STCAIYUN color=skyblue size=4>3.  </font> 如何诊断和分析内存问题\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjmsGXdjBloy",
        "colab_type": "text"
      },
      "source": [
        "</font>  <font face=楷体>PyTorch中每个Tensor都有一个to()成员函数，其所作用是将Tensor放到某个设备上（CPU、GPU$\\cdots$），to()的输入是detorch.device   \n",
        "torch.cuda.is_available函数检查GPU是否可用\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGwmbSsjLoqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\tdev = \"cuda:0\"\n",
        "else:\n",
        "\tdev = \"cpu\"\n",
        "\n",
        "device = torch.device(dev)\n",
        "\n",
        "a = torch.zeros(4,3)   \n",
        "a = a.to(device)       #alternatively, a.to(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqxWmhLIEqw9",
        "colab_type": "text"
      },
      "source": [
        "cuda（）函数：将张量放在GPU上的另一种方法是调用cuda(n)，n是GPU的索引"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Y03RO1G9_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0bdeb531-2a94-4cd4-a267-7c09b4d61fe0"
      },
      "source": [
        "class myNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(5,1)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "clf = myNetwork()\n",
        "clf.to(0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "myNetwork(\n",
              "  (net): Linear(in_features=5, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKKaP7t-HUvP",
        "colab_type": "text"
      },
      "source": [
        "自动选择GPU  \n",
        "PyTorch提供了一些函数实现自动选择GPU ， 以减少代码跨设备传输  \n",
        "torch.get_device仅支持GPU张量，返回张量所在的GPU的索引"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjEEGDB6Lonu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = a.get_device() \n",
        "b = torch.tensor(a.shape).to(dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHPvK9GfIOWI",
        "colab_type": "text"
      },
      "source": [
        "可以设置创建GPU张量的默认设备"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxb3kXCALolG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74a72c3a-2a27-4176-80a0-9c7acb693715"
      },
      "source": [
        "torch.cuda.set_device(0)\n",
        "\n",
        "tens = torch.Tensor(3,4).cuda()\n",
        "tens.get_device()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFdHMWIIyhx",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体><font face=楷体 color=skyblue size=4 >\n",
        "    new_ *函数  \n",
        "    </font>\n",
        "new_函数成为PyTorch 1.0版的一部分。  \n",
        "    \n",
        "<font face=楷体><font face=楷体 color=skyblue >new_ones函数：</font>返回一个相同数据类型的新张量，并且在与调用new_ones函数的张量相同的设备上"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwl_A4UuLoi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "91c32e9a-35b3-4123-94d8-72d91cc5c306"
      },
      "source": [
        "ones = torch.ones((2,)).cuda(0)\n",
        "\n",
        "# Create a tensor of ones of size (3,4) on same device as of \"ones\"\n",
        "newOnes = ones.new_ones((3,4)) \n",
        "\n",
        "randTensor = torch.randn(2,4)\n",
        "print(ones)\n",
        "print(newOnes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1.], device='cuda:0')\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgd4cjtSKJr6",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体><font face=楷体 color=skyblue size=4 >\n",
        "多GPU\n",
        "</font>  \n",
        "两种方式使用多个GPU：\n",
        "    \n",
        "\n",
        "*   数据并行，将批次分成小批次，并在多个GPU上并行处理这些小批次。\n",
        "*   模型并行，我们将神经网络分解为更小的子网络，在不同的GPU上执行这些子网络。\n",
        " </font>\n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t44SQs8BK1xs",
        "colab_type": "text"
      },
      "source": [
        "<font face=楷体 color=skyblue>数据并行：</font>通过nn.DataParallel类实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-X1PM9_Log3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu-8hZwrLoc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX8SQNasLoXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJEsD8xP8-Pf",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# 搭建神经网络\n",
        "用 torch.nn 包搭建神经网络  \n",
        "\n",
        "nn建立在autograd的基础上来进行模型的定义和微分  \n",
        "**一个典型的神经网络的训练过程：**\n",
        "\n",
        "1、定义一个有着可学习的参数（或者权重）的神经网络  \n",
        "2、对着一个输入的数据集进行迭代:  \n",
        "3、用神经网络对输入进行处理  \n",
        "4、计算代价值 (对输出值的修正到底有多少)  \n",
        "5、将梯度传播回神经网络的参数中  \n",
        "6、更新网络中的权重  \n",
        "$\\qquad$通常使用简单的更新规则: weight = weight + learning_rate * gradient  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWlOM8vHesGM",
        "colab_type": "text"
      },
      "source": [
        "##定义一个神经网络\n",
        "定义一个<font color=geen>**forward函数**</font>，backward会自动地生成， 可以在forward函数中使用所有的Tensor中的操作，模型中可学习的参数会由<font color=geen>**net.parameters()**</font>返回。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9niX6Fg8G8O",
        "colab_type": "code",
        "outputId": "74c6dccb-acce-4632-db8a-07f908d51281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)  # If the size is a square you can only specify a single number\n",
        "        x = x.view(-1, self.num_flat_features(x))  # ？？？？？？？？？？？？？？？？？\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:] # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "net = Net()\n",
        "net"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mxXftBneZbM",
        "colab_type": "text"
      },
      "source": [
        "## 输入\n",
        "**注意：** torch.nn包只接受小批量样本，而非单个样本。     \n",
        "例如：nn.Conv2d能够接受四维的$TensornSamples \\times nChannels \\times Height \\times Width$批量样本，\n",
        "如果非要用单个样本，使用input.unsqueeze(0)来加一个假维度就可以了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWa0e8119QGg",
        "colab_type": "code",
        "outputId": "9f98e66a-9a32-4c3e-d641-74fc196e031b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size()) # conv1's .weight\n",
        "\n",
        "input = Variable(torch.randn(1, 1, 32, 32))\n",
        "out = net(input)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsfG_ZpFfKEc",
        "colab_type": "text"
      },
      "source": [
        "## 反向传播"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfWibyTE-PLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad() # 对所有的参数的梯度缓冲区进行归零\n",
        "out.backward(torch.randn(1, 10)) # 使用随机的梯度进行反向传播"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt2nK9ylc_Ic",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3QpTC9XfUjZ",
        "colab_type": "text"
      },
      "source": [
        "##计算loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKmnx-NXfT3Y",
        "colab_type": "code",
        "outputId": "bd950846-eca9-4c84-d82b-a26840310791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "output = net(input)\n",
        "target = Variable(torch.range(1, 10))  # a dummy target, for example\n",
        "criterion = nn.MSELoss()\n",
        "loss = criterion(output, target)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:443: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(38.5381, grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0TPXLgRrdfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(loss.grad_fn) # creator貌似被grad_fn代替了\n",
        "print(loss.grad_fn.previous_functions[0][0]) # Linear\n",
        "print(loss.grad_fn.previous_functions[0][0].previous_functions[0][0]) # ReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOAPopdDKPtK",
        "colab_type": "text"
      },
      "source": [
        "调用loss.backward()，看看 conv1's在进行反馈之后的偏置梯度如何"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W22B8W0rE5x1",
        "colab_type": "code",
        "outputId": "19923a7c-be9f-4548-afa3-a5135f895e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# 调用loss.backward(), 看看 conv1's在进行反馈之后的偏置梯度如何\n",
        "net.zero_grad() # 归零操作\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "loss.backward()\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0193, -0.0114,  0.0311,  0.0051, -0.0441, -0.0320])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8pYaRWLBkO",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## 更新权重\n",
        "\n",
        "最简单的就是**随机梯度下降法(SGD)：**\n",
        "  ~~~\n",
        "weight = weight - learning_rate * gradient\n",
        "  ~~~\n",
        "**简单的python实现：**\n",
        "  ~~~\n",
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "    f.data.sub_(f.grad.data * learning_rate)\n",
        "~~~\n",
        "还有许多不同种类的方法：**SGD, Nesterov-SGD, Adam, RMSProp, etc**，这些方法都可以用**torch.optim包**来实现"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8thatqJiNxQB",
        "colab_type": "text"
      },
      "source": [
        "1、创建 optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll0qrHJrE6F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "# 创建 optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgdMhhxpOA_z",
        "colab_type": "text"
      },
      "source": [
        "2、使用 optimizer 实现梯度下降"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IsE13MpreNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.zero_grad()  # 缓存区梯度归零\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()  # 开始更新"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aj8xak5E7oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NDVYUoGE73B",
        "colab_type": "code",
        "outputId": "9ac68ee8-047f-4817-da9c-b2f721398a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAsxHDkTWZlo",
        "colab_type": "code",
        "outputId": "c12de9a0-10d3-4e90-fcea-340999b529a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "\n",
        "# show some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s'%classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bird   dog  deer   dog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztfWmQXcd13tf3vv292QHMAoAcgAQJ\ngOBOcRElWZYsm5Zl00k5imSXo1RUxfxwEjvlVCJFPyxV5YddSdmxqxynWN7klCPZlhWLlh1tlFSS\nHIkSQZEEF4BYiW0w+7yZt2+dH+f0PefNuzPYKAxm3F8VOQ997+vb3bfvfeec7yzGWgsPDw8Pj82P\nYKMH4OHh4eHx1sC/0D08PDy2CPwL3cPDw2OLwL/QPTw8PLYI/Avdw8PDY4vAv9A9PDw8tgj8C93D\nw8Nji+C6XujGmCeMMceMMSeMMR97qwbl4eHh4XH1MNcaWGSMCQG8AeB9AM4D+AGAD1trX3vrhufh\n4eHhcaVIXMd3HwZwwlp7CgCMMZ8F8CSANV/ouVzODg4OXsclPTw8PP7xYWpqas5au/1y513PC30n\ngHPq3+cBPLLeFwYHB/HUU09dxyU9PDw8/vHhU5/61JtXct6PnBQ1xjxljHneGPN8pVL5UV/Ow8PD\n4x8trueFfgHAbvXvXdzWBWvt09bah6y1D+Vyueu4nIeHh4fHerieF/oPAOwzxuwxxqQAfAjAM2/N\nsDw8PDw8rhbXbEO31raMMf8GwJcBhAD+2Fr76tX2M1YYAwBoc0wYhgCApaUlGWiSfnv27r0VAFCt\nVqNjzWYTANDpdKK2fL4AACgUBqK2VrMNACiVSgAAY0zPNZMpWZJag65Rr9Wjtnab+giCoOt7uj89\njvXOc22tVis65rSYVCoVtdXrdP16U8Zx5tJZaPzrj38i+rw4Pw8AqCzMRG3nT74CAJg6/UbU5i4b\nFkZoXJm+6Fj/wDAAYHDHRNSWKhChXeC1BYBsKg0ASPJcMmkZdzpB82yuLEZtS+ePAwAWzh2P2hrL\nNM4QtN6hEjM6PMhScSVqq/G9XyqVo7aypev377wNALDvoR+Ljm3fcyf1m85EbWFAY/vfv/e7WI3K\nrZ8EAFi5jTA8JmOksVUsAgCGttE921dYjo6dmqV9tBAMSR9uTqpfh6Dd2xaH6Lu2t801GXWsbXuv\nadsxbZ3utrZsyahNbVO06ZFDU437YP6TXWPddeet0edMKg8AqJVkD8/P0j596cUXorYWP3N799wC\nABiU7YSRDE1mR142SNCmwSX6hC+cOPAgAOCex94NADAJ9SwVaa9Vl+ejtqXZWQBApSJ7LJOjfX1u\n+iIA4HuHn4uOTc1TH0Urc1lpNgAAzY4svlv7WoOOGciCJ0M62Gk1ZC6gPfzwre/DteJ6SFFYa/8e\nwN9fTx8eHh4eHm8NruuF/lZg7969AEQKBYAG/6JlMiJRJRL0qzwwMNj1l44lAQBFlpgAYPt2/sW2\n8mvupPZarQYAaLdEvBgcov6a6hez3qDztCS/WgrX0niHpQU9l0hCT4iEnkjQsjtpX8NJ6PqY00ac\n1AD0Suidsmg4i2dPAQCmT78etTWXpgEAfUb6nW+QyJUMaDx79+2Pjm0f3wkASKXkmplslv6qthTP\nJcHzTKod5VZtpS5SSykg0S6flTXNBzTnoENrZNXcW077ajRlLjVaj1RH2hosIdUXSfKaOn1SjoEk\ntOzgsIwtXHvri2QuIqnh2WSsSHG35YkyusPSNV95U+ZUTB6ivpIy9yjmQ4d+RBK0wdrQfdDftgnU\nUVqvTpv3plItgjbtYav2OhKkiQXqvDbc/qQLqC0faSWBanOPVdhZ22p7/MTh6PNdBx4FANz3wNui\ntgJrhI8+JG21lUsAgEaZ9mvrjHhBtxoL9KEp1xyw9I4IKtJ22yRp5SsLtP/nXhOttHyB2hrVhait\nskKaXpXfCwBQ4Wc4maP+D2Sl/1tGaf9fsvIOOj5D1oTpolgVOnyPDC9WvSHvljarUYHaC7Yt179W\n+NB/Dw8Pjy0C/0L38PDw2CLYcJOLIwSdGQIQU8viopBp7ni91kuA9veTCpRJZ6O2DjMS9bqQp61W\nN6Gp0x44UrbVFrWoVicVSBOaCbYphEHYc8yRs+2OqLeG9dSGUreSSTIRpdNiulgPQ0NErKWza59/\n4eKZ6PPUFJkblmclFiEskyrYasjYggSppuPjuwAAE7v3RMfy/f10TZkeMkxMJ9Wckzy/gFVIbTiw\nvA5JK6aRFLN/bUV2dSLmjr+tzQlsRghVx+5zSrWlO7SP2jW6j6WZqehYsUT3sRyK2+yImmsPuF8t\n7TRYbb59SPbpgVkyB3zrNfrC2e3viY6l8v08Ac2A0nmm09tmsZ7JRZv8aK0SHdnXuTTNvcDbv2nl\n/kxfIhPRyqWjUVt+J5k4wkDWo2Pd/WNTQNd4eNzK5hIkLp8y5NgJMfldnJoDAJw/K6bCfbsnAQD9\nao8tnCPzyOJFMhs2FuaiYxne/rmM3INOhvbTzr27ZLQ1cno4/KXPAwCqU3LNZo3MY+m09JHL0Dok\nFRNsy0RwN6p03xvKDJjk53ZyUBwGxifJueOHJ8X0Oc/fmasycZtU7wp+HyTUXi8UxCR4rfASuoeH\nh8cWwYZL6E7C1RK3k5a12+Lu3fQL3N9PRISWrlOpJP8VEtVJwWGYjNqcu6KDJl3dNcOE/MY5YtJJ\n3gBgq7ZrvJq8jCM53TXceDRcv1p6d/3qazqi1JTWluJKdVmrWpuli7a49SXaRPJ02iIlFDivztC2\ncQBAvq8/OtZfoHGnlA9ckj+HijELVv3VhJ+T0K3SkkJLUlBKsUE1y9IKS4BGSS3NOvWRUCJ6ku+R\nJunk+tS/qQt52WAS1Wa3RW237qQ5x8VTu0spDzQkmUzeMf9i1Pblk3TC3C1PAABy2Xx0rB25Emom\nMeZiVwm37QNF3g+G5AwwbmkP7x6Te/xqiu7xK9NCuLU7TJSmxP00aHcPrmPVPebFtUHv/kusI6nX\n6solz5C2/eor/xC1papEgKYq8lymqzSH8hxJ5s+fE/JyeJCk4Hc+dG/Utvft5KJ4+913RW0XjpCL\n7hs/JE211pyNjs2VqP+d4xITef9OcmvNK8eFUu0EAOD0adIUNKE5sYscBgYDcVMt9NG+e/eB26K2\nJj9PM7wOx89fjI5dmqPntarI/nxe3kfXCi+he3h4eGwR+Be6h4eHxxbBhptcZmYo6kqbV5wJ4tKl\nS1Gb8yFfWSGVSfucO79vTVA6E0dKRX46H/LxcVK3tdkmzRGO5bKYBxyJoQlb5xPu2nQfzlyi/db1\ndx2ceceNW5Oj7nxtcolMOeuo7JfOnYo+10u0NkkVcun4HtUtBvspQjSTJ7U8UKaOLA870UXq9f7+\nRzO1q/4NoMaRnNWiqKZOtbdt6df5nQc890ZD/PhdpKiOsnOaf0P10XBEdJOjTRticsmniC1sLp+P\n2s699N2euayelDa5jKdp4crHxS96qu+d1H+OVOumMrkFbLIIlH+5689avY7rkaG9sNxvO5So3ost\nmt/Febr+haqs37v2kqljaVj22NkEnR8oc5plE5js595xdfumu7PW3pSaRK1XmbwcFbNXn6HnK62e\n2xrvjyBLa/qO9z4cHZs8QKaWd71TooD7R4Z7rpUbI5PS2Qq9A6YvCtlZDOg9cmpFIkXLdSJi754c\nj9o6AZk/Zou0lm31HNzWTzEug6MShb5Uov2WgbD9mQpdd3JsBwDgzuGR6NiXDr8MADg2K++xEjt8\nQCyfVw0voXt4eHhsEWy4hH7qFEmWOpeLk9B126lTpwEA20bo17GpEktY2+syB84jsnOnuDNt307S\ngXNbLJeFNMxyFGQ2J66PjiDVUrZzs3TagNYKnISu88w46NwsDm4ccRK9lvzd8VRG9SFBeACA00de\njj4PFUgy6VMSd81F1xkhXjJ5kjDCZLpnLiEn/AhV7hLrognjqlzxGHWUZ5m1ruqKSMutKq15U0Xl\ntZq0poHTcFS3SV4Po6JTK+wyapLS1qxRH1kmyAMrJJZpUb8jSmOZPvId+pDTCUO7piJsIIB0lbSM\n1xflHiT3U74RG7mpammcCV5FLrpP18eNmlV/gY6hNeqwRjkH2cPFKUqvtGRFOgyTTLIrFcQNM5K8\nu8RxdB9UH4NgbZkwaAvpetuefQCAdz3wQNSWrpJ0unBWtMuLRSIw88Mk1aYVcbu4Qs/Vcy/KXr/n\nnrsBADu2yfxGd9E9vf3AQQDAyrLsvz6O+EyH8v4I2GHg5GmhyEtldnVt9WoW2SS1pTMyd8OPfFNp\nlwGTz4sXaS/uuuPO6Ni7HqTSEc2XJafRuZmeZLVXDS+he3h4eGwR+Be6h4eHxxbBhptcXKKsbdtE\npXEk4cKC+KDm80QCHTxA/qb9A0JIOLW8K5kXR3S2VQKnKG0tq4n9/cI+OOIxlRF/8ST30aV+MpxJ\nJIxJ8qTNJW1mI7VvdYL9XaWPXrONRpKTj9lgbWU9HYgKmWGyqal8XMvst+xS4AJAkueaTNM1w6Qy\nrxg61lG/+YaJoVBFwlpW9y2vUbsuppRqldOSloXc7pSorVUVMgh8j8JUznUqh1zyJ+3OzdcKoGIA\nOLVwo0nmhoSKJqxV6Fg+L37i2wdoP72pSOJonnzJhJr73DKN90JZ1nmE4x5c8qXu4Eom92J8t7tv\n8dr31Nre7wr7rL7nkmdxjMF4IGmTj7xBEbPLQ++N2pzRKCaLr3QZt9dUk4sk7Soyv+orT/7Mh6PP\nQwP0rF08KRGrK1NkaulXpsR2jp7rbxwm8rllj0XHRjlh3GPveDxqu/se9klXpp8km01/7oMfpO9t\nlwjM8jyZbjtViUKvr5A5rVgUE+z8Er17khye2j8gZqw+Tiy3OCd+5QhoDvWa7I8hTiAY8loWZ8Uf\n/o7JAwCA8cmDUdvffvtrAICmvPauGl5C9/Dw8NgiuKyEboz5YwAfADBjrT3EbcMA/gLAJIAzAD5o\nrV1cq4/1cPfdRGro8nQDLH1rMrLQRxJVJJlrd8EYUrTDhE8ikVHndae3DY1KIhEVndBujmHX+YAQ\ntm5siYTIOXFEaZKJuyDQBS7or5PetZTj3C3jUvYiRtqTuYlk0G7R73SzJqRyjYmfvHLjTDFx3Jej\ntmxSSeMxOUYCF4VptSTvPtCfellcFGvLs/xXJMYWt5m2rKnTrFKsiXQUWVfhyL5aVSR/l7J3sF9c\n90rsqmeSJCmZQOYZcP6YlnJzTIZrr6WT0PVy11iurZSFYBvh/DEmZHJWS6tOi9CahXVSe5xU7twG\n13djNKb3u+4rYZI+ZBelzswxLhSfVMVLXAblbs2TnyGXm0cdiZ4vdXqUdkc3rhra/JyIms9955sA\ngOUpIUAP3krE547d+6K2x36MNAmbI9K6siz76dBdpJ0/9s53RG3bR7bxpVX+H76BI7dQ1OZP/rMd\n0bGlSxQ9+tK3vhS1XTxGJGurKq7TfWmaTJotAyNKyg9zpOmtTKno7Baxoi1NgvM+HuCo6+KsSs/L\n7pmjd9wftT3x3vcDAP72r76Oa8WVSOh/CuCJVW0fA/CstXYfgGf53x4eHh4eG4jLSujW2m8ZYyZX\nNT8J4N38+dMAvgngP13LACYmKGOZtn+7z11udKGzO5OUpd0AnZQQF+Sjc6i481xbXB4W7SrpbPm6\nyIO7hBtPt9tWr0uZs51r4c19R77b66KoJZ8oYGmd399A5awJWMvoKInUZXdrN8SlsrFCduEOu2+m\nhMZAGBtgssq3TbfxfWmWRWppl0hp65REympX6FqZlMpg6eblxD4l5TRYMm+qYJkOazYJtT9cRsqV\nZvc9BpSGpWz/yWBtC7KTqtv6lAxJZa2G2FnbnC8mKPD+uFwZuXX8Ft0+6RJ4rdvXamxxNnm2hvcn\naDzTl85Ex6pjPwkAyKt96hSgQK2zXaVqdbo0M3Qdo3G6Ag26XmD3uP7uy38n/2jSHtilUyu2KIdL\noi17si9Dx+/YSy6hGXWPDx6kAiyDeeXCyuUNkyqPjnteDbvZhjnhjTLD5NJY6sj75vwlyhuTVvlx\ntg+QxSA/PMhTk5t7cYGCklodGdvCAj1LgdLw67xnV4q0RoU+GWPI7pAddf5cuBPXi2u1oY9aa11+\n0ksARq97JB4eHh4e14XrJkUticVrUvXGmKeMMc8bY57X0q+Hh4eHx1uLa3VbnDbGjFtrp4wx4wBm\n1jrRWvs0gKcBYGJiYs0Xv85n0muS6M2Jok0SzvwRlzelq+bnKjOMVstdBKiOHnVmmOHh4Z42Z96J\nczPUiKJYdcrZKEKUIx518Yaw26VRQxfOWI0do5JsP6iS6l1XpG+TTRelJSGqFqYpMq04TW6FO3aM\nRccM587RHF1vzKP6yK6H7Zq4IzaW6VrtqqRHta46ulWkJRPLtuEKkCgCmbdoU6VijUhZZX5wkb4t\nF8wqI4zcFZs1ubddZe1XoRNjWUpxvpakIlvrJVbV+8hW1dYmCR5HR7e5/C6awLOrc6hoxNX37DpE\nH9l1NF0mwvGCFZfedH6s53xH+pouE6Uz9bnrqH3tLGLd5UvovFB1vGpJs4q0rte4Bm9C5Shq0v1e\nmpbXxw+/S+l1T14gs8b4rluiY+emztFllLmswxHBQ9u2y4W5cEuQzOihAgDSbM5Np8UJo1qnMQ0P\nSbTp8AibWpg8X1rUhTa4RqgqAZqI8hDJIjR4zs06bYZWW9ZvhJ0lajNCEmf7Y3xorxLXKqE/A+Aj\n/PkjAL5w3SPx8PDw8LguXInb4mdABOg2Y8x5AL8B4DcB/KUx5qOgGgEfvNYBOMlVZxd0wUZa4k5y\njg4nQmhXQndeXL4UDSl60UtounEUCpI7os4/wXFSeJzk7aT3OK1Az6XDknar1dRT6uovzm2xuY5U\nGSSUhhPSuHUZMUckVpVbYb1M0vTSDFVYL6sMltkCSbUWveNAjKTmKpY7qRUAaty/zshnnfSdFFIq\nYMLRtbX1ejuCV0uTvFdSWenDSeEBp4kslkV8ilxMjSq51ll7LYUfVKUE2TWxv08IttoKrVvfBJF1\n3S6FMcFoMUfiCP0rguok7TIlligXSS0nRRYGOL9Lp6W1u3VcNqMcLWrv8N+u/cSyoM4HsxppVb8w\nTNDa25aYXbNZkuCX5oVIP3aSysUtWnqWF1UW1rlZkuQLJyT/yegYaSC7Jm+N2gY5q2FcLqYqZ2ud\nL6qgRdYkcn3yDOWYwJzn6wfaxZn3p1UkaoH3cE3t9Xab88Y454pAOS7w9isvyDNXiC5x7eTolXi5\nfHiNQ+9do93Dw8PDYwPgI0U9PDw8tgg2PJfLHNcO1ASlU5G0H3qkrrIqqCNL40wucQSp68+pQPoc\nFwHa1ydEjuuvplK9OhXZmVe0L7tTm3WbI1vj88G0+Zi0OTOQHpv7bmsdUrSkTAxhhYtwKB/XQpZV\nXnWtDJsnUknn/y39R3UZdBrfng/yucm5WYoLU9GhEpOhCZW2NtNPhFW2X4jm7ACpyIYjResVIS9b\nS+RnXFPmplKR1OCClXu1bZAJrZDMMFGxAAAV7i+rYh2M89uPsbw4v2ttTXDrkR0Q4nhumchkZ2nR\nFpdov64f+BmZowyvvdVkZPR4alMHq/vq0e1vU/Tt0iKZEVK7f0IN3PWgiFi5uBqI7Tpqukxt/EFF\nuAbO1LZO9HKtKua9JD9z2vJjjIu+VXlVOBK3wZdKq3t29swZAEBhcChqm+fUuLMqRe7oGBGkrWaF\n5yJr6sjZhdnpqK0J2ivZgpDJKc4FNDg4wN+TcdQrdK2Uzn1kqY90SqVc5txEjuTXjh8u8jmn6ojW\nl5156dpNLl5C9/Dw8Ngi2HAJ3ZGbmhR1knQXMciSQBhTACJOqnWfNUHp+nORqForcNfXEavuGro8\n3moSK44w1RK6nldvH1zRXlUbd7/imvRts1hjwrV/f8tlIZsSXGBjMCXzGxwkMk8TiQG7ZKXTtFa5\nvGSUi3PGtDGineUzV5bIzay8ImvVYvfCICGaU5Aj0lm7VCZDOu6kMZ3NscBZ+kpLopHNzpAWULwo\nEmB+iKSyvm0kvalEmlHBkXpT+k1n1ibQhfrtzVOSGD0g/b7wNwCADkeMJhKiMbiI5i7/SRvTxP9I\nJngvWLnvpQ6tVaD3uutDPbm5EmUQPL9M6obTxoAogLdLVYiTqQN2BXTbuZujXcelch2Ctd4UTavG\nmmomIXuyXKa55pTaOJijPZDhnENhTs7fnietbnBMitZU2BXw3AXJZNjmDJ2j2zjbodJ63FbcNi75\nXYo1ct/tqIylbnum+XkJjIyjukzPWpiU56XV5oyhan4rrKE6l1qr1JMGl0psKjfpICsS/LXCS+ge\nHh4eWwT+he7h4eGxRbDhJpc4v+u46DlH6jj105GYcX0B8cSqgzODdJGu3G8rplZpUflnr/YX1r7s\ncb7E6/mwO19obXJx19cml4hYXcfk4mp1AlLAoGVUSl02v4QpsUVUyrSGtQb72ytS1Nlc9BWjcati\nHZYLSzS5bqgOHEywSSfMCdl0YZHWvloWf/W+S6SabuO6jcP9EguQZt/dLrdxQypsSc350gz1F+TI\n5FJXEXuWfaDrTVlTG30WtTnqvueD5PXK75S6kMGLpCLPHP8eAGD80PvkC611UuRCm5uo49Eypbyd\nS4g/tTOJQdd1dalhU0ICVqdeAgCUAzJJ9KmbJpmOe33kuwlbF71se892nHnclNYhfdOhjLvBCbga\nKuPZQo3TNudlT5oqOz2kOMmaclIY27MHALBrr9yDFugevPzK61Hb3DSRrO0Km6CUeS01QP7iKRW3\nMThA61ZeOh+1hS7FNsdGtDqq8A3HPCwtipnHccMFVXhneJDMgHNL5D+v3PIRpGlMLZXGuZZmc2jv\nq+2K4SV0Dw8Pjy2Cm0ZC14iLwlxNlHZJvjHnt5w02ZUDtVvyD5SEHrDk01GEnCtfV9U5QJx0w3+1\na2Dk+KWjGvn63RlnuyWkZlOkSV02bjXarXXyxigfuzaL100l1i6zW+Pxk0qqYM0gt2McADC5LJpI\npjDC5+j5uWvoQhjUVirRGjlCCgD68iQtTy3LnN54k8jTs29KhfOQ13lkhKSbO/cK6TXWT1JLuSQp\nVms1EmE0ybmwRGPPLhIpW1US/QprIlrSbbe5rVeBi3KdoK1JUd5PSqK65YEPAAAqR54BAASj4m7W\nGKboUV1vLuDKElZJrpk3vwEAmGGFobrn7uhYiu9jS+W2KXRofubU16K2c3PsAreHCFsdmSsSt4rW\njTTguNTP7nu9z6WJEf/WC3Ad7hftp86RxEZpgXOc18e0hcTdMUg5ifbdSu6h4aDkKJrYR/MbHZe2\nttOsmyLWzl4i0vzSOYo6rbZFus4NksSfCOWahRHKF6OjUovz5NZYyLN2p9YjP0KSd7qk3Emb7pkW\np4O7HngUAPDSCSqgMb0kLr3ODTaXFxfMmera0ctXCi+he3h4eGwR+Be6h4eHxxbBhptcJJXsZULq\nnG7X6a59SN91VYFiTB268krQ/ftllZnCugRHqjanYVJR14B013LJenSfrkZpV/Ro0OtTH6zKgapr\naDrVOOwiW+lvq7O2OabR1FGk9DlUqv1SkUi0czOiVja54/SrVFn9zrsfjI6NjpEaWlkW//YmzytM\nCsnUl+PqMBwVVyzJ+gXsdzszK30EaVIxi20hRStlmtfpGVKRp2fk2H37yIyRUImQpH6qzK+0QsSq\n8zk3aakOE0XwKvNHw8UHiObdg+7twrED6t5md90OABhqvQsAcFvllejY/DgRbRcaqgyUJdU/t/RG\n1DR9nnzIw/t/CQCQUgR5h00+hY4QoOb0VwAAU+q+hAN0r8I+MgUEOjlcxGj2zq/7kVtFlPZam7qe\npciEs85zW1fVsVp8z3Ta2lqdFriREBL83ndSiqgD+4gcTiTEJBFFcoaqetAl2jPLS5KCt9ki89/4\nbqq7Mz42Hh1L8PW1pS3ZpnXL9UvitXNHXwAALLCZJK/S/oZM6I8My7jdvu6khBRdZNNgZoh83qvL\n8uwt8n5NNISoL5apbUi27lXDS+geHh4eWwQbLqHHSeZO6l0vpWiXtBBDiq53rSidqiL8nFQdatfA\nINnTNj+3yG10rK+vX53eW5gjLqK0s4rYjc0Ho/pwkaLNdSR0nculwBxQUkno1Tq7Q1qRTdpM6J7j\nmoozsyIZJ18nN7AXXngxaqvzOFIqmvaRtz0AABhgF63Fqtyz6VNUkCDok6i8bIGkoGpb1r6VpDWs\nWZLoihWR8mtNmsPEkCra4Krbq8jWGU5D6qJ6C8PKVY1dNit1WY8aF9NYT0Lv3k4ud4k6zgR6bTet\nwUxZiizsXSEibOeAEHjnGyTFLZ97Lmrr7PsxAMBAhqS9TlvdY75W4tz3o6bFKZLot43tj9pmc/sA\nABl2/+tyGHC1Srtn1jM/+cx7sistbm/tW/m8NlEfKoeBIEhzv+IumMwT8f7wjz8ZtR18xzsAALkc\n3b+8irwMmFCtViX3y4kzpO3UFSm6h90aJ8b38lCljw5H4jaaSvNkF9YBVeCisJ2k+3NHfwgAWJk6\nGR2rduhaiaQ8+8Pj5FK5d//9Udt8la6xxJJ5JZA9ucLOA6Fy2ljm+YlOcvXwErqHh4fHFsGVFLjY\nDeDPQIWgLYCnrbW/a4wZBvAXACYBnAHwQWvt4lr9rIU4ady1xeVhiSsIsLq0nD5PBw+5z+48nf2s\nVCrxtVWQD/d76tSbUdsLh+kXO8mBCTt2SH3sHOd9cBXo6bhIp6vHFie9r1voYJ2f33pD2XZZqmmr\nrjJcTKCpcoW4iuPju8leqXOufPlLXwUAHDsq9t4wTf3qvDFvniLJ5Z8++bMAgJFde6Njp4+fofGo\ncbTZZmgbolEUi7T2SV6HkRG1plwKr39QDIvJYZpLoSi5XFYqJDUtLtIWbClpKMNaAXRJPl6cuAcg\nzo7ciSnkEDlxMscyW5CgoIVZ0jL2Q7L63VKkvfP3S+I6OnzvJACgzZqI2n44kKdAl8KwPFaHF0kq\nnM+L5J8ZvaN73F37xNm6laup7Q3mi44Zx1Ep3mg9+/s6ezIMVa6TDk1s+w4pvjE2QS6ap6ZEup7+\nCq3R0HaSlodVVtXhAgfj1MRh1IyYAAAfJ0lEQVRePrVA/MKdt+2O2m7fR+uRYgl6RbnNWuYltA09\nnaO9lc3KZAIQ97FtN0nepcX56JgrsDKgEgals/R5bLfs/7MvkCZ25CS9P+aWL0ofzCmMDokd3jav\nsshJDK5EQm8B+HVr7UEAjwL4FWPMQQAfA/CstXYfgGf53x4eHh4eG4TLvtCttVPW2hf48wqA10EJ\ne58E8Gk+7dMAfv5HNUgPDw8Pj8vjqkhRY8wkgPsBPAdg1FrrQp8ugUwyV424VLlxxSOcWcKZY7Qp\nJc710bVpM4wzZ7hcLrp/lxtGa9YXL1ABg29/+ztR25nTpD6lOHXmmdNnVf+kRt1yi1Qqf/zxxwF0\nF85YnasmLqeMRkSyrvPza1S9wpBNJ+WKuEkluMp4TtVMzY2Qa90v/PMPAQCKc1Jn8cUjR+mcjKjN\nRS6gUK2JO9obx6i+41E2rzzyoJBCy/OkGrs1A4D6MrUNKjewapNMLiMjZKoa3yYmqxabZlotMY8V\n2PySqouqnsnQ8bkiqcaGTWgAEDoXxkC2e30dk4vziF27nEg3XN3VQOdcGSfTwmHhmdF5nfZRY1bW\no3zkiwCA3ZwHxoRiKro1R6aWKaOilzNkCjCD8ri5Wh22456DuEHGMqByOPJN5LnowhX8Xav5TxdZ\nHXOpaKzKDPj2t/84AOBnf/YXo7ZsnuZycVoilC9M0/2b5TwpZ/gZBIBjFTL1pUMx+Y3vILfWIJT9\nMTVNr6VclswxRt3lGuf4yao00oU+Mus06tKvczcu9FPE6gibtQAgnaJnIquSs3S4UsrCsphmvvIt\nMlsulmh+pars10Sa1nulJs9oFyF+jbhiUtQYUwDw1wB+zVq7rI9Z2g2xBiBjzFPGmOeNMc9XKpW4\nUzw8PDw83gJckYRujEmCXuZ/bq39PDdPG2PGrbVTxphxADNx37XWPg3gaQCYmJjoeenHlW2Ly7a4\nWpqNI0x1MYk4qX21hK77dy6MOpfKmTMkSS0tyq+ok1JcXpXFJfltazYqfEzmMsZVyScnJ6O2qEJ9\n0Pt7GhGm6vcxzr1xNVKK4E1x1ralikjc5QpJutu2i2vd4+99DwBgmKukf/Nr34yOVbiEWy4rEr0L\ndhooiLbh8mqk+Lz+bSI53v/YozwpmcsSu0a2xiSIYyRN/Q6PUl9LM5LnJTdC80omxaXMScQt7Qra\n6c6WWS5JME6BS9wFGVkju16awFUufICQhGad/Cc6sYnzdG0vi4j+D9//EgBghyL6+u1nAABDoKCk\ntz367ujY7KuUgXHmxR9EbZ0a7f/ZupDEkw8QGduO0e5E8o5zOURPm4nO1ykbuU2z7OuR94yBAdk7\njzz4EADgljHZH65oxMSAaIH37CH31IVF+u6lOdEG59g1tVKS57HRoCCihXmR8leWSDvbvctJ4UrD\n4WDBjnovHD1OWvalC5Jr5Z2PkztpX5b2qVHuvkGL3Y6TyqrA/b56VO7V7By5mCY526Mta02Bnsfl\nqipMk+nN/Hm1uKyEbugN80cAXrfW/rY69AyAj/DnjwD4wnWPxsPDw8PjmnElEvrjAH4ZwBFjjIsy\n+c8AfhPAXxpjPgrgTQAf/NEM0cPDw8PjSnDZF7q19jtYO439e693AI6MjPNDXy/yM853W/cRV9hi\ntf+3Nnk4c0alIipehf2t02lRhdKpBo+bzSCtXtPP8oqYYX7wA1LBdMGKe+65B4AQttqUEtVHVVF2\nzowQVyzDQdcydBXvVzTHkiWi8fHHfypq2r+fIuq+/HeUH+ToK6+qcdC1tOli2wCRWAVlchlmP/vx\nnUQEm6ys1fjtd9HYUmJiOHGEijEoN2ck+VozM+R3HUIGvm2YVPSEitYtV0jNrtRl3VqsbA7209g0\nAbU4R77gIxPiJ57Lrh0i6rZdV74g9whocrHnsehNgFJQZFr2lrcBAN54RZTZVJKiPJc4vqEvK/d4\njivUf/VluS/b99Ej13+rkM9uZVZHIHfDxn5c3Wijv70katd6RLVK4/oiZPrExHXiTcoXdMf+Q1Hb\nYIH2k1Vr6p7b/j4yvTSUl0KpRuarw4efj9qOHyfyfm5OLL6pFF33kYcfAwAcuktSEpsk7a0jrwsx\n/XU2NQYqovTuQ7S+24bJZJpOqqIkXO9UhTVgaorMhEdekcjqPk797FJQtzry3JT5NdNS+7TQz4S4\nL3Dh4eHh4bHhuVychB7ncqjbVhOf8VFuvefHSf5x/3b9LswLkTgwMMTnqZwvLDE0W2sno9fl8aan\nSTq8cFGIvomJCe6fpBBHkgIiXcW6YCrXxNWoqGuWWUMo1YRw2XeAJKM777onajt5nKSmF39IUnNb\nEcIJ57qncmQ0WZowGVnTvhwXDIhCHHUuHJJQRndLdGCCfey0xB2yxDMyyoUaktK/CxCtlkXraXHO\ni1pNtJ6Q1yvP0axtdX8Wl5iYDGX9Mlx2LFaWjSSvXmk8llt0GqLuxEUv94sL5oPv/7cAgKN1KZgy\nzKXkLsxSFOEXvn44OvYTD5GGkxqTwhlzZTpv9/G/jtqqlQf5PPprNPnLE1QelXA1OjSv6babE+7b\nOmqxQdJvoygl2ursEmvUmkI8LgmqiP2Lr9G8+tR6vPtxctXsVyUKQ94/hRyRomFa9sn0HJGXb549\nGrXNLdFzVWvLXnfOdN/+/tcBAMs1eaYTKZrg9CVxh2xybpaH7tPZRjkSl5+9tvLZDNzDoTZDq8UR\n0EaeoQEmeyucdXFkQOcjoj3faErEdJvzLa2n9VwOXkL38PDw2CLwL3QPDw+PLYINN7k0W6Si6FS2\nrjiFJgtTqVTXMW0ucd+N8znv8m/nvy4dbqBT5bJv6dnzolb2DVDCHe16vFzh6vZMWuqIuhYTpG1V\nNzHBZOWIStI1s0AmgHmOvLzzDiHOXL8dpeK5PjIqum015lQ9xBr7trZVhGHfMKm6mYKYdy4wkeMi\nP1OaSObFyqqK6QOcKCuXlnFkudjFEpuq5mckkdTYKJk1EspkNTJOSZQSaek3wdGr9Xlal0ZRkldV\nimRi6DSFrLas6rZVgi9wlF2rTudlU2prh2QWqqvasA22OyT6pPhBBL7f3Zov+2l3VOtqYlCbMNz+\nVL7bu3aTGv9PPvkforYv/D55AtdjLHhf/M53qVtVUKRUJRPeCxekmEY2/1cAgMFJSuO7827JwpEf\nZOJRDa7GdhVdb7fDa9Mqkili5dLr0bHlGTJxdEri691q0nNg1T7d8f5uH4lsn+yTToOu/+qxl6K2\new6R+a9fmRxDjvh0RWAyKgJ0/51EIE/ukURc9TaNo95U5rQ8XbfOZsiz05JgzqVerlXENDLEtWwf\neeyxqG0bJ91rVjlmRdva+NbqgjOLS7T/M1nlnMBbtlEt8dyEiE8yo2rU/Kx7l1xHji4voXt4eHhs\nEWy4hO6gScbVeVuA3iIW+lhcxKWTzAMldToiLkrNr1ihJBdBOHdBJPRskSSHlpJCakxiJEHnB0p8\nb7Z6XTAtF0FIq2IM+w8R2VVkqTZU2ombi9YsWnW6po3LY8qYnpccEg0+vxOIBNF2pfPUtXShCgCo\nlEWCdUltsnlVKII1hbSSGB0Z2mJCdX5OxtHXR+uXyYjUkuDv9o1K+tdJnvPcSSJpZxqSh6UyQ/12\nVKmu0JVpU+55Ad+jkNcoXxBpaHsfaSfalbHK+016Fbgt0+miTI36f3dbdLvVwagkhAruLaSpv3sm\nJeq1/va3AwAunqJ9N6fKlP3JSXLP01GK+QLdM6s0hTKnH144/GUAwNTr35JrcurgZkeerwZHMmfU\nXggtrXOFpfB6TWk/LE3mVYRrkd1ws6m166WFyjc1ZBJQOwCIi3BceUZ3RPrIs0tsJq3zM9E9TaV1\nLih+RtnVMFtQmgLnWwqUdtKs09wLeZlftJ/4RmaURulSDDdUib0Tb5AWUJwSArbF5RDzHBGbUOUF\nF/kZbSsNLuOexytNIhQDL6F7eHh4bBH4F7qHh4fHFsGGm1xc9XUd2enMDdp00W47FajXR919tyt5\nFR8OE71pdt35un/nO14sCvFT47as8usV/ZqTQamEYM5UpCP13PGjr4vv7L7bidxx1YxC0/u72lIm\nKDfO1jq+70uLMm4X3RkqNXR5mdTyslKlD91LpNTcWao6dPLIEemQVc6W9m/nCE2dCMzlms2xuppS\na9XicVeUf3vGJLgP2XqDO4iYTPDSat/chSUy4SzNqvA5ru7TVnVnAjYHJSyprUlF3A4OETlb6Jf7\nMr9E5K3QrwJ3O8J2TPI0RYI7E1hcymNnHbNqn6aZpDZL4jP9yNvI/PbCApG/p96UeAXLZq9KR+Ze\nWyY1vl8R+jlO54ok3QN9z5bmiOSsq9SsZSaOk8qHPMlkfI1NhIWErF+OzWrVmvTh9uJA39pEfb0q\nJokWf3e6KhGdxcXlrnkCgA2o32jZ1LFWk441VPzB8CA5LqRyshcqHH/R10/mJpcyFwDqbKpqtaTf\nFFdWGh6UhHGRqZTJ9e73E/V37qJEm75xnEjkyrKYXNpct7SvL8t9KjMPm2drahyJJpt1rkPM9hK6\nh4eHxxbBhkvocalhnSStJVLnYpVh6VAfc1GeXa6P1tVo7JXQ3XczihR0baPbxb2wxCFnRuWacCSg\nbTnXr94xalcuV7c0kxJSxfJ5KSYItZTvoAtzuHS8cflpHColkfpqnChi+4CQb3MzJIu6mpsAsHuC\n5urWKK3G6KSKhIpOtSwVzi2JFDLGEn+GXQ+zfXl1PkkfyUxvhGuXFxhL7aafxmv75R7YArUlm4ok\ndgRpRwjEIEltCUe+qYjEgSFKGaz5tlJ17dz8pueD5HLRfbgcJNFfReA5PlDnRHGRtvW6SK4DO0gq\nnCmTy+YxFVG8dzdF9xaVu+XFS1RQZLElxHGJScBBzpmzQ+Xasbw/WxDCb5o1m2VV0KGQYQ2Ln0fn\nTgwAC23OX6Sk/BTLgpW6jGM1OkphHuDcLIdul0jl/XtvBwAkdTENdGvA2n23zpJ5nyJWgyTlWimW\nhYwfGyNXzTKTromEImc5ehkNeZZuv3U/AGBkZJvML+XcJ13NYxlhhcfx/MuSKrdYJw25rNZjZIi0\nhxoTsTVVGMbl3UkklHOH7SaErwVeQvfw8PDYIthwCb3Akl1cGbZaXWypaf7FjGyTMZkVdR8uAETb\nrZwULpkVRUJxNvldOyVvhnOlzCqbseXvzrLEq+3lA4MkheSUe5crcKHL0iVYU3CuYeuWnQPQYikr\nxNoSunO9AoAUl6AbHhQJ3Unwp06eitqyHGRRYndFXSDBfcoqVy4XLFNaEYlxcYUkk0yOJPqcktAT\nXKIrpYJ8nOSqZREnyS3X6eCC8pjLDNP92DEh61fhXDW1OSlI0CqR1pBj23wmJ+PIsHSYUJJgeo6P\nxwjq0SqHOlKIc+xAu9J2B4LorIHO47ErG0xA96ValgkWhkmanp4j3iNVkHwf23cSt/Diy5LfxXIw\nS1NptG12SVzi/ZpUEmneuZoGsof72O1vRWWrLNVIssxzkYWEKq/W4ACukZz0EbLb7ooO7loFowLK\nJnaQm+qhOw5EbTnWUK3WUHmvrHAAX1ZxIW22O+9Wz+gbp0jjbKm5zHOemaYrM6j4ALcyA3mRxh9/\nmItZ5MWGblgybzn354TcyXNTZwAAJ89I8FWYop53TsrYnKtjm+eXrMpaJVjKLylX4SDofQ9cLbyE\n7uHh4bFF4F/oHh4eHlsElzW5GGMyAL4FSoaZAPA5a+1vGGP2APgsgBEAhwH8snVhW1eBuMhIFy3m\nzCwAkGKSULs4qTEC6CZKHUGq25wS6fLCxNUx1dFw7rs7xyWqcYRd4KpMquk6pi4KLqNqA6ZZ7Uqo\nAhQRw8J/tdkmrmaqG9t6RbZzXdFwHE2bkLm4KNBXXnghahvkuRaGiYQsLimXTY4ETCvSt5Cg+WUz\n0u/cDJF5p0+R6+PbdkrN0qzLv6MCLp2XVkPVXV1epnlNTZFLW60mxwbH9vA1ZasWRplsnRT1HU12\nqUzSxWolIW6rRSLMjKpIEGaJsEKlN4Gu8wi0sUk1VEGTVUUv9NZ00YTaROOCAkslcbsbH5oEABRz\nNJ4z0/8g4yidAwDMLkpd0g6bVzSp7IwBDTbHzKxIUZJ8gp6hdCjX7PCQkoqQq3DUo8tDpAly9+n2\nITFTBJyX5ExR1nk1aioyd36W7sGp4yek7TzNa98dd0ZtfUwkNvlV0lDE7ewMmdhaak8uzJN5JTAy\n3u1DlIclnenj82WeRd5rb7v/0ajt0AHKgZMMVP5fF5nOxVcqNSE7/99z3wQALM6LyS/DbpPNpoo9\nZkI3x89LQqca5v2fV66SSyqt8rXiSiT0OoD3WGvvBXAfgCeMMY8C+C0Av2OtvR3AIoCPXvdoPDw8\nPDyuGVdSgs4CcD9PSf7PAngPgF/k9k8D+CSAP7jaATgJXReFcK5+CUVyRpIwSyZhzLE4qTaRUnlE\nVkntmox0boIueAEQQjWnJG4XBOTcEHWAU5bLmmUzWlruDUBK8LUMi4IpRdbF5aVx67FeLpcglD7q\nNXaTUin8qnWSZFodWY95Duy449C9AIDxCdFEahx401gRySRhuvO2AMAyBzG9dORlAMDgmEhxB+86\nCJ5o1ObyqZSqIskssmbQ5H63KfcxlxkTan7bthPZO6CyT3a4wECL3fmqS1LAoMOsa12VF0w78nFe\n3DgdojgvRXLKfY6rcMHnqP3k+giURF9jon4pqYjjLK1NjfPuXFiQcYfLND+tSbpcJHFVEDqsItTV\nNVsclBRACLkwjClVx0N37oramcDtrdMrIo0nA5ImV2px2XAIuYI8N9Pz5I75fVXSMMVS9RtvSkDb\n9jGSrvuHSHI9fkYyJS6wpqLLIpZZch4elD0zOkRk8kA/td1+2/7oWDpLaz8+IeSl0yStWje7ym2y\nqMpKvnmWCm0kk7qMoXP3lD1QZYm7yftvoL8QHWsH1JZUOWKSTpP4UedyMcaEXCB6BsBXAZwEsGRt\ntLvOA9i5xnefMsY8b4x5fj2TgYeHh4fH9eGKXujW2ra19j4AuwA8DGD/Zb6iv/u0tfYha+1D2p3P\nw8PDw+OtxVX5oVtrl4wx3wDwGIBBY0yCpfRdAC6s/+14uOIKRqmQac4H0lbEWZ1JOoncUgn7XYEG\nReS0nOqoo/cC992YnCtshumK2mQWS0dtJtls40habfrRkaoOOTYLtNXY2qyCOT/3dEqZDnhMul+n\n2YTJtf3QdX1NZzXSBQxqvJbNZTGhzLGpY/IOitib3LNH5slqflNFNTqVtFGWtkVOl1sskxo8vyjq\n8Nximeci61eucNpQNfbA0dV8q9ptbTqjzwOF/qgtw/sjUPfFcM6eINrS0keBzTw1VUcymXP3udfk\nsipYkS/AYw3Wi+brCiOlFsWUBinafztuE2W2xoVJps6QGh8a5XfN+6StQy7jIlbddSNbkSpcgeaq\nloiP645/cDVF+Z8Nnfe3TQcvLYvZIcMRxK24oqwMnY45zXu32lapkTn6t3ZB2s7NnKFL8tgucq1V\nABjeTg4JoZp8h+MDamqfHj36Gp3fTwT96LBEHu+9hfZ4Pi3CZbtO+yNM6BS5nG6ao5iH+iSm48F7\nHwEAfO/5Z9VsOY2vMrc2yvQgrnAOpJoq0pLi9ai3lanZffc6uNHLSujGmO3GmEH+nAXwPgCvA/gG\ngF/g0z4C4AvXPgwPDw8Pj+vFlUjo4wA+bcjnKwDwl9baLxpjXgPwWWPMfwHwQwB/dE0jiBE6ixx9\nqAlHx6uFLCFpEtAVM9CEYoMJtoZyI3ICjJOCtcthnJtjm0XdpvoV7esnV6gdXKJKE7cuslVzBXW+\nvp6LK33nCNa2ypHhJNJKRaSWaEzB2rer2dQkFkkaTSU+NZgoNUmRyhZZWp9dJClxcFjyn+SzNM+B\n0VHpw3ml1mQ9JvdR5shSiaNNlZTaYYc3ndmuExUEUQQir40rGRb51UEI0JGR4agtyfla6mp+zSii\nz/nkCQGVKBA5luqTexuUe/PnRGNcXVpOfdQa35XI6jo7oyu+kcrp7J20V4Kg90Fw+1TnBopzpTSr\nRqLPd4SwfjbceptehSK+f1fsRGmSeZZmU4m1sy0O5OQeBDzGtnI6WGSJ35V61GOq8jOkcyD152hP\n6vxJmSStZUO5SBp+Jl1elSkl5Y+cI6l9oF8k7h2jXIawrTV2zg/FkcdaK3jwvvsAAC+9+u2orcT5\ndoJAZank6GmXWXFpUeVA2sHuvcpK4LKSXo9h+kq8XF4GcH9M+ymQPd3Dw8PD4yaAjxT18PDw2CLY\n8ORckYqn1VtWU7v8b/mzM3GEKsrNqaY6mZf7blol1spzoilnakkpH3Uxicj5Tk3VZGuNE2otLM73\nHHOJxnIqoVWVk/y7tK76Wi4FqSN89bGMKhRRq9me8a5GoHy9XZKoVquXTHN1GQGgzaaki5emeNxy\nLOCiE1VV2bzDyapSqg5iKsUJuDhla0WZYxbYpNNs9EbPlctiUnJmNHdvB4ckem5khNPnKsK5yWp7\nS9dd5X4dmWWU2abDanCQkcRXNikE32o41/eOUrMTbOILNSnqEnA5QjHGhKHzezlz0/ETEpE7toc6\n2T443NUn9+wmoJq4+EugopxdIjquPRokVSIujpYsKxOeYaIUgTIxcHchm/VCbTpjU1tSmVf6CzTe\noezahqdRFVnqzKg1ZWIYHmWzh9rWmQw9T/kCp8m+IOaVFpOXY2NiBnQLNjMthTOybC5cLpLZ5rvf\n/050bOoi1W5NhbJGd99DJpTxiV1RW46jvt37aXpWokIvXKQI3nRGmXgtmwFVilyT6C7GoyNFl5fJ\nRKNNSs5slPMFLjw8PDw8TFzq1h8VJiYm7FNPPXXDrufh4eGxFfCpT33qsLX2ocud5yV0Dw8Pjy0C\n/0L38PDw2CLwL3QPDw+PLQL/Qvfw8PDYIrihpKgxZhaUqWDucufe5NiGzT2HzT5+YPPPYbOPH9j8\nc9hM47/VWrv9cifd0Bc6ABhjnr8StvZmxmafw2YfP7D557DZxw9s/jls9vHHwZtcPDw8PLYI/Avd\nw8PDY4tgI17oT2/ANd9qbPY5bPbxA5t/Dpt9/MDmn8NmH38PbrgN3cPDw8PjRwNvcvHw8PDYIrih\nL3RjzBPGmGPGmBPGmI/dyGtfC4wxu40x3zDGvGaMedUY86vcPmyM+aox5jj/HbpcXxsJLvL9Q2PM\nF/nfe4wxz/F9+AtjTOpyfWwkjDGDxpjPGWOOGmNeN8Y8tgnvwb/nPfSKMeYzxpjMzXwfjDF/bIyZ\nMca8otpi19wQfo/n8bIx5oGNG7lgjTn8V95HLxtj/o+rxsbHPs5zOGaM+amNGfX14Ya90Lni0e8D\n+GkABwF82Bhz8EZd/xrRAvDr1tqDAB4F8Cs85o8BeNZauw/As/zvmxm/Ciob6PBbAH7HWns7qKjm\nRzdkVFeO3wXwJWvtfgD3guayae6BMWYngH8H4CFr7SFQna4P4ea+D38K4IlVbWut+U8D2Mf/PQXg\nD27QGC+HP0XvHL4K4JC19h4AbwD4OADwc/0hAHfxd/4Hv7M2FW6khP4wgBPW2lPW2gaAzwJ48gZe\n/6phrZ2y1r7An1dAL5KdoHF/mk/7NICf35gRXh7GmF0AfgbAH/K/DYD3APgcn3Kzj38AwLvAJQ6t\ntQ1r7RI20T1gJABkjTEJUJWxKdzE98Fa+y0AC6ua11rzJwH8mSV8D1RAfvzGjHRtxM3BWvsVLmwP\nAN8DFbgHaA6ftdbWrbWnAZzAJqzIdiNf6DsBnFP/Ps9tmwLGmElQKb7nAIxaa13G+0sARtf42s2A\n/w7gP0JKJ4wAWFKb+ma/D3sAzAL4EzYb/aExJo9NdA+stRcA/DcAZ0Ev8iKAw9hc9wFYe80367P9\nrwD8X/68WefQBU+KXgGMMQUAfw3g16y1XaVuLLkJ3ZSuQsaYDwCYsdYe3uixXAcSAB4A8AfW2vtB\nqSO6zCs38z0AALY1Pwn6cZoAkEevKWBT4WZf88vBGPMJkEn1zzd6LG8lbuQL/QKA3erfu7jtpoYx\nJgl6mf+5tfbz3DztVEr+O7PW9zcYjwP4OWPMGZCJ6z0ge/Qgq/7AzX8fzgM4b619jv/9OdALfrPc\nAwD4CQCnrbWz1tomgM+D7s1mug/A2mu+qZ5tY8y/BPABAL9kxW97U81hLdzIF/oPAOxjZj8FIiCe\nuYHXv2qwvfmPALxurf1tdegZAB/hzx8B8IUbPbYrgbX249baXdbaSdB6f91a+0sAvgHgF/i0m3b8\nAGCtvQTgnDHmTm56L4DXsEnuAeMsgEeNMTneU24Om+Y+MNZa82cA/Av2dnkUQFGZZm4qGGOeAJkg\nf85aW1GHngHwIWNM2hizB0Twfn8jxnhdsNbesP8AvB/ELJ8E8Ikbee1rHO87QGrlywBe5P/eD7JD\nPwvgOICvARje6LFewVzeDeCL/HkvaLOeAPBXANIbPb7LjP0+AM/zffgbAEOb7R4A+BSAowBeAfC/\nQNXIb9r7AOAzIHt/E6QlfXStNQdVs/59fq6PgLx5btY5nADZyt3z/D/V+Z/gORwD8NMbPf5r+c9H\ninp4eHhsEXhS1MPDw2OLwL/QPTw8PLYI/Avdw8PDY4vAv9A9PDw8tgj8C93Dw8Nji8C/0D08PDy2\nCPwL3cPDw2OLwL/QPTw8PLYI/j96MM58Czj+WwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xts_GClE8FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"docstring for Net\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,6,5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(6,16,5)\n",
        "        self.fc1 = nn.Linear(16*5*5,120)\n",
        "        self.fc2 = nn.Linear(120,84)        \n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1,16*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gu9QooXE8Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#声明使用交叉熵函数作为代价函数\n",
        "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
        "#声明使用学习率0.001的SGD优化器\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0\n",
        "    for i,data in enumerate(trainloader,0):\n",
        "        inputs,labels = data\n",
        "        inputs,labels = Variable(inputs).cuda(),Variable(labels).cuda()\n",
        "        #获得数据并将其放在GPU上\n",
        "        optimizer.zero_grad()\n",
        "        #初始化梯度\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        #前馈\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #反馈计算梯度并更新权值\n",
        "\n",
        "        running_loss += loss.data[0]\n",
        "        if i % 200 == 0:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0\n",
        "            #打印平均代价函数值\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayEP51z2E8vP",
        "colab_type": "code",
        "outputId": "42e85fea-3770-4976-99f8-8930f25fb4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "corret,total = 0,0\n",
        "for images,labels in testloader:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    outputs = net(Variable(images))\n",
        "    _,predicted = torch.max(outputs.data,1)\n",
        "    total += labels.size(0)\n",
        "    corret += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * corret / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 10 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vi1N3ewXFCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P592TDzLXFRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg2uTAC7XFfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CyfQBbOXFsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqpMivTAXF47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH_iEmUv-vVe",
        "colab_type": "code",
        "outputId": "3abd89ec-40fa-49fd-b768-29a6af569b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x = torch.tensor([[1.,2.,3.],[4.,5.,6.]],requires_grad=True)\n",
        "y = x+1\n",
        "print(y)\n",
        "z = 2*y*y\n",
        "print(z)\n",
        "J = torch.mean(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 3., 4.],\n",
            "        [5., 6., 7.]], grad_fn=<AddBackward0>)\n",
            "tensor([[ 8., 18., 32.],\n",
            "        [50., 72., 98.]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWzVAmTrFRp",
        "colab_type": "code",
        "outputId": "c0798b7e-cce7-46de-cd35-706456c12e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "z.backward(torch.tensor([[1.,1.,1.],[1.,1.,1.]]))\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8., 12., 16.],\n",
              "        [20., 24., 28.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOYQcyJSztyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_LFpW52rpTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "J.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4jhtAa_r3fo",
        "colab_type": "code",
        "outputId": "8671c4f0-6593-42f8-c337-969495cc5835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8., 12., 16.],\n",
              "        [20., 24., 28.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heydkof3r-_C",
        "colab_type": "code",
        "outputId": "7e7fae98-b6b1-4824-a77f-fcc184399159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = torch.ones(2,4,requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixbpeQVfvAsw",
        "colab_type": "code",
        "outputId": "5ef6d082-45d8-4a79-d0d9-5c74ab1c5392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywut47stvE-3",
        "colab_type": "code",
        "outputId": "fa885921-98fc-4538-9a02-0d1fbbd13d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hb0_o-EvHAn",
        "colab_type": "code",
        "outputId": "bb27cd07-527c-4c97-87e2-e07da09758dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x.requires_grad_(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTrZgJIYvI63",
        "colab_type": "code",
        "outputId": "3442b784-9237-4cb4-f386-001c45f7c678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.requires_grad,y.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAKr86xgvYmL",
        "colab_type": "code",
        "outputId": "447cbb39-6b4c-4195-82f9-e71a56871431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "x = torch.rand(5)\n",
        "print(x)\n",
        "x = Variable(x,requires_grad = True)\n",
        "y = x * 2\n",
        "print(y)\n",
        "grads = torch.FloatTensor([1,1,1,1,1])\n",
        "y.backward(grads)#如果y是scalar的话，那么直接y.backward()，然后通过x.grad方式，就可以得到var的梯度\n",
        "x.grad           #如果y不是scalar，那么只能通过传参的方式给x指定梯度"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3219, 0.7271, 0.3582, 0.1854, 0.4333])\n",
            "tensor([0.6437, 1.4541, 0.7165, 0.3709, 0.8666], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eo4D-aa5Zps",
        "colab_type": "code",
        "outputId": "5f0e6a39-b03b-4f55-9c1c-656969513398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(2,1,7,3)\n",
        "conv = torch.nn.Conv2d(1,8,(2,3))\n",
        "res = conv(x)\n",
        "\n",
        "print(res.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 6, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q6bZfRu-JV1",
        "colab_type": "code",
        "outputId": "92a80e9b-684e-4d23-f7b3-0c958a0da06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.6527, -1.2410, -1.1945],\n",
              "          [-0.0185, -2.1766,  0.6402],\n",
              "          [-0.7816, -1.0634, -0.2349],\n",
              "          [ 0.2766,  0.1649, -0.1483],\n",
              "          [-1.8347, -1.0713, -0.4455],\n",
              "          [ 0.8888,  1.0780, -0.9985],\n",
              "          [ 0.2306, -1.0541,  0.2395]]],\n",
              "\n",
              "\n",
              "        [[[-0.0297, -0.6147,  0.8194],\n",
              "          [-0.0355,  0.5811, -1.1233],\n",
              "          [-0.2102,  0.5853, -0.1647],\n",
              "          [ 1.0932, -0.9402, -1.8629],\n",
              "          [-0.6348,  1.0294, -0.7822],\n",
              "          [-0.2458, -0.6021, -0.5502],\n",
              "          [ 0.6221,  1.1570, -0.1598]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0n4zp2-KAh",
        "colab_type": "code",
        "outputId": "04f4de25-1b19-4790-fea6-33110ffc85a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = torch.Tensor([-1])\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNTzfubWBgMc",
        "colab_type": "code",
        "outputId": "cd4f2e52-7152-48f0-9081-aa339ef09a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.FloatTensor(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mipyIMbOWNsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}