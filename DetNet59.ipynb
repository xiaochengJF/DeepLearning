{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DetNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1du856gLPIlb9OAxBCMWWr-YZ9cYdHTQG",
      "authorship_tag": "ABX9TyNC5gq163m2GNOMsTP9QOUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaochengJF/DeepLearning/blob/master/DetNet59.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPJO_QOC7ipL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''导入必要模块'''\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import math\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "\n",
        "'''\n",
        "Norm = \"Batch\" 下面所有的正则化都是用 Batch Normalization\n",
        "Norm = \"Group\" 下面所有的正则化都是用 Group Normalization\n",
        "'''\n",
        "Norm = 'Batch'  \n",
        "\n",
        "# \n",
        "# 搭建 Residual 模块\n",
        "# 可以参考 torchvision.models.resnet50() 中的实现细节\n",
        "# 搭建子模块\n",
        "class ResidualBlock(nn.Module):\n",
        "    # 实现子module: Resifual Block\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inchannel, outchannel, stride=1, shortcut=None, norm=Norm):\n",
        "        super(ResidualBlock,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inchannel, outchannel, kernel_size=1, bias=False)\n",
        "        self.nf_1 = self._Norm_function(norm, outchannel)\n",
        "        self.conv2 = nn.Conv2d(outchannel,outchannel, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.nf_2 = self._Norm_function(norm, outchannel)\n",
        "        self.conv3 = nn.Conv2d(outchannel, outchannel*4, kernel_size=1, bias=False)\n",
        "        self.nf_3 = self._Norm_function(norm, outchannel*4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "\n",
        "        # 将Residual Block 看成两边组成，左边为普通卷积连接\n",
        "        self.left = nn.Sequential(self.conv1, self.nf_1, self.relu,\n",
        "                                  self.conv2, self.nf_2, self.relu,\n",
        "                                  self.conv3, self.nf_3,)\n",
        "\n",
        "        # 右边为 skip connection 或者叫shortcut\n",
        "        self.right = shortcut\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.left(x)\n",
        "\n",
        "        if self.right is not None:\n",
        "            residual = self.right(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "    def _Norm_function(self, norm, outchannel):\n",
        "        if norm == 'Batch':     return nn.BatchNorm2d(outchannel)\n",
        "        elif norm == 'Group':   return nn.GroupNorm(num_groups=1, num_channels=outchannel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OTflzTL9EwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dilated_BottleNeck(nn.Module):\n",
        "    '''实现module：Dilated bottleNeck '''\n",
        "    expansion = 4\n",
        "    def __init__(self, inchannel, outchannel=256, stride=1, shortcut=None, norm=Norm):\n",
        "        super(Dilated_BottleNeck, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(inchannel, outchannel, kernel_size=1, bias=False)\n",
        "        self.nf_1 = self._Norm_function(norm, outchannel)\n",
        "\n",
        "        # 空洞卷积：对应论文图A、B中绿色的小模块\n",
        "        # 为什么stride=1，padding=2，后面会有解释\n",
        "        self.conv2 = nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=stride,\n",
        "                               padding=2, dilation=2, bias=False)\n",
        "        \n",
        "        self.nf_2 = self._Norm_function(norm, outchannel)\n",
        "        self.conv3 = nn.Conv2d(outchannel, outchannel, kernel_size=1, bias=False)\n",
        "        self.nf_3 = self._Norm_function(norm, outchannel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "\n",
        "        self.left = nn.Sequential(self.conv1, self.nf_1, self.relu,\n",
        "                                  self.conv2, self.nf_2, self.relu,\n",
        "                                  self.conv3, self.nf_3, )\n",
        "       # ''' 先保留右边为空 '''\n",
        "        self.right = shortcut\n",
        "\n",
        "    def forward(self,x):\n",
        "        residual = x\n",
        "        out = self.left(x)\n",
        "\n",
        "        if self.right is not None:\n",
        "            residual = self.right(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "    def _Norm_function(self,norm, outchannel):\n",
        "        if norm == 'Group':     return nn.GroupNorm(num_groups=1, num_channels=outchannel)\n",
        "        elif norm == 'Batch':   return nn.BatchNorm2d(outchannel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCZpXmqt9UT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DetNet(nn.Module):\n",
        "    '''\n",
        "      实现module：DetNet\n",
        "      DetNet59：model = DetNet([3,4,6])\n",
        "    '''\n",
        "    def __init__(self, layers, num_classes=2):\n",
        "        # 初始 residual 的位置\n",
        "        self.inchannel = 64\n",
        "        self.det_channel = 256\n",
        "        super(DetNet, self).__init__()\n",
        "\n",
        "        # 前面 stage1 ～ stage4 与 ResNet 相同\n",
        "        self.stage_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            self._Norm_function(Norm, outchannel=64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.stage_2 = self._make_layer(ResidualBlock, 64,  layers[0], stride=2)\n",
        "        self.stage_3 = self._make_layer(ResidualBlock, 128, layers[1], stride=2)\n",
        "        self.stage_4 = self._make_layer(ResidualBlock, 256, layers[2], stride=2)\n",
        "\n",
        "        self.stage_5 = nn.Sequential(self._DetNetBlock_B(self.inchannel,   self.det_channel),\n",
        "                                     self._DetNetBlock_A(self.det_channel, self.det_channel),\n",
        "                                     self._DetNetBlock_A(self.det_channel, self.det_channel),)\n",
        "\n",
        "        self.stage_6 = nn.Sequential(self._DetNetBlock_B(self.det_channel, self.det_channel),\n",
        "                                     self._DetNetBlock_A(self.det_channel, self.det_channel),\n",
        "                                     self._DetNetBlock_A(self.det_channel, self.det_channel),)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(7,stride=1)\n",
        "        self.fc = nn.Linear(self.det_channel, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stage_1(x)\n",
        "        x = self.stage_2(x)\n",
        "        x = self.stage_3(x)\n",
        "        x = self.stage_4(x)\n",
        "\n",
        "        x = self.stage_5(x)\n",
        "        x = self.stage_6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # 构建图A模块\n",
        "    def _DetNetBlock_A(self, inchannel, outchannel ):\n",
        "        return Dilated_BottleNeck(inchannel, outchannel)\n",
        "\n",
        "    # 构建图B模块\n",
        "    def _DetNetBlock_B(self, inchannel, outchannel):\n",
        "        shortcut = nn.Sequential(\n",
        "            nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            self._Norm_function(Norm, outchannel))\n",
        "        layers = []\n",
        "        layers.append(Dilated_BottleNeck(inchannel, outchannel, stride=1, shortcut=shortcut))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_layer(self, block, outchannel, block_num, stride=1):\n",
        "        shortcut = None\n",
        "        if stride !=1 or self.inchannel != outchannel * block.expansion:\n",
        "            # 构建残差 1X1 卷积\n",
        "            shortcut = nn.Sequential(\n",
        "                nn.Conv2d(self.inchannel, outchannel* block.expansion,kernel_size=1, stride=stride,\n",
        "                          bias=False),\n",
        "                self._Norm_function(Norm, outchannel* block.expansion)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inchannel, outchannel, stride, shortcut))\n",
        "\n",
        "        # 更新residual的位置\n",
        "        self.inchannel = outchannel * block.expansion\n",
        "\n",
        "        for i in range(1, block_num):\n",
        "            layers.append(block(self.inchannel, outchannel))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _Norm_function(self,norm, outchannel):\n",
        "        if norm == 'Group':     return nn.GroupNorm(num_groups=1, num_channels=outchannel)\n",
        "        elif norm == 'Batch':   return nn.BatchNorm2d(outchannel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l--J07-H9jzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    '''\n",
        "    实现module：ResNet\n",
        "    用子module实现residual block，用_make_layer函数实现layer\n",
        "\n",
        "    ResNet50:  model = ResNet(ResidualBlock, [3, 4, 6, 3])\n",
        "    ReaNet101: model = ResNet(ResidualBlock, [3, 4, 23, 3])\n",
        "\n",
        "    '''\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        self.inchannel = 64\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.Conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            self._Norm_function(Norm, outchannel=64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.Conv2_x = self._make_layer(block, 64, layers[0])\n",
        "        self.Conv3_x = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.Conv4_x = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.Conv5_x = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion , num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Conv1(x)\n",
        "\n",
        "        x = self.Conv2_x(x)\n",
        "        x = self.Conv3_x(x)\n",
        "        x = self.Conv4_x(x)\n",
        "        x = self.Conv5_x(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, outchannel, block_num, stride=1):\n",
        "        shortcut = None\n",
        "        if stride !=1 or self.inchannel != outchannel * block.expansion:\n",
        "            shortcut = nn.Sequential(\n",
        "                nn.Conv2d(self.inchannel, outchannel* block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                self._Norm_function(Norm, outchannel * block.expansion)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inchannel, outchannel, stride, shortcut))\n",
        "        self.inchannel = outchannel * block.expansion\n",
        "\n",
        "        for i in range(1, block_num):\n",
        "            layers.append(block(self.inchannel, outchannel))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _Norm_function(self, norm, outchannel):\n",
        "        if norm == 'Batch':     return nn.BatchNorm2d(outchannel)\n",
        "        elif norm == 'Group':   return nn.GroupNorm(num_groups=1, num_channels=outchannel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-Sd0n49mtH",
        "colab_type": "code",
        "outputId": "23051057-7844-4d52-b230-9c82fb5edc0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    x = Variable(torch.randn(1, 3, 224, 224))\n",
        "    # model = ResNet(ResidualBlock, [3, 4, 6, 3])\n",
        "    # model = torchvision.models.resnet50()\n",
        "\n",
        "    model = DetNet([3,4,6])\n",
        "    y = model(x)\n",
        "    print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DetNet(\n",
            "  (stage_1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (stage_2): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (right): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage_3): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (right): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage_4): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (right): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): ResidualBlock(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage_5): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Dilated_BottleNeck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (left): Sequential(\n",
            "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "          (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (right): Sequential(\n",
            "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Dilated_BottleNeck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): Dilated_BottleNeck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage_6): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Dilated_BottleNeck(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (left): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "          (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (right): Sequential(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Dilated_BottleNeck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): Dilated_BottleNeck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (nf_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (nf_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (left): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrZAAI1lEsBE",
        "colab_type": "text"
      },
      "source": [
        "## 可视化网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgVEWyll-QQc",
        "colab_type": "code",
        "outputId": "0e63c073-5872-4778-e224-be80b459957c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install graphviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPNEL8oq-qm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from graphviz import Digraph\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def make_dot(var, params=None):\n",
        "    \"\"\"\n",
        "    Produces Graphviz representation of PyTorch autograd graph\n",
        "    Blue nodes are the Variables that require grad, orange are Tensors\n",
        "    saved for backward in torch.autograd.Function\n",
        "    Args:\n",
        "        var: output Variable\n",
        "        params: dict of (name, Variable) to add names to node that\n",
        "            require grad (TODO: make optional)\n",
        "    \"\"\"\n",
        "    if params is not None:\n",
        "        assert isinstance(params.values()[0], Variable)\n",
        "        param_map = {id(v): k for k, v in params.items()}\n",
        "\n",
        "    node_attr = dict(style='filled',\n",
        "                     shape='box',\n",
        "                     align='left',\n",
        "                     fontsize='12',\n",
        "                     ranksep='0.1',\n",
        "                     height='0.2')\n",
        "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
        "    seen = set()\n",
        "\n",
        "    def size_to_str(size):\n",
        "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
        "\n",
        "    def add_nodes(var):\n",
        "        if var not in seen:\n",
        "            if torch.is_tensor(var):\n",
        "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
        "            elif hasattr(var, 'variable'):\n",
        "                u = var.variable\n",
        "                name = param_map[id(u)] if params is not None else ''\n",
        "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
        "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
        "            else:\n",
        "                dot.node(str(id(var)), str(type(var).__name__))\n",
        "            seen.add(var)\n",
        "            if hasattr(var, 'next_functions'):\n",
        "                for u in var.next_functions:\n",
        "                    if u[0] is not None:\n",
        "                        dot.edge(str(id(u[0])), str(id(var)))\n",
        "                        add_nodes(u[0])\n",
        "            if hasattr(var, 'saved_tensors'):\n",
        "                for t in var.saved_tensors:\n",
        "                    dot.edge(str(id(t)), str(id(var)))\n",
        "                    add_nodes(t)\n",
        "    add_nodes(var.grad_fn)\n",
        "    return dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCmkBU3I-0VF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('./')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    x = Variable(torch.randn(1, 3, 224, 224))\n",
        "    model = DetNet([3,4,6])\n",
        "    y = model(x)\n",
        "    g = make_dot(y)\n",
        "    g.view()\n",
        "\n",
        "    #print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoGTXOkCFOJC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}